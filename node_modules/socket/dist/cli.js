#!/usr/bin/env node
'use strict';

var require$$0 = require('node:url');
var vendor = require('./vendor.js');
var debug = require('../external/@socketsecurity/registry/lib/debug');
var logger = require('../external/@socketsecurity/registry/lib/logger');
var utils = require('./utils.js');
var fs = require('node:fs/promises');
var Module = require('node:module');
var constants = require('./constants.js');
var words = require('../external/@socketsecurity/registry/lib/words');
var fs$1 = require('node:fs');
var path = require('node:path');
var shadowBin = require('./shadow-bin.js');
var prompts = require('../external/@socketsecurity/registry/lib/prompts');
var spawn = require('../external/@socketsecurity/registry/lib/spawn');
var util = require('node:util');
var arrays = require('../external/@socketsecurity/registry/lib/arrays');
var registry = require('../external/@socketsecurity/registry');
var npm = require('../external/@socketsecurity/registry/lib/npm');
var packages = require('../external/@socketsecurity/registry/lib/packages');
var sorts = require('../external/@socketsecurity/registry/lib/sorts');
var path$1 = require('../external/@socketsecurity/registry/lib/path');
var regexps = require('../external/@socketsecurity/registry/lib/regexps');
var fs$2 = require('../external/@socketsecurity/registry/lib/fs');
var shadowInject = require('./shadow-inject.js');
var objects = require('../external/@socketsecurity/registry/lib/objects');
var registryConstants = require('../external/@socketsecurity/registry/lib/constants');
var require$$7 = require('../external/@socketsecurity/registry/lib/promises');
var os = require('node:os');
var promises = require('node:stream/promises');

var _documentCurrentScript = typeof document !== 'undefined' ? document.currentScript : null;
async function fetchOrgAnalyticsData(time) {
  const sockSdkResult = await utils.setupSdk();
  if (!sockSdkResult.ok) {
    return sockSdkResult;
  }
  const sockSdk = sockSdkResult.data;
  return await utils.handleApiCall(sockSdk.getOrgAnalytics(time.toString()), 'analytics data');
}

async function fetchRepoAnalyticsData(repo, time) {
  const sockSdkResult = await utils.setupSdk();
  if (!sockSdkResult.ok) {
    return sockSdkResult;
  }
  const sockSdk = sockSdkResult.data;
  return await utils.handleApiCall(sockSdk.getRepoAnalytics(repo, time.toString()), 'analytics data');
}

// Note: Widgets does not seem to actually work as code :'(

const require$4 =Module.createRequire(require$$0.pathToFileURL(__filename).href)
const METRICS = ['total_critical_alerts', 'total_high_alerts', 'total_medium_alerts', 'total_low_alerts', 'total_critical_added', 'total_medium_added', 'total_low_added', 'total_high_added', 'total_critical_prevented', 'total_high_prevented', 'total_medium_prevented', 'total_low_prevented'];

// Note: This maps `new Date(date).getMonth()` to English three letters
const Months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'];
async function outputAnalytics(result, {
  filePath,
  outputKind,
  repo,
  scope,
  time
}) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (!result.ok) {
    if (outputKind === 'json') {
      logger.logger.log(utils.serializeResultJson(result));
      return;
    }
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  if (outputKind === 'json') {
    const serialized = utils.serializeResultJson(result);
    if (filePath) {
      try {
        await fs.writeFile(filePath, serialized, 'utf8');
        logger.logger.success(`Data successfully written to ${filePath}`);
      } catch (e) {
        process.exitCode = 1;
        logger.logger.log(utils.serializeResultJson({
          ok: false,
          message: 'File Write Failure',
          cause: 'There was an error trying to write the json to disk'
        }));
      }
    } else {
      logger.logger.log(serialized);
    }
    return;
  }
  const fdata = scope === 'org' ? formatDataOrg(result.data) : formatDataRepo(result.data);
  if (outputKind === 'markdown') {
    const serialized = renderMarkdown(fdata, time, repo);

    // TODO: do we want to write to file even if there was an error...?
    if (filePath) {
      try {
        await fs.writeFile(filePath, serialized, 'utf8');
        logger.logger.success(`Data successfully written to ${filePath}`);
      } catch (e) {
        logger.logger.error(e);
      }
    } else {
      logger.logger.log(serialized);
    }
  } else {
    displayAnalyticsScreen(fdata);
  }
}
function renderMarkdown(data, days, repoSlug) {
  return `
# Socket Alert Analytics

These are the Socket.dev analytics for the ${repoSlug ? `${repoSlug} repo` : 'org'} of the past ${days} days

${[['Total critical alerts', utils.mdTableStringNumber('Date', 'Counts', data['total_critical_alerts'])], ['Total high alerts', utils.mdTableStringNumber('Date', 'Counts', data['total_high_alerts'])], ['Total critical alerts added to the main branch', utils.mdTableStringNumber('Date', 'Counts', data['total_critical_added'])], ['Total high alerts added to the main branch', utils.mdTableStringNumber('Date', 'Counts', data['total_high_added'])], ['Total critical alerts prevented from the main branch', utils.mdTableStringNumber('Date', 'Counts', data['total_critical_prevented'])], ['Total high alerts prevented from the main branch', utils.mdTableStringNumber('Date', 'Counts', data['total_high_prevented'])], ['Total medium alerts prevented from the main branch', utils.mdTableStringNumber('Date', 'Counts', data['total_medium_prevented'])], ['Total low alerts prevented from the main branch', utils.mdTableStringNumber('Date', 'Counts', data['total_low_prevented'])]].map(([title, table]) => `
## ${title}

${table}
`.trim()).join('\n\n')}

## Top 5 alert types

${utils.mdTableStringNumber('Name', 'Counts', data['top_five_alert_types'])}
`.trim() + '\n';
}
function displayAnalyticsScreen(data) {
  const ScreenWidget = require$4('../external/blessed/lib/widgets/screen.js');
  // Lazily access constants.blessedOptions.
  const screen = new ScreenWidget({
    ...constants.blessedOptions
  });
  const GridLayout = require$4('../external/blessed-contrib/lib/layout/grid.js');
  const grid = new GridLayout({
    rows: 5,
    cols: 4,
    screen
  });
  renderLineCharts(grid, screen, 'Total critical alerts', [0, 0, 1, 2], data['total_critical_alerts']);
  renderLineCharts(grid, screen, 'Total high alerts', [0, 2, 1, 2], data['total_high_alerts']);
  renderLineCharts(grid, screen, 'Total critical alerts added to the main branch', [1, 0, 1, 2], data['total_critical_added']);
  renderLineCharts(grid, screen, 'Total high alerts added to the main branch', [1, 2, 1, 2], data['total_high_added']);
  renderLineCharts(grid, screen, 'Total critical alerts prevented from the main branch', [2, 0, 1, 2], data['total_critical_prevented']);
  renderLineCharts(grid, screen, 'Total high alerts prevented from the main branch', [2, 2, 1, 2], data['total_high_prevented']);
  renderLineCharts(grid, screen, 'Total medium alerts prevented from the main branch', [3, 0, 1, 2], data['total_medium_prevented']);
  renderLineCharts(grid, screen, 'Total low alerts prevented from the main branch', [3, 2, 1, 2], data['total_low_prevented']);
  const BarChart = require$4('../external/blessed-contrib/lib/widget/charts/bar.js');
  const bar = grid.set(4, 0, 1, 2, BarChart, {
    label: 'Top 5 alert types',
    barWidth: 10,
    barSpacing: 17,
    xOffset: 0,
    maxHeight: 9,
    barBgColor: 'magenta'
  });
  screen.append(bar); //must append before setting data

  bar.setData({
    titles: Object.keys(data.top_five_alert_types),
    data: Object.values(data.top_five_alert_types)
  });
  screen.render();
  // eslint-disable-next-line n/no-process-exit
  screen.key(['escape', 'q', 'C-c'], () => process.exit(0));
}
function formatDataRepo(data) {
  const sortedTopFiveAlerts = {};
  const totalTopAlerts = {};
  const formattedData = {};
  for (const metric of METRICS) {
    formattedData[metric] = {};
  }
  for (const entry of data) {
    const topFiveAlertTypes = entry['top_five_alert_types'];
    for (const type of Object.keys(topFiveAlertTypes)) {
      const count = topFiveAlertTypes[type] ?? 0;
      if (!totalTopAlerts[type]) {
        totalTopAlerts[type] = count;
      } else if (count > (totalTopAlerts[type] ?? 0)) {
        totalTopAlerts[type] = count;
      }
    }
  }
  for (const entry of data) {
    for (const metric of METRICS) {
      formattedData[metric][formatDate(entry['created_at'])] = entry[metric];
    }
  }
  const topFiveAlertEntries = Object.entries(totalTopAlerts).sort(([_keya, a], [_keyb, b]) => b - a).slice(0, 5);
  for (const [key, value] of topFiveAlertEntries) {
    sortedTopFiveAlerts[key] = value;
  }
  return {
    ...formattedData,
    top_five_alert_types: sortedTopFiveAlerts
  };
}
function formatDataOrg(data) {
  const sortedTopFiveAlerts = {};
  const totalTopAlerts = {};
  const formattedData = {};
  for (const metric of METRICS) {
    formattedData[metric] = {};
  }
  for (const entry of data) {
    const topFiveAlertTypes = entry['top_five_alert_types'];
    for (const type of Object.keys(topFiveAlertTypes)) {
      const count = topFiveAlertTypes[type] ?? 0;
      if (!totalTopAlerts[type]) {
        totalTopAlerts[type] = count;
      } else {
        totalTopAlerts[type] += count;
      }
    }
  }
  for (const metric of METRICS) {
    const formatted = formattedData[metric];
    for (const entry of data) {
      const date = formatDate(entry['created_at']);
      if (!formatted[date]) {
        formatted[date] = entry[metric];
      } else {
        formatted[date] += entry[metric];
      }
    }
  }
  const topFiveAlertEntries = Object.entries(totalTopAlerts).sort(([_keya, a], [_keyb, b]) => b - a).slice(0, 5);
  for (const [key, value] of topFiveAlertEntries) {
    sortedTopFiveAlerts[key] = value;
  }
  return {
    ...formattedData,
    top_five_alert_types: sortedTopFiveAlerts
  };
}
function formatDate(date) {
  return `${Months[new Date(date).getMonth()]} ${new Date(date).getDate()}`;
}
function renderLineCharts(grid, screen, title, coords, data) {
  const LineChart = require$4('../external/blessed-contrib/lib/widget/charts/line.js');
  const line = grid.set(...coords, LineChart, {
    style: {
      line: 'cyan',
      text: 'cyan',
      baseline: 'black'
    },
    xLabelPadding: 0,
    xPadding: 0,
    xOffset: 0,
    wholeNumbersOnly: true,
    legend: {
      width: 1
    },
    label: title
  });
  screen.append(line);
  const lineData = {
    x: Object.keys(data),
    y: Object.values(data)
  };
  line.setData([lineData]);
}

async function handleAnalytics({
  filePath,
  outputKind,
  repo,
  scope,
  time
}) {
  let result;
  if (scope === 'org') {
    result = await fetchOrgAnalyticsData(time);
  } else if (repo) {
    result = await fetchRepoAnalyticsData(repo, time);
  } else {
    result = {
      ok: false,
      message: 'Missing repository name in command'
    };
  }
  if (result.ok && !result.data.length) {
    result = {
      ok: true,
      message: `The analytics data for this ${scope === 'org' ? 'organization' : 'repository'} is not yet available.`,
      data: []
    };
  }
  await outputAnalytics(result, {
    filePath,
    outputKind,
    repo,
    scope,
    time
  });
}

const {
  DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$L
} = constants;
const config$Q = {
  commandName: 'analytics',
  description: `Look up analytics data`,
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags,
    file: {
      type: 'string',
      shortFlag: 'f',
      description: 'Filepath to save output. Only valid with --json/--markdown. Defaults to stdout.'
    },
    repo: {
      type: 'string',
      shortFlag: 'r',
      default: '',
      description: 'Name of the repository. Only valid when scope=repo'
    },
    scope: {
      type: 'string',
      shortFlag: 's',
      default: 'org',
      description: "Scope of the analytics data - either 'org' or 'repo', default: org"
    },
    time: {
      type: 'number',
      shortFlag: 't',
      default: 30,
      description: 'Time filter - either 7, 30 or 90, default: 30'
    }
  },
  help: (command, {
    flags
  }) => `
    Usage
      $ ${command} ${utils.isTestingV1() ? '[ org | repo <reponame>] [time]' : '--scope=<scope> --time=<time filter>'}

    API Token Requirements
      - Quota: 1 unit
      - Permissions: report:write

    ${utils.isTestingV1() ? '' : 'Default parameters are set to show the organization-level analytics over the'}
    ${utils.isTestingV1() ? '' : 'last 30 days.'}

    ${utils.isTestingV1() ? 'The scope is either org or repo level, defaults to org.' : ''}

    ${utils.isTestingV1() ? 'When scope is repo, a repo slug must be given as well.' : ''}

    ${utils.isTestingV1() ? 'The time argument must be number 7, 30, or 90 and defaults to 30.' : ''}

    Options
      ${utils.getFlagListOutput(flags, 6)}

    Examples
      $ ${command} ${utils.isTestingV1() ? 'org 7' : '--scope=org --time=7'}
      $ ${command} ${utils.isTestingV1() ? 'repo test-repo 30' : '--scope=org --time=30'}
      $ ${command} ${utils.isTestingV1() ? '90' : '--scope=repo --repo=test-repo --time=30'}
  `
  // Drop consecutive empty lines. Temporarily necessary to deal with v1 prep.
  .replace(/\n(?: *\n)+/g, '\n\n')
};
const cmdAnalytics = {
  description: config$Q.description,
  hidden: config$Q.hidden,
  run: run$Q
};
async function run$Q(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$Q,
    importMeta,
    parentName
  });
  const {
    file,
    json,
    markdown
  } = cli.flags;
  const outputKind = utils.getOutputKind(json, markdown);

  // In v1 mode support:
  // - []        (no args)
  // - ['org']
  // - ['org', '30']
  // - ['repo', 'name']
  // - ['repo', 'name', '30']
  // - ['30']
  // Validate final values in the next step
  let scope = 'org';
  let time = utils.isTestingV1() ? '30' : 30;
  let repoName = '';
  if (utils.isTestingV1()) {
    if (cli.input[0] === 'org') {
      if (cli.input[1]) {
        time = cli.input[1];
      }
    } else if (cli.input[0] === 'repo') {
      scope = 'repo';
      if (cli.input[1]) {
        repoName = cli.input[1];
      }
      if (cli.input[2]) {
        time = cli.input[2];
      }
    } else if (cli.input[0]) {
      time = cli.input[0];
    }
  } else {
    if (cli.flags['scope']) {
      scope = String(cli.flags['scope'] || '');
    }
    if (scope === 'repo') {
      repoName = String(cli.flags['repo'] || '');
    }
    if (cli.flags['time']) {
      time = Number(cli.flags['time'] || 30);
    }
  }
  const hasApiToken = utils.hasDefaultToken();
  const wasValidInput = utils.checkCommandInput(outputKind, {
    // In v1 this can't go wrong anymore since the unknown value goes to time
    nook: !utils.isTestingV1(),
    test: scope === 'org' || scope === 'repo',
    message: 'Scope must be "repo" or "org"',
    pass: 'ok',
    fail: 'bad'
  }, {
    nook: true,
    // Before v1 there were no args, only flags
    test: utils.isTestingV1() || cli.input.length === 0,
    message: 'This command does not accept any arguments (use flags instead)',
    pass: 'ok',
    fail: `bad`
  }, {
    nook: true,
    test: scope === 'org' || !!repoName,
    message: utils.isTestingV1() ? 'When scope=repo, repo name should be the second argument' : 'When scope=repo, repo name should be set through --repo',
    pass: 'ok',
    fail: 'missing'
  }, {
    nook: true,
    test: scope === 'org' || !utils.isTestingV1() || repoName !== '7' && repoName !== '30' && repoName !== '90',
    message: 'When scope is repo, the second arg should be repo, not time',
    pass: 'ok',
    fail: 'missing'
  }, {
    test: utils.isTestingV1() ? time === '7' || time === '30' || time === '90' : time === 7 || time === 30 || time === 90,
    message: 'The time filter must either be 7, 30 or 90',
    pass: 'ok',
    fail: utils.isTestingV1() ? 'invalid range set, see --help for command arg details.' : 'bad'
  }, {
    nook: true,
    test: !file || !!json || !!markdown,
    message: 'The `--file` flag is only valid when using `--json` or `--markdown`',
    pass: 'ok',
    fail: 'bad'
  }, {
    nook: true,
    test: !json || !markdown,
    message: 'The `--json` and `--markdown` flags can not be used at the same time',
    pass: 'ok',
    fail: 'bad'
  }, {
    nook: true,
    test: hasApiToken,
    message: 'You need to be logged in to use this command. See `socket login`.',
    pass: 'ok',
    fail: 'missing API token'
  });
  if (!wasValidInput) {
    return;
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$L);
    return;
  }
  return await handleAnalytics({
    scope,
    time: time === '90' || time === 90 ? 90 : time === '30' || time === 30 ? 30 : 7,
    repo: repoName,
    outputKind,
    filePath: String(file || '')
  });
}

async function fetchAuditLog({
  logType,
  orgSlug,
  outputKind,
  page,
  perPage
}) {
  const sockSdkResult = await utils.setupSdk();
  if (!sockSdkResult.ok) {
    return sockSdkResult;
  }
  const sockSdk = sockSdkResult.data;
  return await utils.handleApiCall(sockSdk.getAuditLogEvents(orgSlug, {
    // I'm not sure this is used at all.
    outputJson: String(outputKind === 'json'),
    // I'm not sure this is used at all.
    outputMarkdown: String(outputKind === 'markdown'),
    orgSlug,
    type: logType,
    page: String(page),
    per_page: String(perPage)
  }), `audit log for ${orgSlug}`);
}

const {
  REDACTED
} = constants;
async function outputAuditLog(auditLogs, {
  logType,
  orgSlug,
  outputKind,
  page,
  perPage
}) {
  if (!auditLogs.ok) {
    process.exitCode = auditLogs.code ?? 1;
  }
  if (outputKind === 'json') {
    logger.logger.log(await outputAsJson(auditLogs, {
      logType,
      orgSlug,
      page,
      perPage
    }));
  } else if (outputKind !== 'markdown' && !auditLogs.ok) {
    logger.logger.fail(utils.failMsgWithBadge(auditLogs.message, auditLogs.cause));
  } else {
    logger.logger.log(await outputAsMarkdown(auditLogs, {
      logType,
      orgSlug,
      page,
      perPage
    }));
  }
}
async function outputAsJson(auditLogs, {
  logType,
  orgSlug,
  page,
  perPage
}) {
  if (!auditLogs.ok) {
    return utils.serializeResultJson(auditLogs);
  }
  return utils.serializeResultJson({
    ok: true,
    data: {
      desc: 'Audit logs for given query',
      // Lazily access constants.ENV.VITEST.
      generated: constants.ENV.VITEST ? REDACTED : new Date().toISOString(),
      org: orgSlug,
      logType,
      page,
      nextPage: auditLogs.data.nextPage,
      perPage,
      logs: auditLogs.data.results.map(log => {
        // Note: The subset is pretty arbitrary
        const {
          created_at,
          event_id,
          ip_address,
          type,
          user_agent,
          user_email
        } = log;
        return {
          event_id,
          created_at,
          ip_address,
          type,
          user_agent,
          user_email
        };
      })
    }
  });
}
async function outputAsMarkdown(auditLogs, {
  logType,
  orgSlug,
  page,
  perPage
}) {
  if (!auditLogs.ok) {
    return `
# Socket Audit Logs

There was a problem fetching the audit logs:

> ${auditLogs.message}
${auditLogs.cause ? '>\n' + (auditLogs.cause.split('\n').map(s => `> ${s}\n`).join('') ?? '') : ''}
Parameters:

- org: ${orgSlug}
- type filter: ${logType || '(none)'}
- page: ${page}
- per page: ${perPage}
`;
  }
  try {
    const table = utils.mdTable(auditLogs.data.results, ['event_id', 'created_at', 'type', 'user_email', 'ip_address', 'user_agent']);
    return `
# Socket Audit Logs

These are the Socket.dev audit logs as per requested query.
- org: ${orgSlug}
- type filter: ${logType || '(none)'}
- page: ${page}
- next page: ${auditLogs.data.nextPage}
- per page: ${perPage}
- generated: ${constants.ENV.VITEST ? REDACTED : new Date().toISOString()}

${table}
`;
  } catch (e) {
    process.exitCode = 1;
    logger.logger.fail('There was a problem converting the logs to Markdown, please try the `--json` flag');
    if (debug.isDebug()) {
      debug.debugLog('Error:\n', e);
    }
    // logger.error(e)
    return '';
  }
}

async function handleAuditLog({
  logType,
  orgSlug,
  outputKind,
  page,
  perPage
}) {
  const auditLogs = await fetchAuditLog({
    orgSlug,
    outputKind,
    page,
    perPage,
    logType
  });
  await outputAuditLog(auditLogs, {
    logType,
    orgSlug,
    outputKind,
    page,
    perPage
  });
}

const {
  DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$K,
  SOCKET_WEBSITE_URL: SOCKET_WEBSITE_URL$3
} = constants;
const config$P = {
  commandName: 'audit-log',
  description: 'Look up the audit log for an organization',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags,
    interactive: {
      type: 'boolean',
      default: true,
      description: 'Allow for interactive elements, asking for input. Use --no-interactive to prevent any input questions, defaulting them to cancel/no.'
    },
    org: {
      type: 'string',
      description: 'Force override the organization slug, overrides the default org from config'
    },
    type: {
      type: 'string',
      shortFlag: 't',
      default: '',
      description: 'Type of log event'
    },
    perPage: {
      type: 'number',
      shortFlag: 'pp',
      default: 30,
      description: 'Results per page - default is 30'
    },
    page: {
      type: 'number',
      shortFlag: 'p',
      default: 1,
      description: 'Page number - default is 1'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command} ${utils.isTestingV1() ? '<repo>' : '<org slug>'}

    API Token Requirements
      - Quota: 1 unit
      - Permissions: audit-log:list

    This feature requires an Enterprise Plan. To learn more about getting access
    to this feature and many more, please visit ${SOCKET_WEBSITE_URL$3}/pricing

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command} ${utils.isTestingV1() ? '' : 'FakeOrg'}
  `
};
const cmdAuditLog = {
  description: config$P.description,
  hidden: config$P.hidden,
  run: run$P
};
async function run$P(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$P,
    importMeta,
    parentName
  });
  const {
    dryRun,
    interactive,
    json,
    markdown,
    org: orgFlag,
    page,
    perPage,
    type
  } = cli.flags;
  const outputKind = utils.getOutputKind(json, markdown);
  const logType = String(type || '');
  const [orgSlug] = await utils.determineOrgSlug(String(orgFlag || ''), cli.input[0] || '', !!interactive, !!dryRun);
  const hasApiToken = utils.hasDefaultToken();
  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: true,
    test: !!orgSlug,
    message: utils.isTestingV1() ? 'Org name by default setting, --org, or auto-discovered' : 'Org name must be the first argument',
    pass: 'ok',
    fail: 'missing'
  }, {
    nook: true,
    test: hasApiToken,
    message: 'You need to be logged in to use this command. See `socket login`.',
    pass: 'ok',
    fail: 'missing API token'
  }, {
    nook: true,
    test: !json || !markdown,
    message: 'The `--json` and `--markdown` flags can not be used at the same time',
    pass: 'ok',
    fail: 'bad'
  });
  if (!wasValidInput) {
    return;
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$K);
    return;
  }
  await handleAuditLog({
    orgSlug,
    outputKind,
    page: Number(page || 0),
    perPage: Number(perPage || 0),
    logType: logType.charAt(0).toUpperCase() + logType.slice(1)
  });
}

const {
  NPM: NPM$b,
  NPX: NPX$1,
  PACKAGE_LOCK_JSON,
  PNPM: PNPM$8,
  YARN,
  YARN_LOCK
} = constants;
const nodejsPlatformTypes = new Set(['javascript', 'js', 'nodejs', NPM$b, PNPM$8, 'ts', 'tsx', 'typescript']);
function argvToArray(argv) {
  if (argv['help']) {
    return ['--help'];
  }
  const result = [];
  for (const {
    0: key,
    1: value
  } of Object.entries(argv)) {
    if (key === '_' || key === '--') {
      continue;
    }
    if (key === 'babel' || key === 'install-deps' || key === 'validate') {
      // cdxgen documents no-babel, no-install-deps, and no-validate flags so
      // use them when relevant.
      result.push(`--${value ? key : `no-${key}`}`);
    } else if (value === true) {
      result.push(`--${key}`);
    } else if (typeof value === 'string') {
      result.push(`--${key}`, String(value));
    } else if (Array.isArray(value)) {
      result.push(`--${key}`, ...value.map(String));
    }
  }
  if (argv['--']) {
    result.push('--', ...argv['--']);
  }
  return result;
}
async function runCdxgen(yargvWithYes) {
  let cleanupPackageLock = false;
  const {
    yes,
    ...yargv
  } = {
    __proto__: null,
    ...yargvWithYes
  };
  const yesArgs = yes ? ['--yes'] : [];
  if (yargv.type !== YARN && nodejsPlatformTypes.has(yargv.type) && fs$1.existsSync(`./${YARN_LOCK}`)) {
    if (fs$1.existsSync(`./${PACKAGE_LOCK_JSON}`)) {
      yargv.type = NPM$b;
    } else {
      // Use synp to create a package-lock.json from the yarn.lock,
      // based on the node_modules folder, for a more accurate SBOM.
      try {
        await shadowBin(NPX$1, [...yesArgs,
        // Lazily access constants.ENV.INLINED_SYNP_VERSION.
        `synp@${constants.ENV.INLINED_SYNP_VERSION}`, '--source-file', `./${YARN_LOCK}`]);
        yargv.type = NPM$b;
        cleanupPackageLock = true;
      } catch {}
    }
  }
  await shadowBin(NPX$1, [...yesArgs,
  // Lazily access constants.ENV.INLINED_CYCLONEDX_CDXGEN_VERSION.
  `@cyclonedx/cdxgen@${constants.ENV.INLINED_CYCLONEDX_CDXGEN_VERSION}`, ...argvToArray(yargv)]);
  if (cleanupPackageLock) {
    try {
      await fs$1.promises.rm(`./${PACKAGE_LOCK_JSON}`);
    } catch {}
  }
  const fullOutputPath = path.join(process.cwd(), yargv.output);
  if (fs$1.existsSync(fullOutputPath)) {
    logger.logger.log(vendor.yoctocolorsCjsExports.cyanBright(`${yargv.output} created!`));
  }
}

const {
  DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$J
} = constants;

// TODO: Convert yargs to meow.
const toLower = arg => arg.toLowerCase();
const arrayToLower = arg => arg.map(toLower);

// npx @cyclonedx/cdxgen@11.2.7 --help
//
// Options:
//   -o, --output                 Output file. Default bom.json                                       [default: "bom.json"]
//   -t, --type                   Project type. Please refer to https://cyclonedx.github.io/cdxgen/#/PROJECT_TYPES for supp
//                                orted languages/platforms.                                                        [array]
//       --exclude-type           Project types to exclude. Please refer to https://cyclonedx.github.io/cdxgen/#/PROJECT_TY
//                                PES for supported languages/platforms.
//   -r, --recurse                Recurse mode suitable for mono-repos. Defaults to true. Pass --no-recurse to disable.
//                                                                                                [boolean] [default: true]
//   -p, --print                  Print the SBOM as a table with tree.                                            [boolean]
//   -c, --resolve-class          Resolve class names for packages. jars only for now.                            [boolean]
//       --deep                   Perform deep searches for components. Useful while scanning C/C++ apps, live OS and oci i
//                                mages.                                                                          [boolean]
//       --server-url             Dependency track url. Eg: https://deptrack.cyclonedx.io
//       --skip-dt-tls-check      Skip TLS certificate check when calling Dependency-Track.      [boolean] [default: false]
//       --api-key                Dependency track api key
//       --project-group          Dependency track project group
//       --project-name           Dependency track project name. Default use the directory name
//       --project-version        Dependency track project version                                   [string] [default: ""]
//       --project-id             Dependency track project id. Either provide the id or the project name and version togeth
//                                er                                                                               [string]
//       --parent-project-id      Dependency track parent project id                                               [string]
//       --required-only          Include only the packages with required scope on the SBOM. Would set compositions.aggrega
//                                te to incomplete unless --no-auto-compositions is passed.                       [boolean]
//       --fail-on-error          Fail if any dependency extractor fails.                                         [boolean]
//       --no-babel               Do not use babel to perform usage analysis for JavaScript/TypeScript projects.  [boolean]
//       --generate-key-and-sign  Generate an RSA public/private key pair and then sign the generated SBOM using JSON Web S
//                                ignatures.                                                                      [boolean]
//       --server                 Run cdxgen as a server                                                          [boolean]
//       --server-host            Listen address                                                     [default: "127.0.0.1"]
//       --server-port            Listen port                                                             [default: "9090"]
//       --install-deps           Install dependencies automatically for some projects. Defaults to true but disabled for c
//                                ontainers and oci scans. Use --no-install-deps to disable this feature.
//                                                                                                [boolean] [default: true]
//       --validate               Validate the generated SBOM using json schema. Defaults to true. Pass --no-validate to di
//                                sable.                                                          [boolean] [default: true]
//       --evidence               Generate SBOM with evidence for supported languages.           [boolean] [default: false]
//       --spec-version           CycloneDX Specification version to use. Defaults to 1.6
//                                                                         [number] [choices: 1.4, 1.5, 1.6] [default: 1.6]
//       --filter                 Filter components containing this word in purl or component.properties.value. Multiple va
//                                lues allowed.                                                                     [array]
//       --only                   Include components only containing this word in purl. Useful to generate BOM with first p
//                                arty components alone. Multiple values allowed.                                   [array]
//       --author                 The person(s) who created the BOM. Set this value if you're intending the modify the BOM
//                                and claim authorship.                               [array] [default: "OWASP Foundation"]
//       --profile                BOM profile to use for generation. Default generic.
//   [choices: "appsec", "research", "operational", "threat-modeling", "license-compliance", "generic", "machine-learning",
//                                                        "ml", "deep-learning", "ml-deep", "ml-tiny"] [default: "generic"]
//       --exclude                Additional glob pattern(s) to ignore                                              [array]
//       --include-formulation    Generate formulation section with git metadata and build tools. Defaults to false.
//                                                                                               [boolean] [default: false]
//       --include-crypto         Include crypto libraries as components.                        [boolean] [default: false]
//       --standard               The list of standards which may consist of regulations, industry or organizational-specif
//                                ic standards, maturity models, best practices, or any other requirements which can be eva
//                                luated against or attested to.
//   [array] [choices: "asvs-5.0", "asvs-4.0.3", "bsimm-v13", "masvs-2.0.0", "nist_ssdf-1.1", "pcissc-secure-slc-1.1", "scv
//                                                                                          s-1.0.0", "ssaf-DRAFT-2023-11"]
//       --json-pretty            Pretty-print the generated BOM json.                           [boolean] [default: false]
//       --min-confidence         Minimum confidence needed for the identity of a component from 0 - 1, where 1 is 100% con
//                                fidence.                                                            [number] [default: 0]
//       --technique              Analysis technique to use
//   [array] [choices: "auto", "source-code-analysis", "binary-analysis", "manifest-analysis", "hash-comparison", "instrume
//                                                                                                    ntation", "filename"]
//       --auto-compositions      Automatically set compositions when the BOM was filtered. Defaults to true
//                                                                                                [boolean] [default: true]
//   -h, --help                   Show help                                                                       [boolean]
//   -v, --version                Show version number                                                             [boolean]

// isSecureMode defined at:
// https://github.com/CycloneDX/cdxgen/blob/v11.2.7/lib/helpers/utils.js#L66
// const isSecureMode =
//   ['true', '1'].includes(process.env?.CDXGEN_SECURE_MODE) ||
//   process.env?.NODE_OPTIONS?.includes('--permission')

// Yargs CDXGEN configuration defined at:
// https://github.com/CycloneDX/cdxgen/blob/v11.2.7/bin/cdxgen.js#L64
const yargsConfig = {
  configuration: {
    'camel-case-expansion': false,
    'greedy-arrays': false,
    'parse-numbers': false,
    'populate--': true,
    'short-option-groups': false,
    'strip-aliased': true,
    'unknown-options-as-args': true
  },
  coerce: {
    'exclude-type': arrayToLower,
    'feature-flags': arrayToLower,
    filter: arrayToLower,
    only: arrayToLower,
    profile: toLower,
    standard: arrayToLower,
    technique: arrayToLower,
    type: arrayToLower
  },
  default: {
    //author: ['OWASP Foundation'],
    //'auto-compositions': true,
    //babel: true,
    //banner: false, // hidden
    //'deps-slices-file': 'deps.slices.json', // hidden
    //evidence: false,
    //'exclude-type': [],
    //'export-proto': true, // hidden
    //'fail-on-error': isSecureMode,
    //'feature-flags': [], // hidden
    //'include-crypto': false,
    //'include-formulation': false,
    //'install-deps': !isSecureMode
    //lifecycle: 'build', // hidden
    //'min-confidence': '0',
    //output: 'bom.json',
    //profile: 'generic',
    //'project-version': '',
    //'proto-bin-file': 'bom.cdx', // hidden
    //recurse: true,
    //'skip-dt-tls-check': false,
    //'semantics-slices-file': 'semantics.slices.json',
    //'server-host': '127.0.0.1',
    //'server-port': '9090',
    //'spec-version': '1.6',
    type: ['js']
    //validate: true,
  },
  alias: {
    help: ['h'],
    output: ['o'],
    print: ['p'],
    recurse: ['r'],
    'resolve-class': ['c'],
    type: ['t'],
    version: ['v'],
    yes: ['y']
  },
  array: [{
    key: 'author',
    type: 'string'
  }, {
    key: 'exclude',
    type: 'string'
  }, {
    key: 'exclude-type',
    type: 'string'
  }, {
    key: 'feature-flags',
    type: 'string'
  },
  // hidden
  {
    key: 'filter',
    type: 'string'
  }, {
    key: 'only',
    type: 'string'
  }, {
    key: 'standard',
    type: 'string'
  }, {
    key: 'technique',
    type: 'string'
  }, {
    key: 'type',
    type: 'string'
  }],
  boolean: ['auto-compositions', 'babel', 'banner',
  // hidden
  'deep', 'evidence', 'export-proto',
  // hidden
  'fail-on-error', 'generate-key-and-sign', 'help', 'include-crypto', 'include-formulation', 'install-deps', 'json-pretty', 'print', 'recurse', 'required-only', 'resolve-class', 'skip-dt-tls-check', 'server', 'validate', 'version',
  // The --yes flag and -y alias map to the corresponding flag and alias of npx.
  // https://docs.npmjs.com/cli/v7/commands/npx#compatibility-with-older-npx-versions
  'yes'],
  string: ['api-key', 'data-flow-slices-file',
  // hidden
  'deps-slices-file',
  // hidden
  'evinse-output',
  // hidden
  'lifecycle', 'min-confidence',
  // number
  'openapi-spec-file',
  // hidden
  'output', 'parent-project-id', 'profile', 'project-group', 'project-name', 'project-version', 'project-id', 'proto-bin-file',
  // hidden
  'reachables-slices-file',
  // hidden
  'semantics-slices-file',
  // hidden
  'server-host', 'server-port', 'server-url', 'spec-version',
  // number
  'usages-slices-file' // hidden
  ]
};
const config$O = {
  commandName: 'cdxgen',
  description: 'Create an SBOM with CycloneDX generator (cdxgen)',
  hidden: false,
  // Stub out flags and help.
  // TODO: Convert yargs to meow.
  flags: {},
  help: () => ''
};
const cmdManifestCdxgen = {
  description: config$O.description,
  hidden: config$O.hidden,
  run: run$O
};
async function run$O(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    allowUnknownFlags: true,
    // Don't let meow take over --help.
    argv: argv.filter(a => !utils.isHelpFlag(a)),
    config: config$O,
    importMeta,
    parentName
  });

  // TODO: Convert yargs to meow.
  const yargv = {
    ...vendor.yargsParser(argv, yargsConfig)
  };
  const unknown = yargv._;
  const {
    length: unknownLength
  } = unknown;
  if (unknownLength) {
    // Use exit status of 2 to indicate incorrect usage, generally invalid
    // options or missing arguments.
    // https://www.gnu.org/software/bash/manual/html_node/Exit-Status.html
    process.exitCode = 2;
    logger.logger.fail(`Unknown ${words.pluralize('argument', unknownLength)}: ${yargv._.join(', ')}`);
    return;
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$J);
    return;
  }

  // Change defaults when not passing the --help flag.
  if (!yargv.help) {
    // Make 'lifecycle' default to 'pre-build', which also sets 'install-deps' to `false`,
    // to avoid arbitrary code execution on the cdxgen scan.
    // https://github.com/CycloneDX/cdxgen/issues/1328
    if (yargv.lifecycle === undefined) {
      yargv.lifecycle = 'pre-build';
      yargv['install-deps'] = false;
      logger.logger.info(`Socket set cdxgen --lifecycle to "${yargv.lifecycle}" to avoid arbitrary code execution on this scan.\n  Pass "--lifecycle build" to generate a BOM consisting of information obtained during the build process.\n  See cdxgen ${vendor.terminalLinkExports('BOM lifecycles documentation', 'https://cyclonedx.github.io/cdxgen/#/ADVANCED?id=bom-lifecycles')} for more details.\n`);
    }
    if (yargv.output === undefined) {
      yargv.output = 'socket-cdx.json';
    }
  }
  await runCdxgen(yargv);
}

async function handleCdxgen(argv, importMeta, {
  parentName
}) {
  await cmdManifestCdxgen.run(argv, importMeta, {
    parentName
  });
}

const config$N = {
  description: 'Create an SBOM with CycloneDX generator (cdxgen)',
  hidden: true};
const cmdCdxgen = {
  description: config$N.description,
  hidden: config$N.hidden,
  run: run$N
};
async function run$N(argv, importMeta, {
  parentName
}) {
  logger.logger.warn('Warning: The `socket cdxgen` command moved to `socket manifest cdxgen` and will be removed as a toplevel command in the next major bump.');
  await handleCdxgen(argv, importMeta, {
    parentName
  });
}

// Use the config defaultOrg when set, otherwise discover from remote
async function getDefaultOrgSlug() {
  const defaultOrgResult = utils.getConfigValueOrUndef('defaultOrg');
  if (defaultOrgResult) {
    debug.debugLog(`Using default org: ${defaultOrgResult}`);
    return {
      ok: true,
      data: defaultOrgResult
    };
  }
  const sockSdkResult = await utils.setupSdk();
  if (!sockSdkResult.ok) {
    return sockSdkResult;
  }
  const sockSdk = sockSdkResult.data;
  const result = await utils.handleApiCall(sockSdk.getOrganizations(), 'list of organizations');
  if (!result.ok) {
    return result;
  }
  const orgs = result.data.organizations;
  const keys = Object.keys(orgs);
  if (!keys[0]) {
    return {
      ok: false,
      message: 'Failed to establish identity',
      data: `API did not return any organization associated with the current API token. Unable to continue.`
    };
  }
  const slug = (keys[0] in orgs && orgs?.[keys[0]]?.name) ?? undefined;
  if (!slug) {
    return {
      ok: false,
      message: 'Failed to establish identity',
      data: `Was unable to determine the default organization for the current API token. Unable to continue.`
    };
  }
  debug.debugLog(`Resolved org to: ${slug}`);
  return {
    ok: true,
    message: 'Retrieved default org from server',
    data: slug
  };
}

async function fetchCreateOrgFullScan(packagePaths, orgSlug, defaultBranch, pendingHead, tmp, cwd, {
  branchName,
  commitHash,
  commitMessage,
  committers,
  pullRequest,
  repoName
}) {
  const sockSdkResult = await utils.setupSdk();
  if (!sockSdkResult.ok) {
    return sockSdkResult;
  }
  const sockSdk = sockSdkResult.data;
  return await utils.handleApiCall(sockSdk.createOrgFullScan(orgSlug, {
    ...(branchName ? {
      branch: branchName
    } : {}),
    ...(commitHash ? {
      commit_hash: commitHash
    } : {}),
    ...(commitMessage ? {
      commit_message: commitMessage
    } : {}),
    ...(committers ? {
      committers
    } : {}),
    make_default_branch: String(defaultBranch),
    ...(pullRequest ? {
      pull_request: String(pullRequest)
    } : {}),
    repo: repoName || 'socket-default-repository',
    // mandatory, this is server default for repo
    set_as_pending_head: String(pendingHead),
    tmp: String(tmp)
  }, packagePaths, cwd), 'to create a scan');
}

async function fetchSupportedScanFileNames() {
  const sockSdkResult = await utils.setupSdk();
  if (!sockSdkResult.ok) {
    return sockSdkResult;
  }
  const sockSdk = sockSdkResult.data;
  return await utils.handleApiCall(sockSdk.getReportSupportedFiles(), 'supported scan file types');
}

/**
 * This fetches all the relevant pieces of data to generate a report, given a
 * full scan ID.
 */
async function fetchReportData(orgSlug, scanId, includeLicensePolicy) {
  const sockSdkResult = await utils.setupSdk();
  if (!sockSdkResult.ok) {
    return sockSdkResult;
  }
  const sockSdk = sockSdkResult.data;
  let scanStatus = 'requested..';
  let policyStatus = 'requested..';
  let finishedFetching = false;

  // Lazily access constants.spinner.
  const {
    spinner
  } = constants;
  function updateScan(desc) {
    scanStatus = desc;
    updateProgress();
  }
  function updatePolicy(desc) {
    policyStatus = desc;
    updateProgress();
  }
  function updateProgress() {
    if (finishedFetching) {
      spinner.stop();
      logger.logger.info(`Scan result: ${scanStatus}. Security policy: ${policyStatus}.`);
    } else {
      spinner.start(`Scan result: ${scanStatus}. Security policy: ${policyStatus}.`);
    }
  }
  async function fetchScanResult() {
    const result = await utils.queryApiSafeText(`orgs/${orgSlug}/full-scans/${encodeURIComponent(scanId)}${includeLicensePolicy ? '?include_license_details=true' : ''}`);
    updateScan(`response received`);
    if (!result.ok) {
      return result;
    }
    const jsonsString = result.data;

    // This is nd-json; each line is a json object
    const lines = jsonsString.split('\n').filter(Boolean);
    let ok = true;
    const data = lines.map(line => {
      try {
        return JSON.parse(line);
      } catch {
        ok = false;
        debug.debugLog('ndjson failed to parse the following line:');
        debug.debugLog(line);
        return;
      }
    });
    if (ok) {
      updateScan(`success`);
      return {
        ok: true,
        data
      };
    }
    updateScan(`received invalid JSON response`);
    return {
      ok: false,
      message: 'Invalid API response',
      cause: 'The API responded with at least one line that was not valid JSON. Please report if this persists.'
    };
  }
  async function fetchSecurityPolicy() {
    const result = await utils.handleApiCallNoSpinner(sockSdk.getOrgSecurityPolicy(orgSlug), 'GetOrgSecurityPolicy');
    updatePolicy('received policy');
    return result;
  }
  updateProgress();
  const [scan, securityPolicy] = await Promise.all([fetchScanResult().catch(e => {
    updateScan(`failure; unknown blocking problem occurred`);
    return {
      ok: false,
      message: 'Unexpected API problem',
      cause: `We encountered an unexpected problem while requesting the Scan from the API: ${e?.message || '(no error message found)'}${e?.cause ? ` (cause: ${e.cause})` : ''}`
    };
  }), fetchSecurityPolicy().catch(e => {
    updatePolicy(`failure; unknown blocking problem occurred`);
    return {
      ok: false,
      message: 'Unexpected API problem',
      cause: `We encountered an unexpected problem while requesting the policy from the API: ${e?.message || '(no error message found)'}${e?.cause ? ` (cause: ${e.cause})` : ''}`
    };
  })]).finally(() => {
    finishedFetching = true;
    updateProgress();
  });
  if (!scan.ok) {
    return scan;
  }
  if (!securityPolicy.ok) {
    return securityPolicy;
  }
  if (!Array.isArray(scan.data)) {
    return {
      ok: false,
      message: 'Failed to fetch',
      cause: 'Was unable to fetch scan result, bailing'
    };
  }
  return {
    ok: true,
    data: {
      scan: scan.data,
      securityPolicy: securityPolicy.data
    }
  };
}

// Note: The returned cresult will only be ok:false when the generation
//       failed. It won't reflect the healthy state.
function generateReport(scan, securityPolicy, {
  fold,
  orgSlug,
  reportLevel,
  scanId,
  short,
  spinner
}) {
  const now = Date.now();
  spinner?.start('Generating report...');

  // Create an object that includes:
  //   healthy: boolean
  //   worst violation level;
  //   per eco
  //     per package
  //       per version
  //         per offending file
  //           reported issue -> policy action

  // In the context of a report;
  // - the alert.severity is irrelevant
  // - the securityPolicyDefault is irrelevant
  // - the report defaults to healthy:true with no alerts
  // - the appearance of an alert will trigger the policy action;
  //   - error: healthy will end up as false, add alerts to report
  //   - warn: healthy unchanged, add alerts to report
  //   - monitor/ignore: no action
  //   - defer: unknown (no action)

  // Note: the server will emit alerts for license policy violations but
  //       those are only included if you set the flag when requesting the scan
  //       data. The alerts map to a single security policy key that determines
  //       what to do with any violation, regardless of the concrete license.
  //       That rule is called "License Policy Violation".
  // The license policy part is implicitly handled here. Either they are
  // included and may show up, or they are not and won't show up.

  const violations = new Map();
  let healthy = true;
  const securityRules = securityPolicy.securityPolicyRules;
  if (securityRules) {
    // Note: reportLevel: error > warn > monitor > ignore > defer
    scan.forEach(artifact => {
      const {
        alerts,
        name: pkgName = '<unknown>',
        type: ecosystem,
        version = '<unknown>'
      } = artifact;
      alerts?.forEach(alert => {
        const alertName = alert.type; // => policy[type]
        const action = securityRules[alertName]?.action || '';
        switch (action) {
          case 'error':
            {
              healthy = false;
              if (!short) {
                addAlert(artifact, violations, fold, ecosystem, pkgName, version, alert, action);
              }
              break;
            }
          case 'warn':
            {
              if (!short && reportLevel !== 'error') {
                addAlert(artifact, violations, fold, ecosystem, pkgName, version, alert, action);
              }
              break;
            }
          case 'monitor':
            {
              if (!short && reportLevel !== 'warn' && reportLevel !== 'error') {
                addAlert(artifact, violations, fold, ecosystem, pkgName, version, alert, action);
              }
              break;
            }
          case 'ignore':
            {
              if (!short && reportLevel !== 'warn' && reportLevel !== 'error' && reportLevel !== 'monitor') {
                addAlert(artifact, violations, fold, ecosystem, pkgName, version, alert, action);
              }
              break;
            }
          case 'defer':
            {
              // Not sure but ignore for now. Defer to later ;)
              if (!short && reportLevel === 'defer') {
                addAlert(artifact, violations, fold, ecosystem, pkgName, version, alert, action);
              }
              break;
            }
        }
      });
    });
  }
  spinner?.successAndStop(`Generated reported in ${Date.now() - now} ms`);
  if (short) {
    return {
      ok: true,
      data: {
        healthy
      }
    };
  }
  const report = {
    healthy,
    orgSlug,
    scanId,
    options: {
      fold,
      reportLevel
    },
    alerts: violations
  };
  if (!healthy) {
    return {
      ok: true,
      message: 'The report contains at least one alert that violates the policies set by your organization',
      data: report
    };
  }
  return {
    ok: true,
    data: report
  };
}
function createLeaf(art, alert, policyAction) {
  const leaf = {
    type: alert.type,
    policy: policyAction,
    url: utils.getSocketDevPackageOverviewUrlFromPurl(art),
    manifest: art.manifestFiles?.map(obj => obj.file) ?? []
  };
  return leaf;
}
function addAlert(art, violations, foldSetting, ecosystem, pkgName, version, alert, policyAction) {
  if (!violations.has(ecosystem)) {
    violations.set(ecosystem, new Map());
  }
  const ecomap = violations.get(ecosystem);
  if (foldSetting === 'pkg') {
    const existing = ecomap.get(pkgName);
    if (!existing || isStricterPolicy(existing.policy, policyAction)) {
      ecomap.set(pkgName, createLeaf(art, alert, policyAction));
    }
  } else {
    if (!ecomap.has(pkgName)) {
      ecomap.set(pkgName, new Map());
    }
    const pkgmap = ecomap.get(pkgName);
    if (foldSetting === 'version') {
      const existing = pkgmap.get(version);
      if (!existing || isStricterPolicy(existing.policy, policyAction)) {
        pkgmap.set(version, createLeaf(art, alert, policyAction));
      }
    } else {
      if (!pkgmap.has(version)) {
        pkgmap.set(version, new Map());
      }
      const file = alert.file || '<unknown>';
      const vermap = pkgmap.get(version);
      if (foldSetting === 'file') {
        const existing = vermap.get(file);
        if (!existing || isStricterPolicy(existing.policy, policyAction)) {
          vermap.set(file, createLeaf(art, alert, policyAction));
        }
      } else {
        if (!vermap.has(file)) {
          vermap.set(file, new Map());
        }
        const key = `${alert.type} at ${alert.start}:${alert.end}`;
        const filemap = vermap.get(file);
        const existing = filemap.get(key);
        if (!existing || isStricterPolicy(existing.policy, policyAction)) {
          filemap.set(key, createLeaf(art, alert, policyAction));
        }
      }
    }
  }
}
function isStricterPolicy(was, is) {
  // error > warn > monitor > ignore > defer > {unknown}
  if (was === 'error') {
    return false;
  }
  if (is === 'error') {
    return true;
  }
  if (was === 'warn') {
    return false;
  }
  if (is === 'warn') {
    return false;
  }
  if (was === 'monitor') {
    return false;
  }
  if (is === 'monitor') {
    return false;
  }
  if (was === 'ignore') {
    return false;
  }
  if (is === 'ignore') {
    return false;
  }
  if (was === 'defer') {
    return false;
  }
  if (is === 'defer') {
    return false;
  }
  // unreachable?
  return false;
}

async function outputScanReport(result, {
  filePath,
  fold,
  includeLicensePolicy,
  orgSlug,
  outputKind,
  reportLevel,
  scanId,
  short
}) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (!result.ok) {
    if (outputKind === 'json') {
      logger.logger.log(utils.serializeResultJson(result));
      return;
    }
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  const scanReport = generateReport(result.data.scan, result.data.securityPolicy, {
    orgSlug,
    scanId,
    fold,
    reportLevel,
    short,
    // Lazily access constants.spinner.
    spinner: constants.spinner
  });
  if (!scanReport.ok) {
    // Note: this means generation failed, it does not reflect the healthy state
    process.exitCode = scanReport.code ?? 1;

    // If report generation somehow failed then .data should not be set.
    if (outputKind === 'json') {
      logger.logger.log(utils.serializeResultJson(scanReport));
      return;
    }
    logger.logger.fail(utils.failMsgWithBadge(scanReport.message, scanReport.cause));
    return;
  }

  // I don't think we emit the default error message with banner for an unhealhty report, do we?
  // if (!scanReport.data.healhty) {
  //   logger.fail(failMsgWithBadge(scanReport.message, scanReport.cause))
  //   return
  // }

  if (outputKind === 'json' || outputKind === 'text' && filePath && filePath.endsWith('.json')) {
    const json = short ? utils.serializeResultJson(scanReport) : toJsonReport(scanReport.data, includeLicensePolicy);
    if (filePath && filePath !== '-') {
      logger.logger.log('Writing json report to', filePath);
      return await fs.writeFile(filePath, json);
    }
    logger.logger.log(json);
    return;
  }
  if (outputKind === 'markdown' || filePath && filePath.endsWith('.md')) {
    const md = short ? `healthy = ${scanReport.data.healthy}` : toMarkdownReport(scanReport.data,
    // not short so must be regular report
    includeLicensePolicy);
    if (filePath && filePath !== '-') {
      logger.logger.log('Writing markdown report to', filePath);
      return await fs.writeFile(filePath, md);
    }
    logger.logger.log(md);
    logger.logger.log('');
    return;
  }
  if (short) {
    logger.logger.log(scanReport.data.healthy ? 'OK' : 'ERR');
  } else {
    logger.logger.dir(scanReport.data, {
      depth: null
    });
  }
}
function toJsonReport(report, includeLicensePolicy) {
  const obj = utils.mapToObject(report.alerts);
  const newReport = {
    includeLicensePolicy,
    ...report,
    alerts: obj
  };
  return utils.serializeResultJson({
    ok: true,
    data: newReport
  });
}
function toMarkdownReport(report, includeLicensePolicy) {
  const flatData = Array.from(utils.walkNestedMap(report.alerts)).map(({
    keys,
    value
  }) => {
    const {
      manifest,
      policy,
      type,
      url
    } = value;
    return {
      'Alert Type': type,
      Package: keys[1] || '<unknown>',
      'Introduced by': keys[2] || '<unknown>',
      url,
      'Manifest file': manifest.join(', '),
      Policy: policy
    };
  });
  const md = `
# Scan Policy Report

This report tells you whether the results of a Socket scan results violate the
security${includeLicensePolicy ? ' or license' : ''} policy set by your organization.

## Health status

${report.healthy ? `The scan *PASSES* all requirements set by your security${includeLicensePolicy ? ' and license' : ''} policy.` : 'The scan *VIOLATES* one or more policies set to the "error" level.'}

## Settings

Configuration used to generate this report:

- Organization: ${report.orgSlug}
- Scan ID: ${report.scanId}
- Alert folding: ${report.options.fold === 'none' ? 'none' : `up to ${report.options.fold}`}
- Minimal policy level for alert to be included in report: ${report.options.reportLevel === 'defer' ? 'everything' : report.options.reportLevel}
- Include license alerts: ${includeLicensePolicy ? 'yes' : 'no'}

## Alerts

${report.alerts.size ? `All the alerts from the scan with a policy set to at least "${report.options.reportLevel}".` : `The scan contained no alerts with a policy set to at least "${report.options.reportLevel}".`}

${!report.alerts.size ? '' : utils.mdTable(flatData, ['Policy', 'Alert Type', 'Package', 'Introduced by', 'url', 'Manifest file'])}
  `.trim() + '\n';
  return md;
}

async function handleScanReport({
  filePath,
  fold,
  includeLicensePolicy,
  orgSlug,
  outputKind,
  reportLevel,
  scanId,
  short
}) {
  const result = await fetchReportData(orgSlug, scanId, includeLicensePolicy);
  await outputScanReport(result, {
    filePath,
    fold,
    scanId: scanId,
    includeLicensePolicy,
    orgSlug,
    outputKind,
    reportLevel,
    short
  });
}

async function outputCreateNewScan(result, outputKind, interactive) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result));
    return;
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  if (!result.data.id) {
    logger.logger.fail('Did not receive a scan ID from the API...');
    process.exitCode = 1;
  }
  if (outputKind === 'markdown') {
    logger.logger.log('# Create New Scan');
    logger.logger.log('');
    if (result.data.id) {
      logger.logger.log(`A [new Scan](${result.data.html_report_url}) was created with ID: ${result.data.id}`);
      logger.logger.log('');
    } else {
      logger.logger.log(`The server did not return a Scan ID while trying to create a new Scan. This could be an indication something went wrong.`);
    }
    logger.logger.log('');
    return;
  }
  const link = vendor.yoctocolorsCjsExports.underline(vendor.yoctocolorsCjsExports.cyan(`${result.data.html_report_url}`));
  logger.logger.log(`Available at: ${link}`);
  if (interactive && (await prompts.confirm({
    message: 'Would you like to open it in your browser?',
    default: false
  }))) {
    await vendor.open(`${result.data.html_report_url}`);
  }
}

// The point here is to attempt to detect the various supported manifest files
// the CLI can generate. This would be environments that we can't do server side

async function detectManifestActions(cwd = process.cwd()) {
  const output = {
    cdxgen: false,
    // TODO
    count: 0,
    conda: false,
    gradle: false,
    sbt: false
  };
  if (fs$1.existsSync(path.join(cwd, 'build.sbt'))) {
    debug.debugLog('Detected a Scala sbt build, running default Scala generator...');
    output.sbt = true;
    output.count += 1;
  }
  if (fs$1.existsSync(path.join(cwd, 'gradlew'))) {
    debug.debugLog('Detected a gradle build, running default gradle generator...');
    output.gradle = true;
    output.count += 1;
  }
  const envyml = path.join(cwd, 'environment.yml');
  const hasEnvyml = fs$1.existsSync(envyml);
  const envyaml = path.join(cwd, 'environment.yaml');
  const hasEnvyaml = !hasEnvyml && fs$1.existsSync(envyaml);
  if (hasEnvyml || hasEnvyaml) {
    debug.debugLog('Detected an environment.yml file, running default Conda generator...');
    output.conda = true;
    output.count += 1;
  }
  return output;
}

async function convertGradleToMaven(target, bin, cwd, verbose, gradleOpts) {
  // TODO: impl json/md
  if (verbose) {
    logger.logger.log('[VERBOSE] Resolving:', [cwd, bin]);
  }
  const rBin = path.resolve(cwd, bin);
  if (verbose) {
    logger.logger.log('[VERBOSE] Resolving:', [cwd, target]);
  }
  const rTarget = path.resolve(cwd, target);
  const binExists = fs$1.existsSync(rBin);
  const targetExists = fs$1.existsSync(rTarget);
  logger.logger.group('gradle2maven:');
  if (verbose || debug.isDebug()) {
    logger.logger.log(`[VERBOSE] - Absolute bin path: \`${rBin}\` (${binExists ? 'found' : vendor.yoctocolorsCjsExports.red('not found!')})`);
    logger.logger.log(`[VERBOSE] - Absolute target path: \`${rTarget}\` (${targetExists ? 'found' : vendor.yoctocolorsCjsExports.red('not found!')})`);
  } else {
    logger.logger.log(`- executing: \`${rBin}\``);
    if (!binExists) {
      logger.logger.warn('Warning: It appears the executable could not be found at this location. An error might be printed later because of that.');
    }
    logger.logger.log(`- src dir: \`${rTarget}\``);
    if (!targetExists) {
      logger.logger.warn('Warning: It appears the src dir could not be found at this location. An error might be printed later because of that.');
    }
  }
  logger.logger.groupEnd();
  try {
    // Run gradlew with the init script we provide which should yield zero or more
    // pom files. We have to figure out where to store those pom files such that
    // we can upload them and predict them through the GitHub API. We could do a
    // .socket folder. We could do a socket.pom.gz with all the poms, although
    // I'd prefer something plain-text if it is to be committed.
    // Note: init.gradle will be exported by .config/rollup.dist.config.mjs
    const initLocation = path.join(constants.distPath, 'init.gradle');
    const commandArgs = ['--init-script', initLocation, ...gradleOpts, 'pom'];
    if (verbose) {
      logger.logger.log('[VERBOSE] Executing:', [bin], ', args:', commandArgs);
    }
    logger.logger.log(`Converting gradle to maven from \`${bin}\` on \`${target}\` ...`);
    const output = await execGradleWithSpinner(rBin, commandArgs, rTarget, cwd);
    if (verbose) {
      logger.logger.group('[VERBOSE] gradle stdout:');
      logger.logger.log(output);
      logger.logger.groupEnd();
    }
    if (output.code !== 0) {
      process.exitCode = 1;
      logger.logger.fail(`Gradle exited with exit code ${output.code}`);
      // (In verbose mode, stderr was printed above, no need to repeat it)
      if (!verbose) {
        logger.logger.group('stderr:');
        logger.logger.error(output.stderr);
        logger.logger.groupEnd();
      }
      return;
    }
    logger.logger.success('Executed gradle successfully');
    logger.logger.log('Reported exports:');
    output.stdout.replace(/^POM file copied to: (.*)/gm, (_all, fn) => {
      logger.logger.log('- ', fn);
      return fn;
    });
    logger.logger.log('');
    logger.logger.log('Next step is to generate a Scan by running the `socket scan create` command on the same directory');
  } catch (e) {
    process.exitCode = 1;
    logger.logger.fail('There was an unexpected error while generating manifests' + (verbose ? '' : '  (use --verbose for details)'));
    if (verbose) {
      logger.logger.group('[VERBOSE] error:');
      logger.logger.log(e);
      logger.logger.groupEnd();
    }
  }
}
async function execGradleWithSpinner(bin, commandArgs, target, cwd) {
  // Lazily access constants.spinner.
  const {
    spinner
  } = constants;
  let pass = false;
  try {
    spinner.start(`Running gradlew... (this can take a while, it depends on how long gradlew has to run)`);
    const output = await spawn.spawn(bin, commandArgs, {
      // We can pipe the output through to have the user see the result
      // of running gradlew, but then we can't (easily) gather the output
      // to discover the generated files... probably a flag we should allow?
      // stdio: isDebug() ? 'inherit' : undefined,
      cwd: target || cwd
    });
    pass = true;
    const {
      code,
      stderr,
      stdout
    } = output;
    return {
      code,
      stdout,
      stderr
    };
  } finally {
    if (pass) {
      spinner.successAndStop('Completed gradlew execution');
    } else {
      spinner.failAndStop('There was an error while trying to run gradlew.');
    }
  }
}

async function convertSbtToMaven(target, bin, out, verbose, sbtOpts) {
  // TODO: impl json/md

  // Lazily access constants.spinner.
  const {
    spinner
  } = constants;
  const rBin = path.resolve(bin);
  const rTarget = path.resolve(target);
  if (verbose) {
    logger.logger.group('sbt2maven:');
    logger.logger.log(`[VERBOSE] - Absolute bin path: \`${rBin}\``);
    logger.logger.log(`[VERBOSE] - Absolute target path: \`${rTarget}\``);
    // logger.log(`[VERBOSE] - Absolute out path: \`${rout}\``)
    logger.logger.groupEnd();
  } else {
    logger.logger.group('sbt2maven:');
    logger.logger.log(`- executing: \`${bin}\``);
    logger.logger.log(`- src dir: \`${target}\``);
    // logger.log(`- dst dir: \`${out}\``)
    logger.logger.groupEnd();
  }
  try {
    spinner.start(`Converting sbt to maven from \`${bin}\` on \`${target}\`...`);

    // Run sbt with the init script we provide which should yield zero or more
    // pom files. We have to figure out where to store those pom files such that
    // we can upload them and predict them through the GitHub API. We could do a
    // .socket folder. We could do a socket.pom.gz with all the poms, although
    // I'd prefer something plain-text if it is to be committed.
    const output = await spawn.spawn(bin, ['makePom', ...sbtOpts], {
      cwd: target || process.cwd()
    });
    spinner.stop();
    if (verbose) {
      logger.logger.group('[VERBOSE] sbt stdout:');
      logger.logger.log(output);
      logger.logger.groupEnd();
    }
    if (output.stderr) {
      process.exitCode = 1;
      logger.logger.fail('There were errors while running sbt');
      // (In verbose mode, stderr was printed above, no need to repeat it)
      if (!verbose) {
        logger.logger.group('[VERBOSE] stderr:');
        logger.logger.error(output.stderr);
        logger.logger.groupEnd();
      }
      return;
    }
    const poms = [];
    output.stdout.replace(/Wrote (.*?.pom)\n/g, (_all, fn) => {
      poms.push(fn);
      return fn;
    });
    if (!poms.length) {
      process.exitCode = 1;
      logger.logger.fail('There were no errors from sbt but it seems to not have generated any poms either');
      return;
    }
    // Move the pom file to ...? initial cwd? loc will be an absolute path, or dump to stdout
    // TODO: what to do with multiple output files? Do we want to dump them to stdout? Raw or with separators or ?
    // TODO: maybe we can add an option to target a specific file to dump to stdout
    if (out === '-' && poms.length === 1) {
      logger.logger.log('Result:\n```');
      logger.logger.log(await utils.safeReadFile(poms[0]));
      logger.logger.log('```');
      logger.logger.success(`OK`);
    } else if (out === '-') {
      process.exitCode = 1;
      logger.logger.fail('Requested out target was stdout but there are multiple generated files');
      poms.forEach(fn => logger.logger.error('-', fn));
      logger.logger.info('Exiting now...');
      return;
    } else {
      // if (verbose) {
      //   logger.log(
      //     `Moving manifest file from \`${loc.replace(/^\/home\/[^/]*?\//, '~/')}\` to \`${out}\``
      //   )
      // } else {
      //   logger.log('Moving output pom file')
      // }
      // TODO: do we prefer fs-extra? renaming can be gnarly on windows and fs-extra's version is better
      // await renamep(loc, out)
      logger.logger.success(`Generated ${poms.length} pom files`);
      poms.forEach(fn => logger.logger.log('-', fn));
      logger.logger.success(`OK`);
    }
  } catch (e) {
    process.exitCode = 1;
    spinner.stop();
    logger.logger.fail('There was an unexpected error while running this' + (verbose ? '' : ' (use --verbose for details)'));
    if (verbose) {
      logger.logger.group('[VERBOSE] error:');
      logger.logger.log(e);
      logger.logger.groupEnd();
    }
  }
}

async function convertCondaToRequirements(target, cwd, verbose) {
  let contents;
  if (target === '-') {
    if (verbose) {
      logger.logger.info(`[VERBOSE] reading input from stdin`);
    }
    const buf = [];
    contents = await new Promise((resolve, reject) => {
      process.stdin.on('data', chunk => {
        const input = chunk.toString();
        buf.push(input);
      });
      process.stdin.on('end', () => {
        resolve(buf.join(''));
      });
      process.stdin.on('error', e => {
        if (verbose) {
          logger.logger.error('Unexpected error while reading from stdin:', e);
        }
        reject(e);
      });
      process.stdin.on('close', () => {
        if (buf.length === 0) {
          if (verbose) {
            logger.logger.error('stdin closed explicitly without data received');
          }
          reject(new Error('No data received from stdin'));
        } else {
          if (verbose) {
            logger.logger.error('warning: stdin closed explicitly with some data received');
          }
          resolve(buf.join(''));
        }
      });
    });
    if (!contents) {
      return {
        ok: false,
        message: 'Manifest Generation Failed',
        cause: 'No data received from stdin'
      };
    }
  } else {
    const f = path.resolve(cwd, target);
    if (verbose) {
      logger.logger.info(`[VERBOSE] target file: ${f}`);
    }
    if (!fs$1.existsSync(f)) {
      return {
        ok: false,
        message: 'Manifest Generation Failed',
        cause: `Input file not found at ${f}`
      };
    }
    contents = fs$1.readFileSync(target, 'utf8');
    if (!contents) {
      return {
        ok: false,
        message: 'Manifest Generation Failed',
        cause: 'File is empty'
      };
    }
  }
  return {
    ok: true,
    data: {
      contents,
      pip: convertCondaToRequirementsFromInput(contents)
    }
  };
}

// Just extract the first pip block, if one exists at all.
function convertCondaToRequirementsFromInput(input) {
  const keeping = [];
  let collecting = false;
  let delim = '-';
  let indent = '';
  input.split('\n').some(line => {
    if (!line) {
      // Ignore empty lines
      return;
    }
    if (collecting) {
      if (line.startsWith('#')) {
        // Ignore comment lines (keep?)
        return;
      }
      if (line.startsWith(delim)) {
        // In this case we have a line with the same indentation as the
        // `- pip:` line, so we have reached the end of the pip block.
        return true; // the end
      } else {
        if (!indent) {
          // Store the indentation of the block
          if (line.trim().startsWith('-')) {
            indent = line.split('-')[0] + '-';
            if (indent.length <= delim.length) {
              // The first line after the `pip:` line does not indent further
              // than that so the block is empty?
              return true;
            }
          }
        }
        if (line.startsWith(indent)) {
          keeping.push(line.slice(indent.length).trim());
        } else {
          // Unexpected input. bail.
          return true;
        }
      }
    } else {
      // Note: the line may end with a line comment so don't === it.
      if (line.trim().startsWith('- pip:')) {
        delim = line.split('-')[0] + '-';
        collecting = true;
      }
    }
  });
  return keeping.join('\n');
}

async function outputRequirements(result, outputKind, out) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (!result.ok) {
    if (outputKind === 'json') {
      logger.logger.log(utils.serializeResultJson(result));
      return;
    }
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  if (outputKind === 'json') {
    const json = utils.serializeResultJson(result);
    if (out === '-') {
      logger.logger.log(json);
    } else {
      fs$1.writeFileSync(out, json, 'utf8');
    }
    return;
  }
  if (outputKind === 'markdown') {
    const arr = [];
    arr.push('# Converted Conda file');
    arr.push('');
    arr.push('This is the Conda `environment.yml` file converted to python `requirements.txt`:');
    arr.push('');
    arr.push('```file=requirements.txt');
    arr.push(result.data.pip);
    arr.push('```');
    arr.push('');
    const md = arr.join('\n');
    if (out === '-') {
      logger.logger.log(md);
    } else {
      fs$1.writeFileSync(out, md, 'utf8');
    }
    return;
  }
  if (out === '-') {
    logger.logger.log(result.data.pip);
    logger.logger.log('');
  } else {
    fs$1.writeFileSync(out, result.data.pip, 'utf8');
  }
}

async function handleManifestConda(target, out, outputKind, cwd, verbose) {
  const data = await convertCondaToRequirements(target, cwd, verbose);
  await outputRequirements(data, outputKind, out);
}

async function generateAutoManifest(detected, cwd, verbose, outputKind) {
  if (detected.sbt) {
    logger.logger.log('Detected a Scala sbt build, generating pom files with sbt...');
    await convertSbtToMaven(cwd, 'sbt', './socket.sbt.pom.xml', verbose, []);
  }
  if (detected.gradle) {
    logger.logger.log('Detected a gradle build (Gradle, Kotlin, Scala), running default gradle generator...');
    await convertGradleToMaven(cwd, path.join(cwd, 'gradlew'), cwd, verbose, []);
  }
  if (detected.conda) {
    logger.logger.log('Detected an environment.yml file, running default Conda generator...');
    await handleManifestConda(cwd, '', outputKind, cwd, verbose);
  }
}

async function handleCreateNewScan({
  autoManifest,
  branchName,
  commitHash,
  commitMessage,
  committers,
  cwd,
  defaultBranch,
  interactive,
  orgSlug,
  outputKind,
  pendingHead,
  pullRequest,
  readOnly,
  repoName,
  report,
  targets,
  tmp
}) {
  if (autoManifest) {
    logger.logger.info('Auto generating manifest files ...');
    const detected = await detectManifestActions(cwd);
    await generateAutoManifest(detected, cwd, false, outputKind);
    logger.logger.info('Auto generation finished. Proceeding with Scan creation.');
  }
  const supportedFileNames = await fetchSupportedScanFileNames();
  if (!supportedFileNames.ok) {
    await outputCreateNewScan(supportedFileNames, outputKind, interactive);
    return;
  }
  const packagePaths = await utils.getPackageFilesForScan(cwd, targets, supportedFileNames.data);
  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: true,
    test: packagePaths.length > 0,
    pass: 'ok',
    fail: 'found no eligible files to scan',
    message: 'TARGET (file/dir) must contain matching / supported file types for a scan'
  });
  if (!wasValidInput) {
    return;
  }
  if (readOnly) {
    logger.logger.log('[ReadOnly] Bailing now');
    return;
  }
  const data = await fetchCreateOrgFullScan(packagePaths, orgSlug, defaultBranch, pendingHead, tmp, cwd, {
    commitHash,
    commitMessage,
    committers,
    pullRequest,
    repoName,
    branchName
  });
  if (data.ok && report) {
    if (data.data?.id) {
      await handleScanReport({
        filePath: '-',
        fold: 'version',
        includeLicensePolicy: true,
        orgSlug,
        outputKind,
        reportLevel: 'error',
        scanId: data.data.id,
        short: false
      });
    } else {
      await outputCreateNewScan({
        ok: false,
        message: 'Missing Scan ID',
        cause: 'Server did not respond with a scan ID',
        data: data.data
      }, outputKind, interactive);
    }
  } else {
    await outputCreateNewScan(data, outputKind, interactive);
  }
}

async function handleCI(autoManifest) {
  // ci: {
  //   description: 'Alias for "report create --view --strict"',
  //     argv: ['report', 'create', '--view', '--strict']
  // }
  const result = await getDefaultOrgSlug();
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
    // Always assume json mode
    logger.logger.log(utils.serializeResultJson(result));
    return;
  }

  // TODO: does it make sense to discover the commit details from local git?
  // TODO: does it makes sense to use custom branch/repo names here? probably socket.yml, right
  await handleCreateNewScan({
    autoManifest,
    branchName: 'socket-default-branch',
    commitMessage: '',
    commitHash: '',
    committers: '',
    cwd: process.cwd(),
    defaultBranch: false,
    interactive: false,
    orgSlug: result.data,
    outputKind: 'json',
    pendingHead: true,
    // when true, requires branch name set, tmp false
    pullRequest: 0,
    repoName: 'socket-default-repository',
    readOnly: false,
    report: true,
    targets: ['.'],
    tmp: false // don't set when pendingHead is true
  });
}

const {
  DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$I
} = constants;
const config$M = {
  commandName: 'ci',
  description: 'Create a new scan and report whether it passes your security policy',
  hidden: true,
  flags: {
    ...utils.commonFlags,
    autoManifest: {
      type: 'boolean',
      default: false,
      // dev tools is not likely to be set up so this is safer
      description: 'Auto generate manifest files where detected? See autoManifest flag in `socket scan create`'
    }
  },
  help: (parentName, _config) => `
    Usage
      $ ${parentName}

    Options
      ${utils.getFlagListOutput(config$M.flags, 6)}

    This command is intended to use in CI runs to allow automated systems to
    accept or reject a current build. When the scan does not pass your security
    policy, the exit code will be non-zero.

    It will use the default org for the set API token.

    The --autoManifest flag does the same as the one from \`socket scan create\`
    but is not enabled by default since the CI is less likely to be set up with
    all the necessary dev tooling. Enable it if you want the scan to include
    locally generated manifests like for gradle and sbt.
  `
};
const cmdCI = {
  description: config$M.description,
  hidden: config$M.hidden,
  run: run$M
};
async function run$M(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$M,
    importMeta,
    parentName
  });
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$I);
    return;
  }
  await handleCI(Boolean(cli.flags['autoManifest']));
}

async function discoverConfigValue(key) {
  // This will have to be a specific implementation per key because certain
  // keys should request information from particular API endpoints while
  // others should simply return their default value, like endpoint URL.

  if (!utils.supportedConfigKeys.has(key)) {
    return {
      ok: false,
      message: 'Auto discover failed',
      cause: 'Requested key is not a valid config key.'
    };
  }
  if (key === 'apiBaseUrl') {
    // Return the default value
    return {
      ok: false,
      message: 'Auto discover failed',
      cause: "If you're unsure about the base endpoint URL then simply unset it."
    };
  }
  if (key === 'apiProxy') {
    // I don't think we can auto-discover this with any order of reliability..?
    return {
      ok: false,
      message: 'Auto discover failed',
      cause: 'When uncertain, unset this key. Otherwise ask your network administrator'
    };
  }
  if (key === 'apiToken') {
    return {
      ok: false,
      message: 'Auto discover failed',
      cause: 'You can find/create your API token in your Socket dashboard > settings > API tokens.\nYou should then use `socket login` to login instead of this command.'
    };
  }
  if (key === 'defaultOrg') {
    const hasApiToken = utils.hasDefaultToken();
    if (!hasApiToken) {
      return {
        ok: false,
        message: 'Auto discover failed',
        cause: 'No API token set, must have a token to resolve its default org.'
      };
    }
    const org = await getDefaultOrgFromToken();
    if (!org?.length) {
      return {
        ok: false,
        message: 'Auto discover failed',
        cause: 'Was unable to determine default org for the current API token.'
      };
    }
    if (Array.isArray(org)) {
      return {
        ok: true,
        data: org,
        message: 'These are the orgs that the current API token can access.'
      };
    }
    return {
      ok: true,
      data: org,
      message: 'This is the org that belongs to the current API token.'
    };
  }
  if (key === 'enforcedOrgs') {
    const hasApiToken = utils.hasDefaultToken();
    if (!hasApiToken) {
      return {
        ok: false,
        message: 'Auto discover failed',
        cause: 'No API token set, must have a token to resolve orgs to enforce.'
      };
    }
    const orgs = await getEnforceableOrgsFromToken();
    if (!orgs?.length) {
      return {
        ok: false,
        message: 'Auto discover failed',
        cause: 'Was unable to determine any orgs to enforce for the current API token.'
      };
    }
    return {
      ok: true,
      data: orgs,
      message: 'These are the orgs whose security policy you can enforce.'
    };
  }
  if (key === 'test') {
    return {
      ok: false,
      message: 'Auto discover failed',
      cause: 'congrats, you found the test key'
    };
  }

  // Mostly to please TS, because we're not telling it `key` is keyof LocalConfig
  return {
    ok: false,
    message: 'Auto discover failed',
    cause: 'unreachable?'
  };
}
async function getDefaultOrgFromToken() {
  const sockSdkResult = await utils.setupSdk();
  if (!sockSdkResult.ok) {
    return undefined;
  }
  const sockSdk = sockSdkResult.data;
  const result = await utils.handleApiCall(sockSdk.getOrganizations(), 'list of organizations');
  if (result.ok) {
    const arr = Array.from(Object.values(result.data.organizations)).map(({
      slug
    }) => slug);
    if (arr.length === 0) {
      return undefined;
    }
    if (arr.length === 1) {
      return arr[0];
    }
    return arr;
  }
  return undefined;
}
async function getEnforceableOrgsFromToken() {
  const sockSdkResult = await utils.setupSdk();
  if (!sockSdkResult.ok) {
    return undefined;
  }
  const sockSdk = sockSdkResult.data;
  const result = await utils.handleApiCall(sockSdk.getOrganizations(), 'list of organizations');
  if (result.ok) {
    const arr = Array.from(Object.values(result.data.organizations)).map(({
      slug
    }) => slug);
    if (arr.length === 0) {
      return undefined;
    }
    return arr;
  }
  return undefined;
}

async function outputConfigAuto(key, result, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result));
    return;
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  if (outputKind === 'markdown') {
    logger.logger.log(`# Auto discover config value`);
    logger.logger.log('');
    logger.logger.log(`Attempted to automatically discover the value for config key: "${key}"`);
    logger.logger.log('');
    if (result.ok) {
      logger.logger.log(`The discovered value is: "${result.data}"`);
      if (result.message) {
        logger.logger.log('');
        logger.logger.log(result.message);
      }
    }
    logger.logger.log('');
  } else {
    if (result.message) {
      logger.logger.log(result.message);
      logger.logger.log('');
    }
    logger.logger.log(`- ${key}: ${result.data}`);
    logger.logger.log('');
    if (utils.isReadOnlyConfig()) {
      logger.logger.log('(Unable to persist this value because the config is in read-only mode, meaning it was overridden through env or flag.)');
    } else if (key === 'defaultOrg') {
      const proceed = await prompts.select({
        message: 'Would you like to update the default org in local config to this value?',
        choices: (Array.isArray(result.data) ? result.data : [result.data]).map(slug => ({
          name: 'Yes [' + slug + ']',
          value: slug,
          description: `Use "${slug}" as the default organization`
        })).concat({
          name: 'No',
          value: '',
          description: 'Do not use any of these organizations'
        })
      });
      if (proceed) {
        logger.logger.log(`Setting defaultOrg to "${proceed}"...`);
        const updateResult = utils.updateConfigValue('defaultOrg', proceed);
        if (updateResult.ok) {
          logger.logger.log(`OK. Updated defaultOrg to "${proceed}".\nYou should no longer need to add the org to commands that normally require it.`);
        } else {
          logger.logger.log(utils.failMsgWithBadge(updateResult.message, updateResult.cause));
        }
      } else {
        logger.logger.log('OK. No changes made.');
      }
    } else if (key === 'enforcedOrgs') {
      const proceed = await prompts.select({
        message: 'Would you like to update the enforced orgs in local config to this value?',
        choices: (Array.isArray(result.data) ? result.data : [result.data]).map(slug => ({
          name: 'Yes [' + slug + ']',
          value: slug,
          description: `Enforce the security policy of "${slug}" on this machine`
        })).concat({
          name: 'No',
          value: '',
          description: 'Do not use any of these organizations'
        })
      });
      if (proceed) {
        logger.logger.log(`Setting enforcedOrgs key to "${proceed}"...`);
        const updateResult = utils.updateConfigValue('defaultOrg', proceed);
        if (updateResult.ok) {
          logger.logger.log(`OK. Updated enforcedOrgs to "${proceed}".`);
        } else {
          logger.logger.log(utils.failMsgWithBadge(updateResult.message, updateResult.cause));
        }
      } else {
        logger.logger.log('OK. No changes made.');
      }
    }
  }
}

async function handleConfigAuto({
  key,
  outputKind
}) {
  const result = await discoverConfigValue(key);
  await outputConfigAuto(key, result, outputKind);
}

const {
  DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$H
} = constants;
const config$L = {
  commandName: 'auto',
  description: 'Automatically discover and set the correct value config item',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags
  },
  help: (command, config) => `
    Usage
      $ ${command} <org slug>

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Attempt to automatically discover the correct value for a certain config key.

    For certain keys it will request the value from server, for others it will
    reset the value to the default. For some keys this has no effect.

    Keys:

${Array.from(utils.supportedConfigKeys.entries()).map(([key, desc]) => `     - ${key} -- ${desc}`).join('\n')}

    Examples
      $ ${command} auto defaultOrg
  `
};
const cmdConfigAuto = {
  description: config$L.description,
  hidden: config$L.hidden,
  run: run$L
};
async function run$L(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$L,
    importMeta,
    parentName
  });
  const {
    json,
    markdown
  } = cli.flags;
  const outputKind = utils.getOutputKind(json, markdown);
  const [key = ''] = cli.input;
  const wasValidInput = utils.checkCommandInput(outputKind, {
    test: utils.supportedConfigKeys.has(key) && key !== 'test',
    message: 'Config key should be the first arg',
    pass: 'ok',
    fail: key ? 'invalid config key' : 'missing'
  }, {
    nook: true,
    test: !json || !markdown,
    message: 'The `--json` and `--markdown` flags can not be used at the same time',
    pass: 'ok',
    fail: 'bad'
  });
  if (!wasValidInput) {
    return;
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$H);
    return;
  }
  await handleConfigAuto({
    key: key,
    outputKind
  });
}

async function outputConfigGet(key, result, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result));
    return;
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  const readOnly = utils.isReadOnlyConfig();
  if (outputKind === 'markdown') {
    logger.logger.log(`# Config Value`);
    logger.logger.log('');
    logger.logger.log(`Config key '${key}' has value '${result.data}`);
    if (readOnly) {
      logger.logger.log('');
      logger.logger.log('Note: the config is in read-only mode, meaning at least one key was temporarily\n      overridden from an env var or command flag.');
    }
  } else {
    logger.logger.log(`${key}: ${result.data}`);
    if (readOnly) {
      logger.logger.log('');
      logger.logger.log('Note: the config is in read-only mode, meaning at least one key was temporarily overridden from an env var or command flag.');
    }
  }
}

async function handleConfigGet({
  key,
  outputKind
}) {
  const result = utils.getConfigValue(key);
  await outputConfigGet(key, result, outputKind);
}

const {
  DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$G
} = constants;
const config$K = {
  commandName: 'get',
  description: 'Get the value of a local CLI config item',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags
  },
  help: (command, config) => `
    Usage
      $ ${command} <org slug>

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Keys:

${Array.from(utils.supportedConfigKeys.entries()).map(([key, desc]) => `     - ${key} -- ${desc}`).join('\n')}

    Examples
      $ ${command} FakeOrg --repoName=test-repo
  `
};
const cmdConfigGet = {
  description: config$K.description,
  hidden: config$K.hidden,
  run: run$K
};
async function run$K(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$K,
    importMeta,
    parentName
  });
  const {
    json,
    markdown
  } = cli.flags;
  const outputKind = utils.getOutputKind(json, markdown);
  const [key = ''] = cli.input;
  const wasValidInput = utils.checkCommandInput(outputKind, {
    test: utils.supportedConfigKeys.has(key) || key === 'test',
    message: 'Config key should be the first arg',
    pass: 'ok',
    fail: key ? 'invalid config key' : 'missing'
  }, {
    nook: true,
    test: !json || !markdown,
    message: 'The `--json` and `--markdown` flags can not be used at the same time',
    pass: 'ok',
    fail: 'bad'
  });
  if (!wasValidInput) {
    return;
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$G);
    return;
  }
  await handleConfigGet({
    key: key,
    outputKind
  });
}

async function outputConfigList({
  full,
  outputKind
}) {
  const readOnly = utils.isReadOnlyConfig();
  if (outputKind === 'json') {
    let failed = false;
    const obj = {};
    for (const key of utils.supportedConfigKeys.keys()) {
      const result = utils.getConfigValue(key);
      let value = result.data;
      if (!result.ok) {
        value = `Failed to retrieve: ${result.message}`;
        failed = true;
      } else if (!full && utils.sensitiveConfigKeys.has(key)) {
        value = '********';
      }
      if (full || value !== undefined) {
        obj[key] = value ?? '<none>';
      }
    }
    if (failed) {
      process.exitCode = 1;
    }
    logger.logger.log(utils.serializeResultJson(failed ? {
      ok: false,
      message: 'At least one config key failed to be fetched...',
      data: JSON.stringify({
        full,
        config: obj,
        readOnly
      })
    } : {
      ok: true,
      data: {
        full,
        config: obj,
        readOnly
      }
    }));
  } else {
    const maxWidth = Array.from(utils.supportedConfigKeys.keys()).reduce((a, b) => Math.max(a, b.length), 0);
    logger.logger.log('# Local CLI Config');
    logger.logger.log('');
    logger.logger.log(`This is the local CLI config (full=${!!full}):`);
    logger.logger.log('');
    for (const key of utils.supportedConfigKeys.keys()) {
      const result = utils.getConfigValue(key);
      if (!result.ok) {
        logger.logger.log(`- ${key}: failed to read: ${result.message}`);
      } else {
        let value = result.data;
        if (!full && utils.sensitiveConfigKeys.has(key)) {
          value = '********';
        }
        if (full || value !== undefined) {
          logger.logger.log(`- ${key}:${' '.repeat(Math.max(0, maxWidth - key.length + 3))} ${Array.isArray(value) ? value.join(', ') || '<none>' : value ?? '<none>'}`);
        }
      }
    }
    if (readOnly) {
      logger.logger.log('');
      logger.logger.log('Note: the config is in read-only mode, meaning at least one key was temporarily\n      overridden from an env var or command flag.');
    }
  }
}

const {
  DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$F
} = constants;
const config$J = {
  commandName: 'list',
  description: 'Show all local CLI config items and their values',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags,
    full: {
      type: 'boolean',
      default: false,
      description: 'Show full tokens in plaintext (unsafe)'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command} <org slug>

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Keys:

${Array.from(utils.supportedConfigKeys.entries()).map(([key, desc]) => `     - ${key} -- ${desc}`).join('\n')}

    Examples
      $ ${command} FakeOrg --repoName=test-repo
  `
};
const cmdConfigList = {
  description: config$J.description,
  hidden: config$J.hidden,
  run: run$J
};
async function run$J(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$J,
    importMeta,
    parentName
  });
  const {
    full,
    json,
    markdown
  } = cli.flags;
  const outputKind = utils.getOutputKind(json, markdown);
  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: true,
    test: !json || !markdown,
    message: 'The `--json` and `--markdown` flags can not be used at the same time',
    pass: 'ok',
    fail: 'bad'
  });
  if (!wasValidInput) {
    return;
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$F);
    return;
  }
  await outputConfigList({
    full: !!full,
    outputKind
  });
}

async function outputConfigSet(result, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result));
    return;
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  if (outputKind === 'markdown') {
    logger.logger.log(`# Update config`);
    logger.logger.log('');
    logger.logger.log(result.message);
    if (result.data) {
      logger.logger.log('');
      logger.logger.log(result.data);
    }
  } else {
    logger.logger.log(`OK`);
    logger.logger.log(result.message);
    if (result.data) {
      logger.logger.log('');
      logger.logger.log(result.data);
    }
  }
}

async function handleConfigSet({
  key,
  outputKind,
  value
}) {
  const result = utils.updateConfigValue(key, value);
  await outputConfigSet(result, outputKind);
}

const {
  DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$E
} = constants;
const config$I = {
  commandName: 'set',
  description: 'Update the value of a local CLI config item',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags
  },
  help: (command, config) => `
    Usage
      $ ${command} <key> <value>

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    This is a crude way of updating the local configuration for this CLI tool.

    Note that updating a value here is nothing more than updating a key/value
    store entry. No validation is happening. The server may reject your config.

    Keys:

${Array.from(utils.supportedConfigKeys.entries()).map(([key, desc]) => `     - ${key} -- ${desc}`).join('\n')}

    Examples
      $ ${command} apiProxy https://example.com
  `
};
const cmdConfigSet = {
  description: config$I.description,
  hidden: config$I.hidden,
  run: run$I
};
async function run$I(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$I,
    importMeta,
    parentName
  });
  const {
    json,
    markdown
  } = cli.flags;
  const outputKind = utils.getOutputKind(json, markdown);
  const [key = '', ...rest] = cli.input;
  const value = rest.join(' ');
  const wasValidInput = utils.checkCommandInput(outputKind, {
    test: key === 'test' || utils.supportedConfigKeys.has(key),
    message: 'Config key should be the first arg',
    pass: 'ok',
    fail: key ? 'invalid config key' : 'missing'
  }, {
    test: !!value,
    // This is a string, empty string is not ok
    message: 'Key value should be the remaining args (use `unset` to unset a value)',
    pass: 'ok',
    fail: 'missing'
  }, {
    nook: true,
    test: !json || !markdown,
    message: 'The `--json` and `--markdown` flags can not be used at the same time',
    pass: 'ok',
    fail: 'bad'
  });
  if (!wasValidInput) {
    return;
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$E);
    return;
  }
  await handleConfigSet({
    key: key,
    outputKind,
    value
  });
}

async function outputConfigUnset(updateResult, outputKind) {
  if (!updateResult.ok) {
    process.exitCode = updateResult.code ?? 1;
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(updateResult));
    return;
  }
  if (!updateResult.ok) {
    logger.logger.fail(utils.failMsgWithBadge(updateResult.message, updateResult.cause));
    return;
  }
  if (outputKind === 'markdown') {
    logger.logger.log(`# Update config`);
    logger.logger.log('');
    logger.logger.log(updateResult.message);
    if (updateResult.data) {
      logger.logger.log('');
      logger.logger.log(updateResult.data);
    }
  } else {
    logger.logger.log(`OK`);
    logger.logger.log(updateResult.message);
    if (updateResult.data) {
      logger.logger.log('');
      logger.logger.log(updateResult.data);
    }
  }
}

async function handleConfigUnset({
  key,
  outputKind
}) {
  const updateResult = utils.updateConfigValue(key, undefined);
  await outputConfigUnset(updateResult, outputKind);
}

const {
  DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$D
} = constants;
const config$H = {
  commandName: 'unset',
  description: 'Clear the value of a local CLI config item',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags
  },
  help: (command, config) => `
    Usage
      $ ${command} <org slug>

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Keys:

${Array.from(utils.supportedConfigKeys.entries()).map(([key, desc]) => `     - ${key} -- ${desc}`).join('\n')}

    Examples
      $ ${command} FakeOrg --repoName=test-repo
  `
};
const cmdConfigUnset = {
  description: config$H.description,
  hidden: config$H.hidden,
  run: run$H
};
async function run$H(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$H,
    importMeta,
    parentName
  });
  const {
    json,
    markdown
  } = cli.flags;
  const outputKind = utils.getOutputKind(json, markdown);
  const [key = ''] = cli.input;
  const wasValidInput = utils.checkCommandInput(outputKind, {
    test: key === 'test' || utils.supportedConfigKeys.has(key),
    message: 'Config key should be the first arg',
    pass: 'ok',
    fail: key ? 'invalid config key' : 'missing'
  }, {
    nook: true,
    test: !json || !markdown,
    message: 'The `--json` and `--markdown` flags can not be used at the same time',
    pass: 'ok',
    fail: 'bad'
  });
  if (!wasValidInput) {
    return;
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$D);
    return;
  }
  await handleConfigUnset({
    key: key,
    outputKind
  });
}

const description$9 = 'Commands related to the local CLI configuration';
const cmdConfig = {
  description: description$9,
  hidden: true,
  // [beta]
  async run(argv, importMeta, {
    parentName
  }) {
    await utils.meowWithSubcommands({
      auto: cmdConfigAuto,
      get: cmdConfigGet,
      list: cmdConfigList,
      set: cmdConfigSet,
      unset: cmdConfigUnset
    }, {
      argv,
      description: description$9,
      importMeta,
      name: `${parentName} config`
    });
  }
};

async function fetchDependencies({
  limit,
  offset
}) {
  const sockSdkResult = await utils.setupSdk();
  if (!sockSdkResult.ok) {
    return sockSdkResult;
  }
  const sockSdk = sockSdkResult.data;
  return await utils.handleApiCall(sockSdk.searchDependencies({
    limit,
    offset
  }), 'organization dependencies');
}

// @ts-ignore
async function outputDependencies(result, {
  limit,
  offset,
  outputKind
}) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result));
    return;
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  logger.logger.log('Request details: Offset:', offset, ', limit:', limit, ', is there more data after this?', result.data.end ? 'no' : 'yes');
  const options = {
    columns: [{
      field: 'namespace',
      name: vendor.yoctocolorsCjsExports.cyan('Namespace')
    }, {
      field: 'name',
      name: vendor.yoctocolorsCjsExports.cyan('Name')
    }, {
      field: 'version',
      name: vendor.yoctocolorsCjsExports.cyan('Version')
    }, {
      field: 'repository',
      name: vendor.yoctocolorsCjsExports.cyan('Repository')
    }, {
      field: 'branch',
      name: vendor.yoctocolorsCjsExports.cyan('Branch')
    }, {
      field: 'type',
      name: vendor.yoctocolorsCjsExports.cyan('Type')
    }, {
      field: 'direct',
      name: vendor.yoctocolorsCjsExports.cyan('Direct')
    }]
  };
  logger.logger.log(vendor.srcExports(options, result.data.rows));
}

async function handleDependencies({
  limit,
  offset,
  outputKind
}) {
  const result = await fetchDependencies({
    limit,
    offset
  });
  await outputDependencies(result, {
    limit,
    offset,
    outputKind
  });
}

const {
  DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$C
} = constants;
const config$G = {
  commandName: 'dependencies',
  description: 'Search for any dependency that is being used in your organization',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    limit: {
      type: 'number',
      shortFlag: 'l',
      default: 50,
      description: 'Maximum number of dependencies returned'
    },
    offset: {
      type: 'number',
      shortFlag: 'o',
      default: 0,
      description: 'Page number'
    },
    ...utils.outputFlags
  },
  help: (command, config) => `
    Usage
      ${command}

    API Token Requirements
      - Quota: 1 unit
      - Permissions: none (does need token with access to target org)

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Examples
      ${command} --limit 20 --offset 10
  `
};
const cmdScanCreate$1 = {
  description: config$G.description,
  hidden: config$G.hidden,
  run: run$G
};
async function run$G(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$G,
    importMeta,
    parentName
  });
  const {
    json,
    limit,
    markdown,
    offset
  } = cli.flags;
  const outputKind = utils.getOutputKind(json, markdown);
  const hasApiToken = utils.hasDefaultToken();
  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: true,
    test: !json || !markdown,
    message: 'The `--json` and `--markdown` flags can not be used at the same time',
    pass: 'ok',
    fail: 'bad'
  }, {
    nook: true,
    test: hasApiToken,
    message: 'You need to be logged in to use this command. See `socket login`.',
    pass: 'ok',
    fail: 'missing API token'
  });
  if (!wasValidInput) {
    return;
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$C);
    return;
  }
  await handleDependencies({
    limit: Number(limit || 0) || 0,
    offset: Number(offset || 0) || 0,
    outputKind
  });
}

async function fetchDiffScan$1({
  after,
  before,
  orgSlug
}) {
  return await utils.queryApiSafeJson(`orgs/${orgSlug}/full-scans/diff?before=${encodeURIComponent(before)}&after=${encodeURIComponent(after)}`, 'a scan diff');
}

async function outputDiffScan$1(result, {
  depth,
  file,
  outputKind
}) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (!result.ok) {
    if (outputKind === 'json') {
      logger.logger.log(utils.serializeResultJson(result));
      return;
    }
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  const dashboardUrl = result.data.diff_report_url;
  const dashboardMessage = dashboardUrl ? `\n View this diff scan in the Socket dashboard: ${vendor.yoctocolorsCjsExports.cyan(dashboardUrl)}` : '';

  // When forcing json, or dumping to file, serialize to string such that it
  // won't get truncated. The only way to dump the full raw JSON to stdout is
  // to use `--json --file -` (the dash is a standard notation for stdout)
  if (outputKind === 'json' || file) {
    const json = utils.serializeResultJson(result);
    if (file && file !== '-') {
      logger.logger.info(`Writing json to \`${file}\``);
      fs$1.writeFile(file, JSON.stringify(result, null, 2), err => {
        if (err) {
          logger.logger.fail(`Writing to \`${file}\` failed...`);
          logger.logger.error(err);
        } else {
          logger.logger.success(`Data successfully written to \`${file}\``);
        }
        logger.logger.info(dashboardMessage);
      });
    } else {
      // Note: only the .log will go to stdout
      logger.logger.success(`\n Diff scan result: \n`);
      logger.logger.log(json);
      logger.logger.info(dashboardMessage);
    }
    return;
  }

  // In this case neither the --json nor the --file flag was passed
  // Dump the JSON to CLI and let NodeJS deal with truncation

  logger.logger.success('Diff scan result:');
  logger.logger.log(util.inspect(result, {
    showHidden: false,
    depth: depth > 0 ? depth : null,
    colors: true,
    maxArrayLength: null
  }));
  logger.logger.info(`\n 📝 To display the detailed report in the terminal, use the --json flag \n`);
  logger.logger.log(dashboardMessage);
}

async function handleDiffScan$1({
  after,
  before,
  depth,
  file,
  orgSlug,
  outputKind
}) {
  const data = await fetchDiffScan$1({
    after,
    before,
    orgSlug
  });
  await outputDiffScan$1(data, {
    depth,
    file,
    outputKind
  });
}

const {
  DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$B
} = constants;
const config$F = {
  commandName: 'get',
  description: 'Get a diff scan for an organization',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    after: {
      type: 'string',
      shortFlag: 'a',
      default: '',
      description: 'The scan ID of the head scan'
    },
    before: {
      type: 'string',
      shortFlag: 'b',
      default: '',
      description: 'The scan ID of the base scan'
    },
    depth: {
      type: 'number',
      default: 2,
      description: 'Max depth of JSON to display before truncating, use zero for no limit (without --json/--file)'
    },
    json: {
      type: 'boolean',
      shortFlag: 'j',
      default: false,
      description: 'Output result as json. This can be big. Use --file to store it to disk without truncation.'
    },
    file: {
      type: 'string',
      shortFlag: 'f',
      default: '',
      description: 'Path to a local file where the output should be saved. Use `-` to force stdout.'
    }
  },
  help: (command, config) => utils.isTestingV1() ? 'This command will be removed in v1' : `
    Note: This command is deprecated, to be dropped in the next major bump.
          Please see \`socket scan diff\`

    Usage
      $ ${command} <org slug> --before=<before> --after=<after>

    API Token Requirements
      - Quota: 1 unit
      - Permissions: full-scans:list

    This command displays the package changes between two scans. The full output
    can be pretty large depending on the size of your repo and time range. It is
    best stored to disk to be further analyzed by other tools.

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command} FakeCorp --before=aaa0aa0a-aaaa-0000-0a0a-0000000a00a0 --after=aaa1aa1a-aaaa-1111-1a1a-1111111a11a1
  `
};
const cmdDiffScanGet = {
  description: config$F.description,
  hidden: config$F.hidden,
  run: run$F
};
async function run$F(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$F,
    importMeta,
    parentName
  });
  const {
    after,
    before,
    depth,
    file,
    json,
    markdown
  } = cli.flags;
  const outputKind = utils.getOutputKind(json, markdown);
  const defaultOrgSlugResult = utils.getConfigValueOrUndef('defaultOrg');
  const orgSlug = defaultOrgSlugResult || cli.input[0] || '';
  const hasApiToken = utils.hasDefaultToken();
  const wasValidInput = utils.checkCommandInput(outputKind, {
    test: !!(before && after),
    message: 'Specify a before and after scan ID.\nThe args are expecting a full `aaa0aa0a-aaaa-0000-0a0a-0000000a00a0` scan ID.',
    pass: 'ok',
    fail: !before && !after ? 'missing before and after' : !before ? 'missing before' : 'missing after'
  }, {
    test: !!orgSlug,
    nook: true,
    message: 'Org name as the first argument',
    pass: 'ok',
    fail: 'missing'
  }, {
    nook: true,
    test: !json || !markdown,
    message: 'The `--json` and `--markdown` flags can not be used at the same time',
    pass: 'ok',
    fail: 'bad'
  }, {
    nook: true,
    test: hasApiToken,
    message: 'You need to be logged in to use this command. See `socket login`.',
    pass: 'ok',
    fail: 'missing API token'
  });
  if (!wasValidInput) {
    return;
  }
  logger.logger.fail('Warning: this command is deprecated in favor of `socket scan diff` and will be removed in the next major bump.');
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$B);
    return;
  }
  await handleDiffScan$1({
    before: String(before || ''),
    after: String(after || ''),
    depth: Number(depth),
    orgSlug,
    outputKind,
    file: String(file || '')
  });
}

const description$8 = 'Diff scans related commands';
const cmdDiffScan = {
  description: description$8,
  // Hidden because it was broken all this time (nobody could be using it)
  // and we're not sure if it's useful to anyone in its current state.
  // Until we do, we'll hide this to keep the help tidier.
  // And later, we may simply move this under `scan`, anyways.
  hidden: true,
  async run(argv, importMeta, {
    parentName
  }) {
    await utils.meowWithSubcommands({
      get: cmdDiffScanGet
    }, {
      argv,
      description: description$8,
      importMeta,
      name: parentName + ' diff-scan'
    });
  }
};

const GITHUB_ACTIONS_BOT_USERNAME = 'github-actions[bot]';
const GITHUB_ACTIONS_BOT_EMAIL = `${GITHUB_ACTIONS_BOT_USERNAME}@users.noreply.github.com`;
function formatBranchName(name) {
  return name.replace(/[-_.\\/]+/g, '-').replace(/[^-a-zA-Z0-9]+/g, '').replace(/^-+|-+$/g, '');
}
function getBaseGitBranch() {
  // Lazily access constants.ENV.GITHUB_REF_NAME.
  return constants.ENV.GITHUB_REF_NAME ||
  // GitHub defaults to branch name "main"
  // https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/about-branches#about-the-default-branch
  'main';
}
function getSocketBranchName(purl, newVersion, workspaceName) {
  const purlObj = vendor.packageurlJsExports.PackageURL.fromString(purl);
  const maybeWorkspaceName = workspaceName ? `${formatBranchName(workspaceName)}-` : '';
  const maybeNamespace = purlObj.namespace ? `${formatBranchName(purlObj.namespace)}-` : '';
  const fullName = `${maybeWorkspaceName}${maybeNamespace}${formatBranchName(purlObj.name)}`;
  return `socket/${fullName}-${formatBranchName(newVersion)}`;
}
function getSocketPrTitlePattern(purl, workspaceName) {
  const purlObj = vendor.packageurlJsExports.PackageURL.fromString(purl);
  const pkgFullName = utils.getPkgFullNameFromPurlObj(purlObj);
  const workspaceDetails = workspaceName ? ` in ${regexps.escapeRegExp(workspaceName)}` : '';
  return new RegExp(`Bump ${regexps.escapeRegExp(pkgFullName)} from ${regexps.escapeRegExp(purlObj.version)} to \\S+${workspaceDetails}`);
}
function getSocketPullRequestTitle(purl, newVersion, workspaceName) {
  const purlObj = vendor.packageurlJsExports.PackageURL.fromString(purl);
  const pkgFullName = utils.getPkgFullNameFromPurlObj(purlObj);
  const workspaceDetails = workspaceName ? ` in ${workspaceName}` : '';
  return `Bump ${pkgFullName} from ${purlObj.version} to ${newVersion}${workspaceDetails}`;
}
function getSocketPullRequestBody(purl, newVersion, workspaceName) {
  const purlObj = vendor.packageurlJsExports.PackageURL.fromString(purl);
  const pkgFullName = utils.getPkgFullNameFromPurlObj(purlObj);
  const workspaceDetails = workspaceName ? ` in ${workspaceName}` : '';
  return `Bump [${pkgFullName}](${utils.getSocketDevPackageOverviewUrlFromPurl(purlObj)}) from ${purlObj.version} to ${newVersion}${workspaceDetails}.`;
}
function getSocketCommitMessage(purl, newVersion, workspaceName) {
  const purlObj = vendor.packageurlJsExports.PackageURL.fromString(purl);
  const pkgFullName = utils.getPkgFullNameFromPurlObj(purlObj);
  const workspaceDetails = workspaceName ? ` in ${workspaceName}` : '';
  return `socket: Bump ${pkgFullName} from ${purlObj.version} to ${newVersion}${workspaceDetails}`;
}
async function gitCleanFdx(cwd = process.cwd()) {
  const stdioIgnoreOptions = {
    cwd,
    stdio: 'ignore'
  };
  await spawn.spawn('git', ['clean', '-fdx'], stdioIgnoreOptions);
}
async function gitCreateAndPushBranch(branch, commitMsg, filepaths, cwd = process.cwd()) {
  const stdioIgnoreOptions = {
    cwd,
    stdio: 'ignore'
  };
  try {
    await gitEnsureIdentity(cwd);
    await spawn.spawn('git', ['checkout', '-b', branch], stdioIgnoreOptions);
    await spawn.spawn('git', ['add', ...filepaths], stdioIgnoreOptions);
    await spawn.spawn('git', ['commit', '-m', commitMsg], stdioIgnoreOptions);
    await spawn.spawn('git', ['push', '--force', '--set-upstream', 'origin', branch], stdioIgnoreOptions);
    return true;
  } catch {}
  try {
    await spawn.spawn('git', ['branch', '-D', branch], stdioIgnoreOptions);
  } catch {}
  return false;
}
async function gitEnsureIdentity(cwd = process.cwd()) {
  const stdioIgnoreOptions = {
    cwd,
    stdio: 'ignore'
  };
  const stdioPipeOptions = {
    cwd
  };
  let hasUserName = false;
  try {
    hasUserName = !!(await spawn.spawn('git', ['config', '--get', 'user.name'], stdioPipeOptions)).stdout.trim();
  } catch {}
  if (!hasUserName) {
    await spawn.spawn('git', ['config', 'user.name', GITHUB_ACTIONS_BOT_USERNAME], stdioIgnoreOptions);
  }
  let hasUserEmail = false;
  try {
    hasUserEmail = !!(await spawn.spawn('git', ['config', '--get', 'user.email'], stdioPipeOptions)).stdout.trim();
  } catch {}
  if (!hasUserEmail) {
    await spawn.spawn('git', ['config', 'user.email', GITHUB_ACTIONS_BOT_EMAIL], stdioIgnoreOptions);
  }
}
async function gitResetAndClean(branch = 'HEAD', cwd = process.cwd()) {
  // Discards tracked changes.
  await gitResetHard(branch, cwd);
  // Deletes all untracked files and directories.
  await gitCleanFdx(cwd);
}
async function gitResetHard(branch = 'HEAD', cwd = process.cwd()) {
  const stdioIgnoreOptions = {
    cwd,
    stdio: 'ignore'
  };
  await spawn.spawn('git', ['reset', '--hard', branch], stdioIgnoreOptions);
}
async function gitRemoteBranchExists(branch, cwd = process.cwd()) {
  const stdioPipeOptions = {
    cwd
  };
  try {
    return (await spawn.spawn('git', ['ls-remote', '--heads', 'origin', branch], stdioPipeOptions)).stdout.trim().length > 0;
  } catch {
    return false;
  }
}
async function gitUnstagedModifiedFiles(cwd = process.cwd()) {
  const stdioPipeOptions = {
    cwd
  };
  const stdout = (await spawn.spawn('git', ['diff', '--name-only'], stdioPipeOptions)).stdout.trim();
  const rawFiles = stdout.split('\n') ?? [];
  return rawFiles.map(relPath => path$1.normalizePath(relPath));
}

let _octokit;
function getOctokit() {
  if (_octokit === undefined) {
    _octokit = new vendor.Octokit({
      // Lazily access constants.ENV.SOCKET_CLI_GITHUB_TOKEN.
      auth: constants.ENV.SOCKET_CLI_GITHUB_TOKEN
    });
  }
  return _octokit;
}
let _octokitGraphql;
function getOctokitGraphql() {
  if (!_octokitGraphql) {
    _octokitGraphql = vendor.graphql2.defaults({
      headers: {
        // Lazily access constants.ENV.SOCKET_CLI_GITHUB_TOKEN.
        authorization: `token ${constants.ENV.SOCKET_CLI_GITHUB_TOKEN}`
      }
    });
  }
  return _octokitGraphql;
}
async function cacheFetch(key, fetcher, ttlMs) {
  // Optionally disable cache.
  // Lazily access constants.ENV.DISABLE_GITHUB_CACHE.
  if (constants.ENV.DISABLE_GITHUB_CACHE) {
    return await fetcher();
  }
  let data = await readCache(key, ttlMs);
  if (!data) {
    data = await fetcher();
    await writeCache(key, data);
  }
  return data;
}
async function readCache(key,
// 5 minute in milliseconds time to live (TTL).
ttlMs = 5 * 60 * 1000) {
  // Lazily access constants.githubCachePath.
  const cacheJsonPath = path.join(constants.githubCachePath, `${key}.json`);
  try {
    const stat = fs$1.statSync(cacheJsonPath);
    const isExpired = Date.now() - stat.mtimeMs > ttlMs;
    if (!isExpired) {
      return await fs$2.readJson(cacheJsonPath);
    }
  } catch {}
  return null;
}
async function writeCache(key, data) {
  // Lazily access constants.githubCachePath.
  const {
    githubCachePath
  } = constants;
  const cacheJsonPath = path.join(githubCachePath, `${key}.json`);
  if (!fs$1.existsSync(githubCachePath)) {
    await fs$1.promises.mkdir(githubCachePath, {
      recursive: true
    });
  }
  await fs$2.writeJson(cacheJsonPath, data);
}
async function cleanupOpenPrs(owner, repo, purl, newVersion, options) {
  const {
    workspaceName
  } = {
    __proto__: null,
    ...options
  };
  const octokit = getOctokit();
  const octokitGraphql = getOctokitGraphql();
  const titlePattern = getSocketPrTitlePattern(purl, workspaceName);
  const prMatches = [];
  try {
    // Optimistically fetch only the first 50 open PRs using GraphQL to minimize
    // API quota usage. Fallback to REST if no matching PRs are found.
    const gqlCacheKey = `${repo}-pr-graphql-snapshot`;
    const gqlResp = await cacheFetch(gqlCacheKey, () => octokitGraphql(`
          query($owner: String!, $repo: String!) {
            repository(owner: $owner, name: $repo) {
              pullRequests(first: 50, states: OPEN, orderBy: {field: CREATED_AT, direction: DESC}) {
                nodes {
                  number
                  title
                  mergeStateStatus
                  headRefName
                  baseRefName
                }
              }
            }
          }
          `, {
      owner,
      repo
    }));
    const nodes = gqlResp?.repository?.pullRequests?.nodes;
    if (nodes) {
      for (let i = 0, {
          length
        } = nodes; i < length; i += 1) {
        const node = nodes[i];
        if (titlePattern.test(node.title)) {
          prMatches.push({
            apiType: 'graphql',
            cacheKey: gqlCacheKey,
            data: gqlResp,
            entry: node,
            index: i,
            parent: nodes,
            props: node
          });
        }
      }
    }
  } catch {}

  // Fallback to REST if GraphQL found no matching PRs.
  let allOpenPrs;
  if (!prMatches.length) {
    const cacheKey = `${repo}-open-prs`;
    try {
      allOpenPrs = await cacheFetch(cacheKey, async () => await octokit.paginate(octokit.pulls.list, {
        owner,
        repo,
        state: 'open',
        per_page: 100
      }));
    } catch {}
    if (allOpenPrs) {
      for (let i = 0, {
          length
        } = allOpenPrs; i < length; i += 1) {
        const pr = allOpenPrs[i];
        if (titlePattern.test(pr.title)) {
          prMatches.push({
            apiType: 'rest',
            cacheKey,
            data: allOpenPrs,
            entry: pr,
            index: i,
            parent: allOpenPrs,
            props: {
              baseRefName: pr.base.ref,
              headRefName: pr.head.ref,
              // Upper cased mergeable_state is equivalent to mergeStateStatus.
              // https://docs.github.com/en/rest/pulls/pulls?apiVersion=2022-11-28#get-a-pull-request
              mergeStateStatus: pr.mergeable_state?.toUpperCase?.() ?? 'UNKNOWN',
              number: pr.number,
              title: pr.title
            }
          });
        }
      }
    }
  }
  if (!prMatches.length) {
    return;
  }
  const cachesToSave = new Map();
  await Promise.allSettled(prMatches.map(async match => {
    const {
      props
    } = match;
    const versionText = /(?<= to )\S+/.exec(props.title)?.[0];
    const {
      number: prNum
    } = props;
    const prRef = `PR #${prNum}`;
    const prVersion = vendor.semverExports.coerce(versionText);
    // Close older PRs.
    if (prVersion && vendor.semverExports.lt(prVersion, newVersion)) {
      try {
        await octokit.pulls.update({
          owner,
          repo,
          pull_number: prNum,
          state: 'closed'
        });
        debug.debugLog(`Closed ${prRef} for older version ${prVersion}.`);
        // Remove entry from parent object.
        match.parent.splice(match.index, 1);
        // Mark cache to be saved.
        cachesToSave.set(match.cacheKey, match.data);
      } catch (e) {
        debug.debugLog(`Failed to close ${prRef}: ${e?.message || 'Unknown error'}`);
        return;
      }
    }
    // Update stale PRs.
    // https://docs.github.com/en/graphql/reference/enums#mergestatestatus
    if (props.mergeStateStatus === 'BEHIND') {
      try {
        await octokit.repos.merge({
          owner,
          repo,
          base: props.headRefName,
          head: props.baseRefName
        });
        debug.debugLog(`Updated stale ${prRef}.`);
        // Update entry entry.
        if (match.apiType === 'graphql') {
          match.entry.mergeStateStatus = 'CLEAN';
        } else if (match.apiType === 'rest') {
          match.entry.mergeable_state = 'clean';
        }
        // Mark cache to be saved.
        cachesToSave.set(match.cacheKey, match.data);
      } catch (e) {
        const message = e?.message || 'Unknown error';
        debug.debugLog(`Failed to update ${prRef}: ${message}`);
      }
    }
  }));
  if (cachesToSave.size) {
    await Promise.allSettled([...cachesToSave].map(({
      0: key,
      1: data
    }) => writeCache(key, data)));
  }
}
async function enablePrAutoMerge({
  node_id: prId
}) {
  const octokitGraphql = getOctokitGraphql();
  let error;
  try {
    const response = await octokitGraphql(`
      mutation EnableAutoMerge($pullRequestId: ID!) {
        enablePullRequestAutoMerge(input: {
          pullRequestId: $pullRequestId,
          mergeMethod: SQUASH
        }) {
          pullRequest {
            number
          }
        }
      }`, {
      pullRequestId: prId
    });
    const respPrNumber = response?.enablePullRequestAutoMerge?.pullRequest?.number;
    if (respPrNumber) {
      return {
        enabled: true
      };
    }
  } catch (e) {
    error = e;
  }
  if (error instanceof vendor.GraphqlResponseError && Array.isArray(error.errors)) {
    const details = error.errors.map(({
      message
    }) => message.trim());
    return {
      enabled: false,
      details
    };
  }
  return {
    enabled: false
  };
}
function getGitHubEnvRepoInfo() {
  // Lazily access constants.ENV.GITHUB_REPOSITORY.
  const ownerSlashRepo = constants.ENV.GITHUB_REPOSITORY;
  const slashIndex = ownerSlashRepo.indexOf('/');
  if (slashIndex === -1) {
    return null;
  }
  return {
    owner: ownerSlashRepo.slice(0, slashIndex),
    repo: ownerSlashRepo.slice(slashIndex + 1)
  };
}
async function openPr(owner, repo, branch, purl, newVersion, options) {
  const {
    baseBranch = 'main',
    workspaceName
  } = {
    __proto__: null,
    ...options
  };
  // Lazily access constants.ENV.GITHUB_ACTIONS.
  if (!constants.ENV.GITHUB_ACTIONS) {
    debug.debugLog('Missing GITHUB_ACTIONS environment variable.');
    return null;
  }
  const octokit = getOctokit();
  try {
    return await octokit.pulls.create({
      owner,
      repo,
      title: getSocketPullRequestTitle(purl, newVersion, workspaceName),
      head: branch,
      base: baseBranch,
      body: getSocketPullRequestBody(purl, newVersion, workspaceName)
    });
  } catch (e) {
    let message = `Failed to open pull request`;
    const errors = e instanceof vendor.RequestError ? e.response?.data?.['errors'] : undefined;
    if (Array.isArray(errors)) {
      const details = errors.map(d => `- ${d.message?.trim() ?? `${d.resource}.${d.field} (${d.code})`}`).join('\n');
      message += `:\n${details}`;
    }
    debug.debugLog(message);
  }
  return null;
}
async function prExistForBranch(owner, repo, branch) {
  const octokit = getOctokit();
  try {
    const {
      data: prs
    } = await octokit.pulls.list({
      owner,
      repo,
      head: `${owner}:${branch}`,
      state: 'open',
      per_page: 1
    });
    return prs.length > 0;
  } catch {}
  return false;
}
async function setGitRemoteGitHubRepoUrl(owner, repo, token, cwd = process.cwd()) {
  const stdioIgnoreOptions = {
    cwd,
    stdio: 'ignore'
  };
  const url = `https://x-access-token:${token}@github.com/${owner}/${repo}`;
  await spawn.spawn('git', ['remote', 'set-url', 'origin', url], stdioIgnoreOptions);
}

const CMD_NAME$1 = 'socket fix';
function getAlertsMapOptions(options = {}) {
  return {
    __proto__: null,
    consolidate: true,
    nothrow: true,
    ...options,
    include: {
      __proto__: null,
      existing: true,
      unfixable: false,
      upgradable: false,
      ...options?.include
    }
  };
}
function normalizeFixOptions(options_) {
  const options = {
    __proto__: null,
    ...options_
  };
  if (typeof options.autopilot !== 'boolean') {
    options.autopilot = false;
  }
  if (typeof options.autoMerge !== 'boolean') {
    options.autoMerge = !!options.autopilot;
  }
  if (typeof options.cwd !== 'string') {
    options.cwd = process.cwd();
  }
  const limit = typeof options.limit === 'number' ? options.limit : parseInt(`${options.limit || ''}`, 10);
  options.limit = Number.isNaN(limit) ? Infinity : limit;
  options.purls = Array.isArray(options.purls) ? options.purls.flatMap(p => p.split(/, */)) : [];
  if (typeof options.rangeStyle !== 'string') {
    options.rangeStyle = 'preserve';
  }
  if (typeof options.test !== 'boolean') {
    options.test = !!options.autopilot || !!options.testScript;
  }
  if (typeof options.testScript !== 'string') {
    options.testScript = 'test';
  }
  return options;
}

const {
  DRY_RUN_NOT_SAVING: DRY_RUN_NOT_SAVING$1,
  NPM: NPM$a
} = constants;
async function install$1(arb, options) {
  const {
    cwd = process.cwd()
  } = {
    __proto__: null,
    ...options
  };
  try {
    const newArb = new shadowInject.Arborist({
      path: cwd
    });
    newArb.idealTree = await arb.buildIdealTree();
    const actualTree = await newArb.reify();
    arb.actualTree = actualTree;
    return actualTree;
  } catch {}
  return null;
}
async function npmFix(pkgEnvDetails, {
  autoMerge,
  cwd,
  dryRun,
  limit,
  purls,
  rangeStyle,
  test,
  testScript
}) {
  if (dryRun) {
    logger.logger.log(DRY_RUN_NOT_SAVING$1);
    return;
  }
  // Lazily access constants.spinner.
  const {
    spinner
  } = constants;
  spinner?.start();
  const {
    pkgPath: rootPath
  } = pkgEnvDetails;
  const arb = new shadowInject.SafeArborist({
    path: rootPath,
    ...shadowInject.SAFE_ARBORIST_REIFY_OPTIONS_OVERRIDES
  });
  // Calling arb.reify() creates the arb.diff object, nulls-out arb.idealTree,
  // and populates arb.actualTree.
  let actualTree = await arb.reify();
  let alertsMap;
  try {
    alertsMap = purls.length ? await utils.getAlertsMapFromPurls(purls, getAlertsMapOptions({
      limit
    })) : await shadowInject.getAlertsMapFromArborist(arb, getAlertsMapOptions({
      limit
    }));
  } catch (e) {
    spinner?.stop();
    logger.logger.error(e?.message || 'Unknown Socket batch PURL API error.');
    return;
  }
  const infoByPkgName = utils.getCveInfoFromAlertsMap(alertsMap, {
    limit
  });
  if (!infoByPkgName) {
    spinner?.stop();
    logger.logger.info('No fixable vulns found.');
    return;
  }

  // Lazily access constants.ENV properties.
  const token = constants.ENV.SOCKET_CLI_GITHUB_TOKEN;
  const isCi = !!(constants.ENV.CI && constants.ENV.GITHUB_ACTIONS && constants.ENV.GITHUB_REPOSITORY && token);
  const baseBranch = isCi ? getBaseGitBranch() : '';
  const workspacePkgJsonPaths = await utils.globWorkspace(pkgEnvDetails.agent, rootPath);
  const pkgJsonPaths = [...workspacePkgJsonPaths,
  // Process the workspace root last since it will add an override to package.json.
  pkgEnvDetails.editablePkgJson.filename];
  const handleInstallFail = () => {
    logger.logger.error(`Unexpected condition: ${pkgEnvDetails.agent} install failed.\n`);
    logger.logger.dedent();
    spinner?.dedent();
  };
  spinner?.stop();
  let count = 0;
  const sortedInfoEntries = [...infoByPkgName.entries()].sort((a, b) => sorts.naturalCompare(a[0], b[0]));
  infoEntriesLoop: for (let i = 0, {
      length
    } = sortedInfoEntries; i < length; i += 1) {
    const isLastInfoEntry = i === length - 1;
    const {
      0: name,
      1: infos
    } = sortedInfoEntries[i];
    logger.logger.log(`Processing vulns for ${name}:`);
    logger.logger.indent();
    spinner?.indent();
    if (registry.getManifestData(NPM$a, name)) {
      debug.debugLog(`Socket Optimize package exists for ${name}.`);
    }
    // eslint-disable-next-line no-await-in-loop
    const packument = await packages.fetchPackagePackument(name);
    if (!packument) {
      logger.logger.warn(`Unexpected condition: No packument found for ${name}.\n`);
      logger.logger.dedent();
      spinner?.dedent();
      continue infoEntriesLoop;
    }
    const availableVersions = Object.keys(packument.versions);
    const warningsForAfter = new Set();

    // eslint-disable-next-line no-unused-labels
    for (let j = 0, {
        length: length_j
      } = pkgJsonPaths; j < length_j; j += 1) {
      const isLastPkgJsonPath = j === length_j - 1;
      const pkgJsonPath = pkgJsonPaths[j];
      const pkgPath = path.dirname(pkgJsonPath);
      const isWorkspaceRoot = pkgJsonPath === pkgEnvDetails.editablePkgJson.filename;
      const workspaceName = isWorkspaceRoot ? 'root' : path.relative(rootPath, pkgPath);
      const oldVersions = arrays.arrayUnique(shadowInject.findPackageNodes(actualTree, name).map(n => n.target?.version ?? n.version).filter(Boolean));
      if (!oldVersions.length) {
        logger.logger.warn(`Unexpected condition: Lockfile entries not found for ${name}.\n`);
        // Skip to next package.
        logger.logger.dedent();
        spinner?.dedent();
        continue infoEntriesLoop;
      }

      // Always re-read the editable package.json to avoid stale mutations
      // across iterations.
      // eslint-disable-next-line no-await-in-loop
      const editablePkgJson = await packages.readPackageJson(pkgJsonPath, {
        editable: true
      });
      let hasAnnouncedWorkspace = false;
      let workspaceLogCallCount = logger.logger.logCallCount;
      if (debug.isDebug()) {
        debug.debugLog(`Checking workspace: ${workspaceName}`);
        hasAnnouncedWorkspace = true;
        workspaceLogCallCount = logger.logger.logCallCount;
      }
      oldVersionsLoop: for (const oldVersion of oldVersions) {
        const oldId = `${name}@${oldVersion}`;
        const oldPurl = utils.idToPurl(oldId);
        const node = shadowInject.findPackageNode(actualTree, name, oldVersion);
        if (!node) {
          if (hasAnnouncedWorkspace) {
            logger.logger.warn(`Unexpected condition: Arborist node not found, skipping ${oldId}.`);
          }
          continue oldVersionsLoop;
        }
        infosLoop: for (const {
          firstPatchedVersionIdentifier,
          vulnerableVersionRange
        } of infos.values()) {
          const newVersion = shadowInject.findBestPatchVersion(node, availableVersions, vulnerableVersionRange);
          const newVersionPackument = newVersion ? packument.versions[newVersion] : undefined;
          if (!(newVersion && newVersionPackument)) {
            warningsForAfter.add(`${oldId} not updated: requires >=${firstPatchedVersionIdentifier}`);
            continue infosLoop;
          }
          const newVersionRange = utils.applyRange(oldVersion, newVersion, rangeStyle);
          const newId = `${name}@${newVersionRange}`;
          const revertData = {
            ...(editablePkgJson.content.dependencies && {
              dependencies: {
                ...editablePkgJson.content.dependencies
              }
            }),
            ...(editablePkgJson.content.optionalDependencies && {
              optionalDependencies: {
                ...editablePkgJson.content.optionalDependencies
              }
            }),
            ...(editablePkgJson.content.peerDependencies && {
              peerDependencies: {
                ...editablePkgJson.content.peerDependencies
              }
            })
          };
          shadowInject.updateNode(node, newVersion, newVersionPackument);
          shadowInject.updatePackageJsonFromNode(editablePkgJson,
          // eslint-disable-next-line no-await-in-loop
          await arb.buildIdealTree(), node, newVersion, rangeStyle);
          // eslint-disable-next-line no-await-in-loop
          if (!(await editablePkgJson.save({
            ignoreWhitespace: true
          }))) {
            debug.debugLog(`${workspaceName}/package.json not changed, skipping.`);
            // Reset things just in case.
            if (isCi) {
              // eslint-disable-next-line no-await-in-loop
              await gitResetAndClean(baseBranch, cwd);
            }
            continue infosLoop;
          }
          if (!hasAnnouncedWorkspace) {
            hasAnnouncedWorkspace = true;
            workspaceLogCallCount = logger.logger.logCallCount;
          }
          spinner?.start();
          spinner?.info(`Installing ${newId} in ${workspaceName}.`);
          let error;
          let errored = false;
          try {
            // eslint-disable-next-line no-await-in-loop
            const maybeActualTree = await install$1(arb, {
              cwd
            });
            if (maybeActualTree) {
              actualTree = maybeActualTree;
              if (test) {
                spinner?.info(`Testing ${newId} in ${workspaceName}.`);
                // eslint-disable-next-line no-await-in-loop
                await npm.runScript(testScript, [], {
                  spinner,
                  stdio: 'ignore'
                });
              }
              spinner?.success(`Fixed ${name} in ${workspaceName}.`);
            } else {
              errored = true;
            }
          } catch (e) {
            errored = true;
            error = e;
          }
          spinner?.stop();
          if (!errored && isCi) {
            try {
              const moddedFilepaths =
              // eslint-disable-next-line no-await-in-loop
              (await gitUnstagedModifiedFiles(cwd)).filter(p => {
                const basename = path.basename(p);
                return basename === 'package.json' || basename === 'package-lock.json';
              });
              if (!moddedFilepaths.length) {
                logger.logger.warn('Unexpected condition: Nothing to commit, skipping PR creation.');
                continue infosLoop;
              }
              const repoInfo = getGitHubEnvRepoInfo();
              const branch = getSocketBranchName(oldPurl, newVersion, workspaceName);
              let skipPr = false;
              if (
              // eslint-disable-next-line no-await-in-loop
              await prExistForBranch(repoInfo.owner, repoInfo.repo, branch)) {
                skipPr = true;
                debug.debugLog(`Branch "${branch}" exists, skipping PR creation.`);
              }
              // eslint-disable-next-line no-await-in-loop
              else if (await gitRemoteBranchExists(branch, cwd)) {
                skipPr = true;
                debug.debugLog(`Remote branch "${branch}" exists, skipping PR creation.`);
              } else if (
              // eslint-disable-next-line no-await-in-loop
              !(await gitCreateAndPushBranch(branch, getSocketCommitMessage(oldPurl, newVersion, workspaceName), moddedFilepaths, cwd))) {
                skipPr = true;
                logger.logger.warn('Unexpected condition: Push failed, skipping PR creation.');
              }
              if (skipPr) {
                // eslint-disable-next-line no-await-in-loop
                await gitResetAndClean(baseBranch, cwd);
                // eslint-disable-next-line no-await-in-loop
                const maybeActualTree = await install$1(arb, {
                  cwd
                });
                if (!maybeActualTree) {
                  // Exit early if install fails.
                  handleInstallFail();
                  return;
                }
                actualTree = maybeActualTree;
                continue infosLoop;
              }

              // eslint-disable-next-line no-await-in-loop
              await Promise.allSettled([setGitRemoteGitHubRepoUrl(repoInfo.owner, repoInfo.repo, token, cwd), cleanupOpenPrs(repoInfo.owner, repoInfo.repo, oldPurl, newVersion, {
                workspaceName
              })]);
              // eslint-disable-next-line no-await-in-loop
              const prResponse = await openPr(repoInfo.owner, repoInfo.repo, branch, oldPurl, newVersion, {
                baseBranch,
                cwd,
                workspaceName
              });
              if (prResponse) {
                const {
                  data
                } = prResponse;
                const prRef = `PR #${data.number}`;
                logger.logger.success(`Opened ${prRef}.`);
                if (autoMerge) {
                  logger.logger.indent();
                  spinner?.indent();
                  // eslint-disable-next-line no-await-in-loop
                  const {
                    details,
                    enabled
                  } = await enablePrAutoMerge(data);
                  if (enabled) {
                    logger.logger.info(`Auto-merge enabled for ${prRef}.`);
                  } else {
                    const message = `Failed to enable auto-merge for ${prRef}${details ? `:\n${details.map(d => ` - ${d}`).join('\n')}` : '.'}`;
                    logger.logger.error(message);
                  }
                  logger.logger.dedent();
                  spinner?.dedent();
                }
              }
            } catch (e) {
              error = e;
              errored = true;
            }
          }
          if (isCi) {
            spinner?.start();
            // eslint-disable-next-line no-await-in-loop
            await gitResetAndClean(baseBranch, cwd);
            // eslint-disable-next-line no-await-in-loop
            const maybeActualTree = await install$1(arb, {
              cwd
            });
            spinner?.stop();
            if (maybeActualTree) {
              actualTree = maybeActualTree;
            } else {
              errored = true;
            }
          }
          if (errored) {
            if (!isCi) {
              spinner?.start();
              editablePkgJson.update(revertData);
              // eslint-disable-next-line no-await-in-loop
              await Promise.all([utils.removeNodeModules(cwd), editablePkgJson.save({
                ignoreWhitespace: true
              })]);
              // eslint-disable-next-line no-await-in-loop
              const maybeActualTree = await install$1(arb, {
                cwd
              });
              spinner?.stop();
              if (!maybeActualTree) {
                // Exit early if install fails.
                handleInstallFail();
                return;
              }
              actualTree = maybeActualTree;
            }
            logger.logger.fail(`Update failed for ${oldId} in ${workspaceName}.`, error);
          }
          if (++count >= limit) {
            logger.logger.dedent();
            spinner?.dedent();
            break infoEntriesLoop;
          }
        }
      }
      if (!isLastPkgJsonPath && logger.logger.logCallCount > workspaceLogCallCount) {
        logger.logger.logNewline();
      }
    }
    for (const warningText of warningsForAfter) {
      logger.logger.warn(warningText);
    }
    if (!isLastInfoEntry) {
      logger.logger.logNewline();
    }
    logger.logger.dedent();
    spinner?.dedent();
  }
  spinner?.stop();
}

const {
  DRY_RUN_NOT_SAVING,
  NPM: NPM$9,
  OVERRIDES: OVERRIDES$2,
  PNPM: PNPM$7
} = constants;
async function getActualTree(cwd = process.cwd()) {
  // @npmcli/arborist DOES have partial support for pnpm structured node_modules
  // folders. However, support is iffy resulting in unhappy path errors and hangs.
  // So, to avoid the unhappy path, we restrict our usage to --dry-run loading
  // of the node_modules folder.
  const arb = new shadowInject.SafeArborist({
    path: cwd,
    ...shadowInject.SAFE_ARBORIST_REIFY_OPTIONS_OVERRIDES
  });
  return await arb.loadActual();
}
async function install(pkgEnvDetails, options) {
  const {
    args,
    cwd,
    spinner
  } = {
    __proto__: null,
    ...options
  };
  try {
    await utils.runAgentInstall(pkgEnvDetails, {
      args: [...(args ?? []),
      // Enable pnpm updates to pnpm-lock.yaml in CI environments.
      // https://pnpm.io/cli/install#--frozen-lockfile
      '--no-frozen-lockfile',
      // Enable a non-interactive pnpm install
      // https://github.com/pnpm/pnpm/issues/6778
      '--config.confirmModulesPurge=false'],
      spinner,
      stdio: debug.isDebug() ? 'inherit' : 'ignore'
    });
    return await getActualTree(cwd);
  } catch {}
  return null;
}
async function pnpmFix(pkgEnvDetails, {
  autoMerge,
  cwd,
  dryRun,
  limit,
  purls,
  rangeStyle,
  test,
  testScript
}) {
  if (dryRun) {
    logger.logger.log(DRY_RUN_NOT_SAVING);
    return;
  }
  // Lazily access constants.spinner.
  const {
    spinner
  } = constants;
  const {
    pkgPath: rootPath
  } = pkgEnvDetails;
  spinner?.start();
  let actualTree;
  const lockfilePath = path.join(rootPath, 'pnpm-lock.yaml');
  let lockfile = await utils.readPnpmLockfile(lockfilePath);

  // If pnpm-lock.yaml does NOT exist then install with pnpm to create it.
  if (!lockfile) {
    const maybeActualTree = await install(pkgEnvDetails, {
      cwd,
      spinner
    });
    if (maybeActualTree) {
      actualTree = maybeActualTree;
      lockfile = await utils.readPnpmLockfile(lockfilePath);
    }
  }
  // Update pnpm-lock.yaml if its version is older than what the installed pnpm
  // produces.
  if (lockfile && pkgEnvDetails.agentVersion.major >= 10 && utils.parsePnpmLockfileVersion(lockfile.lockfileVersion).major <= 6) {
    const maybeActualTree = await install(pkgEnvDetails, {
      args: ['--lockfile-only'],
      cwd,
      spinner
    });
    if (maybeActualTree) {
      actualTree = maybeActualTree;
      lockfile = await utils.readPnpmLockfile(lockfilePath);
    }
  }

  // Exit early if pnpm-lock.yaml is not found.
  if (!lockfile) {
    spinner?.stop();
    logger.logger.error('Required pnpm-lock.yaml not found.');
    return;
  }
  let alertsMap;
  try {
    alertsMap = purls.length ? await utils.getAlertsMapFromPurls(purls, getAlertsMapOptions({
      limit
    })) : await utils.getAlertsMapFromPnpmLockfile(lockfile, getAlertsMapOptions({
      limit
    }));
  } catch (e) {
    spinner?.stop();
    logger.logger.error(e?.message || 'Unknown Socket batch PURL API error.');
    return;
  }
  const infoByPkgName = utils.getCveInfoFromAlertsMap(alertsMap, {
    limit
  });
  if (!infoByPkgName) {
    spinner?.stop();
    logger.logger.info('No fixable vulns found.');
    return;
  }

  // Lazily access constants.ENV properties.
  const token = constants.ENV.SOCKET_CLI_GITHUB_TOKEN;
  const isCi = !!(constants.ENV.CI && constants.ENV.GITHUB_ACTIONS && constants.ENV.GITHUB_REPOSITORY && token);
  const baseBranch = isCi ? getBaseGitBranch() : '';
  const workspacePkgJsonPaths = await utils.globWorkspace(pkgEnvDetails.agent, rootPath);
  const pkgJsonPaths = [...workspacePkgJsonPaths,
  // Process the workspace root last since it will add an override to package.json.
  pkgEnvDetails.editablePkgJson.filename];
  const handleInstallFail = () => {
    logger.logger.error(`Unexpected condition: ${pkgEnvDetails.agent} install failed.\n`);
    logger.logger.dedent();
    spinner?.dedent();
  };
  spinner?.stop();
  let count = 0;
  const sortedInfoEntries = [...infoByPkgName.entries()].sort((a, b) => sorts.naturalCompare(a[0], b[0]));
  infoEntriesLoop: for (let i = 0, {
      length
    } = sortedInfoEntries; i < length; i += 1) {
    const isLastInfoEntry = i === length - 1;
    const {
      0: name,
      1: infos
    } = sortedInfoEntries[i];
    logger.logger.log(`Processing vulns for ${name}:`);
    logger.logger.indent();
    spinner?.indent();
    if (registry.getManifestData(NPM$9, name)) {
      debug.debugLog(`Socket Optimize package exists for ${name}.`);
    }
    // eslint-disable-next-line no-await-in-loop
    const packument = await packages.fetchPackagePackument(name);
    if (!packument) {
      logger.logger.warn(`Unexpected condition: No packument found for ${name}.\n`);
      logger.logger.dedent();
      spinner?.dedent();
      continue infoEntriesLoop;
    }
    const availableVersions = Object.keys(packument.versions);
    const warningsForAfter = new Set();

    // eslint-disable-next-line no-unused-labels
    for (let j = 0, {
        length: length_j
      } = pkgJsonPaths; j < length_j; j += 1) {
      const isLastPkgJsonPath = j === length_j - 1;
      const pkgJsonPath = pkgJsonPaths[j];
      const pkgPath = path.dirname(pkgJsonPath);
      const isWorkspaceRoot = pkgJsonPath === pkgEnvDetails.editablePkgJson.filename;
      const workspaceName = isWorkspaceRoot ? 'root' : path.relative(rootPath, pkgPath);

      // actualTree may not be defined on the first iteration of pkgJsonPathsLoop.
      if (!actualTree) {
        const maybeActualTree = fs$1.existsSync(path.join(rootPath, 'node_modules')) ?
        // eslint-disable-next-line no-await-in-loop
        await getActualTree(cwd) :
        // eslint-disable-next-line no-await-in-loop
        await install(pkgEnvDetails, {
          cwd,
          spinner
        });
        if (maybeActualTree) {
          actualTree = maybeActualTree;
        }
      }
      if (!actualTree) {
        // Exit early if install fails.
        handleInstallFail();
        return;
      }
      const oldVersions = arrays.arrayUnique(shadowInject.findPackageNodes(actualTree, name).map(n => n.version).filter(Boolean));
      if (!oldVersions.length) {
        logger.logger.warn(`Unexpected condition: Lockfile entries not found for ${name}.\n`);
        // Skip to next package.
        logger.logger.dedent();
        spinner?.dedent();
        continue infoEntriesLoop;
      }

      // Always re-read the editable package.json to avoid stale mutations
      // across iterations.
      // eslint-disable-next-line no-await-in-loop
      const editablePkgJson = await packages.readPackageJson(pkgJsonPath, {
        editable: true
      });
      // Get current overrides for revert logic.
      const oldPnpmSection = editablePkgJson.content[PNPM$7];
      const oldOverrides = oldPnpmSection?.[OVERRIDES$2];
      let hasAnnouncedWorkspace = false;
      let workspaceLogCallCount = logger.logger.logCallCount;
      if (debug.isDebug()) {
        debug.debugLog(`Checking workspace: ${workspaceName}`);
        hasAnnouncedWorkspace = true;
        workspaceLogCallCount = logger.logger.logCallCount;
      }
      oldVersionsLoop: for (const oldVersion of oldVersions) {
        const oldId = `${name}@${oldVersion}`;
        const oldPurl = utils.idToPurl(oldId);
        const node = shadowInject.findPackageNode(actualTree, name, oldVersion);
        if (!node) {
          if (hasAnnouncedWorkspace) {
            logger.logger.warn(`Unexpected condition: Arborist node not found, skipping ${oldId}.`);
          }
          continue oldVersionsLoop;
        }
        infosLoop: for (const {
          firstPatchedVersionIdentifier,
          vulnerableVersionRange
        } of infos.values()) {
          const newVersion = shadowInject.findBestPatchVersion(node, availableVersions, vulnerableVersionRange);
          const newVersionPackument = newVersion ? packument.versions[newVersion] : undefined;
          if (!(newVersion && newVersionPackument)) {
            warningsForAfter.add(`${oldId} not updated: requires >=${firstPatchedVersionIdentifier}`);
            continue infosLoop;
          }
          const overrideKey = `${name}@${vulnerableVersionRange}`;
          const newVersionRange = utils.applyRange(oldOverrides?.[overrideKey] ?? oldVersion, newVersion, rangeStyle);
          const newId = `${name}@${newVersionRange}`;
          const updateData = isWorkspaceRoot ? {
            [PNPM$7]: {
              ...oldPnpmSection,
              [OVERRIDES$2]: {
                ...oldOverrides,
                [overrideKey]: newVersionRange
              }
            }
          } : undefined;
          const revertData = {
            ...(isWorkspaceRoot ? {
              [PNPM$7]: {
                ...oldPnpmSection,
                [OVERRIDES$2]: oldOverrides && Object.keys(oldOverrides).length > 1 ? {
                  ...oldOverrides,
                  [overrideKey]: undefined
                } : undefined
              }
            } : {}),
            ...(editablePkgJson.content.dependencies && {
              dependencies: {
                ...editablePkgJson.content.dependencies
              }
            }),
            ...(editablePkgJson.content.optionalDependencies && {
              optionalDependencies: {
                ...editablePkgJson.content.optionalDependencies
              }
            }),
            ...(editablePkgJson.content.peerDependencies && {
              peerDependencies: {
                ...editablePkgJson.content.peerDependencies
              }
            })
          };
          if (updateData) {
            editablePkgJson.update(updateData);
          }
          shadowInject.updatePackageJsonFromNode(editablePkgJson, actualTree, node, newVersion, rangeStyle);
          // eslint-disable-next-line no-await-in-loop
          if (!(await editablePkgJson.save({
            ignoreWhitespace: true
          }))) {
            debug.debugLog(`${workspaceName}/package.json not changed, skipping.`);
            // Reset things just in case.
            if (isCi) {
              // eslint-disable-next-line no-await-in-loop
              await gitResetAndClean(baseBranch, cwd);
            }
            continue infosLoop;
          }
          if (!hasAnnouncedWorkspace) {
            hasAnnouncedWorkspace = true;
            workspaceLogCallCount = logger.logger.logCallCount;
          }
          spinner?.start();
          spinner?.info(`Installing ${newId} in ${workspaceName}.`);
          let error;
          let errored = false;
          try {
            // eslint-disable-next-line no-await-in-loop
            const maybeActualTree = await install(pkgEnvDetails, {
              cwd,
              spinner
            });
            if (maybeActualTree) {
              actualTree = maybeActualTree;
              if (test) {
                spinner?.info(`Testing ${newId} in ${workspaceName}.`);
                // eslint-disable-next-line no-await-in-loop
                await npm.runScript(testScript, [], {
                  spinner,
                  stdio: 'ignore'
                });
              }
              spinner?.success(`Fixed ${name} in ${workspaceName}.`);
            } else {
              errored = true;
            }
          } catch (e) {
            error = e;
            errored = true;
          }
          spinner?.stop();
          if (!errored && isCi) {
            try {
              const moddedFilepaths =
              // eslint-disable-next-line no-await-in-loop
              (await gitUnstagedModifiedFiles(cwd)).filter(p => {
                const basename = path.basename(p);
                return basename === 'package.json' || basename === 'pnpm-lock.yaml';
              });
              if (!moddedFilepaths.length) {
                logger.logger.warn('Unexpected condition: Nothing to commit, skipping PR creation.');
                continue infosLoop;
              }
              const repoInfo = getGitHubEnvRepoInfo();
              const branch = getSocketBranchName(oldPurl, newVersion, workspaceName);
              let skipPr = false;
              if (
              // eslint-disable-next-line no-await-in-loop
              await prExistForBranch(repoInfo.owner, repoInfo.repo, branch)) {
                skipPr = true;
                debug.debugLog(`Branch "${branch}" exists, skipping PR creation.`);
              }
              // eslint-disable-next-line no-await-in-loop
              else if (await gitRemoteBranchExists(branch, cwd)) {
                skipPr = true;
                debug.debugLog(`Remote branch "${branch}" exists, skipping PR creation.`);
              } else if (
              // eslint-disable-next-line no-await-in-loop
              !(await gitCreateAndPushBranch(branch, getSocketCommitMessage(oldPurl, newVersion, workspaceName), moddedFilepaths, cwd))) {
                skipPr = true;
                logger.logger.warn('Unexpected condition: Push failed, skipping PR creation.');
              }
              if (skipPr) {
                // eslint-disable-next-line no-await-in-loop
                await gitResetAndClean(baseBranch, cwd);
                // eslint-disable-next-line no-await-in-loop
                const maybeActualTree = await install(pkgEnvDetails, {
                  cwd,
                  spinner
                });
                if (!maybeActualTree) {
                  // Exit early if install fails.
                  handleInstallFail();
                  return;
                }
                actualTree = maybeActualTree;
                continue infosLoop;
              }

              // eslint-disable-next-line no-await-in-loop
              await Promise.allSettled([setGitRemoteGitHubRepoUrl(repoInfo.owner, repoInfo.repo, token, cwd), cleanupOpenPrs(repoInfo.owner, repoInfo.repo, oldPurl, newVersion, {
                workspaceName
              })]);
              // eslint-disable-next-line no-await-in-loop
              const prResponse = await openPr(repoInfo.owner, repoInfo.repo, branch, oldPurl, newVersion, {
                baseBranch,
                cwd,
                workspaceName
              });
              if (prResponse) {
                const {
                  data
                } = prResponse;
                const prRef = `PR #${data.number}`;
                logger.logger.success(`Opened ${prRef}.`);
                if (autoMerge) {
                  logger.logger.indent();
                  spinner?.indent();
                  // eslint-disable-next-line no-await-in-loop
                  const {
                    details,
                    enabled
                  } = await enablePrAutoMerge(data);
                  if (enabled) {
                    logger.logger.info(`Auto-merge enabled for ${prRef}.`);
                  } else {
                    const message = `Failed to enable auto-merge for ${prRef}${details ? `:\n${details.map(d => ` - ${d}`).join('\n')}` : '.'}`;
                    logger.logger.error(message);
                  }
                  logger.logger.dedent();
                  spinner?.dedent();
                }
              }
            } catch (e) {
              error = e;
              errored = true;
            }
          }
          if (isCi) {
            spinner?.start();
            // eslint-disable-next-line no-await-in-loop
            await gitResetAndClean(baseBranch, cwd);
            // eslint-disable-next-line no-await-in-loop
            const maybeActualTree = await install(pkgEnvDetails, {
              cwd,
              spinner
            });
            spinner?.stop();
            if (maybeActualTree) {
              actualTree = maybeActualTree;
            } else {
              errored = true;
            }
          }
          if (errored) {
            if (!isCi) {
              spinner?.start();
              editablePkgJson.update(revertData);
              // eslint-disable-next-line no-await-in-loop
              await Promise.all([utils.removeNodeModules(cwd), editablePkgJson.save({
                ignoreWhitespace: true
              })]);
              // eslint-disable-next-line no-await-in-loop
              const maybeActualTree = await install(pkgEnvDetails, {
                cwd,
                spinner
              });
              spinner?.stop();
              if (!maybeActualTree) {
                // Exit early if install fails.
                handleInstallFail();
                return;
              }
              actualTree = maybeActualTree;
            }
            logger.logger.fail(`Update failed for ${oldId} in ${workspaceName}.`, ...(error ? [error] : []));
          }
          if (++count >= limit) {
            logger.logger.dedent();
            spinner?.dedent();
            break infoEntriesLoop;
          }
        }
      }
      if (!isLastPkgJsonPath && logger.logger.logCallCount > workspaceLogCallCount) {
        logger.logger.logNewline();
      }
    }
    for (const warningText of warningsForAfter) {
      logger.logger.warn(warningText);
    }
    if (!isLastInfoEntry) {
      logger.logger.logNewline();
    }
    logger.logger.dedent();
    spinner?.dedent();
  }
  spinner?.stop();
}

const {
  NPM: NPM$8,
  PNPM: PNPM$6
} = constants;
async function runFix(options_) {
  const options = normalizeFixOptions(options_);
  const pkgEnvDetails = await utils.detectAndValidatePackageEnvironment(options.cwd, {
    cmdName: CMD_NAME$1,
    logger: logger.logger
  });
  if (!pkgEnvDetails) {
    return;
  }
  logger.logger.info(`Fixing packages for ${pkgEnvDetails.agent}.\n`);
  const {
    agent
  } = pkgEnvDetails;
  if (agent === NPM$8) {
    await npmFix(pkgEnvDetails, options);
  } else if (agent === PNPM$6) {
    await pnpmFix(pkgEnvDetails, options);
  }
}

const config$E = {
  commandName: 'fix',
  description: 'Update dependencies with "fixable" Socket alerts',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    autoMerge: {
      type: 'boolean',
      default: false,
      description: `Enable auto-merge for pull requests that Socket opens.\n                        See ${vendor.terminalLinkExports('GitHub documentation', 'https://docs.github.com/en/repositories/configuring-branches-and-merges-in-your-repository/configuring-pull-request-merges/managing-auto-merge-for-pull-requests-in-your-repository')} for managing auto-merge for pull requests in your repository.`
    },
    autopilot: {
      type: 'boolean',
      default: false,
      description: `Shorthand for --autoMerge --test`
    },
    limit: {
      type: 'number',
      default: Infinity,
      description: 'The number of fixes to attempt at a time'
    },
    purl: {
      type: 'string',
      default: [],
      description: `Provide a list of ${vendor.terminalLinkExports('package URLs', 'https://github.com/package-url/purl-spec?tab=readme-ov-file#purl')} (PURLs) to fix, as either a comma separated value or as multiple flags,\n                        instead of querying the Socket API`,
      isMultiple: true,
      shortFlag: 'p'
    },
    rangeStyle: {
      type: 'string',
      default: 'preserve',
      description: `
                        Define how updated dependency versions should be written in package.json.
                        Available styles:
                          * caret - Use ^ range for compatible updates (e.g. ^1.2.3)
                          * gt - Use > to allow any newer version (e.g. >1.2.3)
                          * gte - Use >= to allow any newer version (e.g. >=1.2.3)
                          * lt - Use < to allow only lower versions (e.g. <1.2.3)
                          * lte - Use <= to allow only lower versions (e.g. <=1.2.3)
                          * pin - Use the exact version (e.g. 1.2.3)
                          * preserve - Retain the existing version range style as-is
                          * tilde - Use ~ range for patch/minor updates (e.g. ~1.2.3)
      `.trim()
    },
    test: {
      type: 'boolean',
      default: false,
      description: 'Verify the fix by running unit tests'
    },
    testScript: {
      type: 'string',
      default: 'test',
      description: 'The test script to run for each fix attempt'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command}

    Options
      ${utils.getFlagListOutput(config.flags, 6)}
  `
};
const cmdFix = {
  description: config$E.description,
  hidden: config$E.hidden,
  run: run$E
};
async function run$E(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$E,
    importMeta,
    parentName
  });
  const {
    json,
    markdown
  } = cli.flags;
  const outputKind = utils.getOutputKind(json, markdown); // TODO: impl json/md further

  const wasValidInput = utils.checkCommandInput(outputKind, {
    test: utils.RangeStyles.includes(cli.flags['rangeStyle']),
    message: `Expecting range style of ${arrays.joinOr(utils.RangeStyles)}`,
    pass: 'ok',
    fail: 'missing'
  });
  if (!wasValidInput) {
    return;
  }
  await runFix({
    autoMerge: Boolean(cli.flags['autoMerge']),
    autopilot: Boolean(cli.flags['autopilot']),
    limit: Number(cli.flags['limit']),
    dryRun: Boolean(cli.flags['dryRun']),
    purls: Array.isArray(cli.flags['purl']) ? cli.flags['purl'] : [],
    rangeStyle: cli.flags['rangeStyle'] ?? undefined,
    test: Boolean(cli.flags['test']),
    testScript: cli.flags['testScript']
  });
}

async function fetchPackageInfo(pkgName, pkgVersion, includeAllIssues) {
  const sockSdkResult = await utils.setupSdk(utils.getPublicToken());
  if (!sockSdkResult.ok) {
    throw new Error('Was unable to setup sdk. Run `socket login` first.');
  }
  const sockSdk = sockSdkResult.data;
  const result = await utils.handleApiCall(sockSdk.getIssuesByNPMPackage(pkgName, pkgVersion), 'package issues');
  const scoreResult = await utils.handleApiCall(sockSdk.getScoreByNPMPackage(pkgName, pkgVersion), 'package score');
  if (!result.ok) {
    utils.handleUnsuccessfulApiResponse('getIssuesByNPMPackage', result.message, result.cause ?? '', result.data?.code ?? 0);
  }
  if (!scoreResult.ok) {
    utils.handleUnsuccessfulApiResponse('getScoreByNPMPackage', scoreResult.message, scoreResult.cause ?? '', scoreResult.data?.code ?? 0);
  }
  const severityCount = utils.getSeverityCount(result.data, includeAllIssues ? undefined : 'high');
  return {
    data: result.data,
    severityCount,
    score: scoreResult.data
  };
}

const {
  NPM: NPM$7
} = registryConstants;
function formatScore$1(score) {
  if (score > 80) {
    return vendor.yoctocolorsCjsExports.green(`${score}`);
  } else if (score < 80 && score > 60) {
    return vendor.yoctocolorsCjsExports.yellow(`${score}`);
  }
  return vendor.yoctocolorsCjsExports.red(`${score}`);
}
function outputPackageIssuesDetails(packageData, outputMarkdown) {
  const issueDetails = packageData.filter(d => d.value?.severity === utils.ALERT_SEVERITY.critical || d.value?.severity === utils.ALERT_SEVERITY.high);
  const uniqueIssueDetails = issueDetails.reduce((acc, issue) => {
    const {
      type
    } = issue;
    if (type) {
      const details = acc.get(type);
      if (details) {
        details.count += 1;
      } else {
        acc.set(type, {
          label: issue.value?.label ?? '',
          count: 1
        });
      }
    }
    return acc;
  }, new Map());
  const format = new utils.ColorOrMarkdown(outputMarkdown);
  for (const [type, details] of uniqueIssueDetails.entries()) {
    const issueWithLink = format.hyperlink(details.label, utils.getSocketDevAlertUrl(type), {
      fallbackToUrl: true
    });
    if (details.count === 1) {
      logger.logger.log(`- ${issueWithLink}`);
    } else {
      logger.logger.log(`- ${issueWithLink}: ${details.count}`);
    }
  }
}
function outputPackageInfo({
  data,
  score,
  severityCount
}, {
  commandName,
  outputKind,
  pkgName,
  pkgVersion
}) {
  if (outputKind === 'json') {
    logger.logger.log(JSON.stringify(data, undefined, 2));
    return;
  }
  if (outputKind === 'markdown') {
    logger.logger.log(`
# Package report for ${pkgName}

Package report card:
    `.trim());
  } else {
    logger.logger.log(`Package report card for ${pkgName}:`);
  }
  const scoreResult = {
    'Supply Chain Risk': Math.floor(score.supplyChainRisk.score * 100),
    Maintenance: Math.floor(score.maintenance.score * 100),
    Quality: Math.floor(score.quality.score * 100),
    Vulnerabilities: Math.floor(score.vulnerability.score * 100),
    License: Math.floor(score.license.score * 100)
  };
  logger.logger.log('\n');
  Object.entries(scoreResult).map(score => logger.logger.log(`- ${score[0]}: ${formatScore$1(score[1])}`));
  logger.logger.log('\n');
  if (objects.hasKeys(severityCount)) {
    if (outputKind === 'markdown') {
      logger.logger.log('# Issues\n');
    }
    logger.logger.log(`Package has these issues: ${utils.formatSeverityCount(severityCount)}\n`);
    outputPackageIssuesDetails(data, outputKind === 'markdown');
  } else {
    logger.logger.log('Package has no issues');
  }
  const format = new utils.ColorOrMarkdown(outputKind === 'markdown');
  const url = utils.getSocketDevPackageOverviewUrl(NPM$7, pkgName, pkgVersion);
  logger.logger.log('\n');
  if (pkgVersion === 'latest') {
    logger.logger.log(`Detailed info on socket.dev: ${format.hyperlink(`${pkgName}`, url, {
      fallbackToUrl: true
    })}`);
  } else {
    logger.logger.log(`Detailed info on socket.dev: ${format.hyperlink(`${pkgName} v${pkgVersion}`, url, {
      fallbackToUrl: true
    })}`);
  }
  if (outputKind !== 'markdown') {
    logger.logger.log(vendor.yoctocolorsCjsExports.dim(`\nOr rerun ${vendor.yoctocolorsCjsExports.italic(commandName)} using the ${vendor.yoctocolorsCjsExports.italic('--json')} flag to get full JSON output`));
  } else {
    logger.logger.log('');
  }
}

async function handlePackageInfo({
  commandName,
  includeAllIssues,
  outputKind,
  pkgName,
  pkgVersion,
  strict
}) {
  const packageData = await fetchPackageInfo(pkgName, pkgVersion, includeAllIssues);
  if (packageData) {
    outputPackageInfo(packageData, {
      commandName,
      outputKind,
      pkgName,
      pkgVersion
    });
    if (strict && objects.hasKeys(packageData.severityCount)) {
      // Let NodeJS exit gracefully but with exit(1)
      process.exitCode = 1;
    }
  }
}

const {
  DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$A
} = constants;
const config$D = {
  commandName: 'info',
  description: 'Look up info regarding a package',
  hidden: true,
  // Deprecated
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags,
    ...utils.validationFlags
  },
  help: (command, config) => utils.isTestingV1() ? 'This command will be removed in v1' : `
    Usage
      $ ${command} <name>

    Note: this command will be deprecated in favor of \`socket package score\` soon

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command} webtorrent
      $ ${command} webtorrent@1.9.1
  `
};
const cmdInfo = {
  description: config$D.description,
  hidden: config$D.hidden,
  run: run$D
};
async function run$D(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$D,
    importMeta,
    parentName
  });
  const {
    all,
    json,
    markdown,
    strict
  } = cli.flags;
  const outputKind = utils.getOutputKind(json, markdown);
  const [rawPkgName = ''] = cli.input;
  const wasValidInput = utils.checkCommandInput(outputKind, {
    test: !!rawPkgName,
    message: 'Expecting a package name',
    pass: 'ok',
    fail: 'missing'
  }, {
    nook: true,
    test: cli.input.length === 1,
    message: 'Can only accept one package at a time',
    pass: 'ok',
    fail: 'got ' + cli.input.length
  }, {
    nook: true,
    test: !json || !markdown,
    message: 'The `--json` and `--markdown` flags can not be used at the same time',
    pass: 'ok',
    fail: 'bad'
  });
  if (!wasValidInput) {
    return;
  }
  const versionSeparator = rawPkgName.lastIndexOf('@');
  const pkgName = versionSeparator < 1 ? rawPkgName : rawPkgName.slice(0, versionSeparator);
  const pkgVersion = versionSeparator < 1 ? 'latest' : rawPkgName.slice(versionSeparator + 1);
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$A);
    return;
  }
  await handlePackageInfo({
    commandName: `${parentName} ${config$D.commandName}`,
    includeAllIssues: Boolean(all),
    outputKind,
    pkgName,
    pkgVersion,
    strict: Boolean(strict)
  });
}

async function outputInstallCompletion(result) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  logger.logger.log('');
  logger.logger.log(`Installation of tab completion for "${result.data.targetName}" finished!`);
  logger.logger.log('');
  result.data.actions.forEach(action => {
    logger.logger.log(`  - ${action}`);
  });
  logger.logger.log('');
  logger.logger.log('Socket tab completion works automatically in new terminals.');
  logger.logger.log('');
  logger.logger.log('Due to a bash limitation, tab completion cannot be enabled in the');
  logger.logger.log('current shell (bash instance) through NodeJS. You must either:');
  logger.logger.log('');
  logger.logger.log('1. Reload your .bashrc script (best):');
  logger.logger.log('');
  logger.logger.log(`   source ~/.bashrc`);
  logger.logger.log('');
  logger.logger.log('2. Run these commands to load the completion script:');
  logger.logger.log('');
  logger.logger.log(`   source ${result.data.targetPath}`);
  logger.logger.log(`   ${result.data.completionCommand}`);
  logger.logger.log('');
  logger.logger.log('3. Or restart bash somehow (restart terminal or run `bash`)');
  logger.logger.log('');
}

async function setupTabCompletion(targetName) {
  const result = utils.getBashrcDetails(targetName);
  if (!result.ok) {
    return result;
  }
  const {
    completionCommand,
    sourcingCommand,
    targetPath,
    toAddToBashrc
  } = result.data;

  // Target dir is something like ~/.local/share/socket/settings/completion (linux)
  const targetDir = path.dirname(targetPath);
  debug.debugLog('Target Path:', targetPath, ', Target Dir:', targetDir);
  if (!fs$1.existsSync(targetDir)) {
    debug.debugLog('Dir does not exist, creating it now...');
    fs$1.mkdirSync(targetDir, {
      recursive: true
    });
  }
  updateInstalledTabCompletionScript(targetPath);
  let bashrcUpdated = false;

  // Add to ~/.bashrc if not already there
  // Lazily access constants.homePath
  const bashrcPath = constants.homePath ? path.join(constants.homePath, '.bashrc') : '';
  const foundBashrc = Boolean(bashrcPath && fs$1.existsSync(bashrcPath));
  if (foundBashrc) {
    const content = fs$1.readFileSync(bashrcPath, 'utf8');
    if (!content.includes(sourcingCommand)) {
      fs$1.appendFileSync(bashrcPath, toAddToBashrc);
      bashrcUpdated = true;
    }
  }
  return {
    ok: true,
    data: {
      actions: [`Installed the tab completion script in ${targetPath}`, bashrcUpdated ? 'Added tab completion loader to ~/.bashrc' : foundBashrc ? 'Tab completion already found in ~/.bashrc' : 'No ~/.bashrc found so tab completion was not completely installed'],
      bashrcPath,
      bashrcUpdated,
      completionCommand,
      foundBashrc,
      sourcingCommand,
      targetName,
      targetPath
    }
  };
}
function getTabCompletionScriptRaw() {
  const sourceDir = path.dirname(require$$0.fileURLToPath((typeof document === 'undefined' ? require$$0.pathToFileURL(__filename).href : (_documentCurrentScript && _documentCurrentScript.tagName.toUpperCase() === 'SCRIPT' && _documentCurrentScript.src || new URL('cli.js', document.baseURI).href))));
  const sourcePath = path.join(sourceDir, 'socket-completion.bash');
  if (!fs$1.existsSync(sourcePath)) {
    return {
      ok: false,
      message: 'Source not found',
      cause: `Unable to find the source tab completion bash script that Socket should ship. Expected to find it in \`${sourcePath}\` but it was not there.`
    };
  }
  return {
    ok: true,
    data: fs$1.readFileSync(sourcePath, 'utf8')
  };
}
function updateInstalledTabCompletionScript(targetPath) {
  const content = getTabCompletionScriptRaw();
  if (!content.ok) {
    return content;
  }

  // Lazily access constants.ENV.INLINED_SOCKET_CLI_VERSION_HASH.
  const CLI_VERSION = constants.ENV.INLINED_SOCKET_CLI_VERSION_HASH;

  // When installing set the current package.json version.
  // Later, we can call _socket_completion_version to get the installed version.
  fs$1.writeFileSync(targetPath, content.data.replaceAll('SOCKET_VERSION_TOKEN', CLI_VERSION), 'utf8');
  return {
    ok: true,
    data: undefined
  };
}

async function handleInstallCompletion(targetName) {
  const result = await setupTabCompletion(targetName);
  await outputInstallCompletion(result);
}

const {
  DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$z
} = constants;
const config$C = {
  commandName: 'completion',
  description: 'Install bash completion for Socket CLI',
  hidden: true,
  // beta
  flags: {
    ...utils.commonFlags
  },
  help: (command, config) => `
    Usage
      $ ${command} [name=socket]

    Installs bash completion for the Socket CLI. This will:
    1. Source the completion script in your current shell
    2. Add the source command to your ~/.bashrc if it's not already there

    This command will only setup tab completion, nothing else.

    Afterwards you should be able to type \`socket \` and then press tab to
    have bash auto-complete/suggest the sub/command or flags.

    Currently only supports bash.

    The optional name argument allows you to enable tab completion on a command
    name other than "socket". Mostly for debugging but also useful if you use a
    different alias for socket on your system.

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Examples

      $ ${command}
      $ ${command} sd
      $ ${command} ./sd
  `
};
const cmdInstallCompletion = {
  description: config$C.description,
  hidden: config$C.hidden,
  run: run$C
};
async function run$C(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$C,
    importMeta,
    parentName
  });
  const targetName = cli.input[0] || 'socket';
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$z);
    return;
  }
  await handleInstallCompletion(String(targetName));
}

const description$7 = 'Setup the Socket CLI command in your environment';
const cmdInstall = {
  description: description$7,
  hidden: true,
  // beta
  async run(argv, importMeta, {
    parentName
  }) {
    await utils.meowWithSubcommands({
      completion: cmdInstallCompletion
    }, {
      argv,
      description: description$7,
      importMeta,
      name: `${parentName} install`
    });
  }
};

function applyLogin(apiToken, enforcedOrgs, apiBaseUrl, apiProxy) {
  utils.updateConfigValue('enforcedOrgs', enforcedOrgs);
  utils.updateConfigValue('apiToken', apiToken);
  utils.updateConfigValue('apiBaseUrl', apiBaseUrl);
  utils.updateConfigValue('apiProxy', apiProxy);
}

const {
  SOCKET_PUBLIC_API_TOKEN
} = constants;
async function attemptLogin(apiBaseUrl, apiProxy) {
  apiBaseUrl ??= utils.getConfigValueOrUndef('apiBaseUrl') ?? undefined;
  apiProxy ??= utils.getConfigValueOrUndef('apiProxy') ?? undefined;
  const apiToken = (await prompts.password({
    message: `Enter your ${vendor.terminalLinkExports('Socket.dev API key', 'https://docs.socket.dev/docs/api-keys')} (leave blank for a public key)`
  })) || SOCKET_PUBLIC_API_TOKEN;
  const sdk = await utils.setupSdk(apiToken, apiBaseUrl, apiProxy);
  if (!sdk.ok) {
    process.exitCode = 1;
    logger.logger.fail(utils.failMsgWithBadge(sdk.message, sdk.cause));
    return;
  }
  const result = await utils.handleApiCall(sdk.data.getOrganizations(), 'token verification');
  if (!result.ok) {
    process.exitCode = 1;
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  logger.logger.success('API key verified');
  const orgs = result.data;
  const enforcedChoices = Object.values(orgs.organizations).filter(org => org?.plan === 'enterprise').map(org => ({
    name: org.name ?? 'undefined',
    value: org.id
  }));
  let enforcedOrgs = [];
  if (enforcedChoices.length > 1) {
    const id = await prompts.select({
      message: "Which organization's policies should Socket enforce system-wide?",
      choices: enforcedChoices.concat({
        name: 'None',
        value: '',
        description: 'Pick "None" if this is a personal device'
      })
    });
    if (id) {
      enforcedOrgs = [id];
    }
  } else if (enforcedChoices.length) {
    if (await prompts.confirm({
      message: `Should Socket enforce ${enforcedChoices[0]?.name}'s security policies system-wide?`,
      default: true
    })) {
      const existing = enforcedChoices[0];
      if (existing) {
        enforcedOrgs = [existing.value];
      }
    }
  }
  if (utils.isTestingV1() && (await prompts.select({
    message: 'Would you like to install bash tab completion?',
    choices: [{
      name: 'Yes',
      value: true,
      description: 'Sets up tab completion for "socket" in your bash env. If you\'re unsure, this is probably what you want.'
    }, {
      name: 'No',
      value: false,
      description: 'Will skip tab completion setup. Does not change how Socket works.'
    }]
  }))) {
    logger.logger.log('Setting up tab completion...');
    const result = await setupTabCompletion('socket');
    if (result.ok) {
      logger.logger.success('Tab completion will be enabled after restarting your terminal');
    } else {
      logger.logger.fail('Failed to install tab completion script. Try `socket install completion` later.');
    }
  }
  const previousPersistedToken = utils.getConfigValueOrUndef('apiToken');
  try {
    applyLogin(apiToken, enforcedOrgs, apiBaseUrl, apiProxy);
    logger.logger.success(`API credentials ${previousPersistedToken === apiToken ? 'refreshed' : previousPersistedToken ? 'updated' : 'set'}`);
    if (utils.isReadOnlyConfig()) {
      logger.logger.log('');
      logger.logger.warn('Note: config is in read-only mode, at least one key was overridden through flag/env, so the login was not persisted!');
    }
  } catch {
    process.exitCode = 1;
    logger.logger.fail(`API login failed`);
  }
}

const {
  DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$y
} = constants;
const config$B = {
  commandName: 'login',
  description: 'Socket API login',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    apiBaseUrl: {
      type: 'string',
      description: 'API server to connect to for login'
    },
    apiProxy: {
      type: 'string',
      description: 'Proxy to use when making connection to API server'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command}

    API Token Requirements
      - Quota: 1 unit

    Logs into the Socket API by prompting for an API key

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command}
      $ ${command} --api-proxy=http://localhost:1234
  `
};
const cmdLogin = {
  description: config$B.description,
  hidden: config$B.hidden,
  run: run$B
};
async function run$B(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$B,
    importMeta,
    parentName
  });
  const apiBaseUrl = cli.flags['apiBaseUrl'];
  const apiProxy = cli.flags['apiProxy'];
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$y);
    return;
  }
  if (!vendor.isInteractiveExports()) {
    throw new utils.InputError('Cannot prompt for credentials in a non-interactive shell');
  }
  await attemptLogin(apiBaseUrl, apiProxy);
}

function applyLogout() {
  utils.updateConfigValue('apiToken', null);
  utils.updateConfigValue('apiBaseUrl', null);
  utils.updateConfigValue('apiProxy', null);
  utils.updateConfigValue('enforcedOrgs', null);
}

function attemptLogout() {
  try {
    applyLogout();
    logger.logger.success('Successfully logged out');
    if (utils.isReadOnlyConfig()) {
      logger.logger.log('');
      logger.logger.warn('Note: config is in read-only mode, at least one key was overridden through flag/env, so the logout was not persisted!');
    }
  } catch {
    logger.logger.fail('Failed to complete logout steps');
  }
}

const {
  DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$x
} = constants;
const config$A = {
  commandName: 'logout',
  description: 'Socket API logout',
  hidden: false,
  flags: {
    ...utils.commonFlags
  },
  help: (command, _config) => `
    Usage
      $ ${command}

    Logs out of the Socket API and clears all Socket credentials from disk
  `
};
const cmdLogout = {
  description: config$A.description,
  hidden: config$A.hidden,
  run: run$A
};
async function run$A(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$A,
    importMeta,
    parentName
  });
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$x);
    return;
  }
  attemptLogout();
}

const {
  DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$w
} = constants;
const config$z = {
  commandName: 'auto',
  description: 'Auto-detect build and attempt to generate manifest file',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    cwd: {
      type: 'string',
      description: 'Set the cwd, defaults to process.cwd()'
    },
    verbose: {
      type: 'boolean',
      default: false,
      description: 'Enable debug output, may help when running into errors'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command}

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Tries to figure out what language your current repo uses. If it finds a
    supported case then it will try to generate the manifest file for that
    language with the default or detected settings.
  `
};
const cmdManifestAuto = {
  description: config$z.description,
  hidden: config$z.hidden,
  run: run$z
};
async function run$z(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$z,
    importMeta,
    parentName
  });
  const {
    cwd: cwdFlag,
    json,
    markdown,
    verbose: verboseFlag
  } = cli.flags;
  const outputKind = utils.getOutputKind(json, markdown); // TODO: impl json/md further
  const cwd = String(cwdFlag || process.cwd());
  const verbose = !!verboseFlag;
  if (verbose) {
    logger.logger.group('- ', parentName, config$z.commandName, ':');
    logger.logger.group('- flags:', cli.flags);
    logger.logger.groupEnd();
    logger.logger.log('- input:', cli.input);
    logger.logger.log('- cwd:', cwd);
    logger.logger.groupEnd();
  }
  const detected = await detectManifestActions(String(cwd));
  debug.debugLog(detected);
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$w);
    return;
  }
  if (!detected.count) {
    logger.logger.fail('Was unable to discover any targets for which we can generate manifest files...');
    logger.logger.log('');
    logger.logger.log('- Make sure this script would work with your target build (see `socket manifest --help` for your target).');
    logger.logger.log('- Make sure to run it from the correct dir (use --cwd to target another dir)');
    logger.logger.log('- Make sure the necessary build tools are available (`PATH`)');
    process.exitCode = 1;
    return;
  }
  await generateAutoManifest(detected, cwd, verbose, outputKind);
  logger.logger.success(`Finished. Should have attempted to generate manifest files for ${detected.count} targets.`);
}

const {
  DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$v
} = constants;
const config$y = {
  commandName: 'conda',
  description: '[beta] Convert a Conda environment.yml file to a python requirements.txt',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags,
    cwd: {
      type: 'string',
      description: 'Set the cwd, defaults to process.cwd()'
    },
    out: {
      type: 'string',
      default: '-',
      description: 'Output target (use `-` or omit to print to stdout)'
    },
    verbose: {
      type: 'boolean',
      description: 'Print debug messages'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command} FILE

    Warning: While we don't support Conda necessarily, this tool extracts the pip
             block from an environment.yml and outputs it as a requirements.txt
             which you can scan as if it were a pypi package.

    USE AT YOUR OWN RISK

    Note: FILE can be a dash (-) to indicate stdin. This way you can pipe the
          contents of a file to have it processed.

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Examples

      $ ${command} ./environment.yml
  `
};
const cmdManifestConda = {
  description: config$y.description,
  hidden: config$y.hidden,
  run: run$y
};
async function run$y(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$y,
    importMeta,
    parentName
  });
  const {
    cwd = process.cwd(),
    json = false,
    markdown = false,
    out = '-',
    verbose = false
  } = cli.flags;
  const outputKind = utils.getOutputKind(json, markdown); // TODO: impl json/md further

  const [target = ''] = cli.input;
  if (verbose) {
    logger.logger.group('- ', parentName, config$y.commandName, ':');
    logger.logger.group('- flags:', cli.flags);
    logger.logger.groupEnd();
    logger.logger.log('- target:', target);
    logger.logger.log('- output:', out);
    logger.logger.groupEnd();
  }
  const wasValidInput = utils.checkCommandInput(outputKind, {
    test: !!target,
    message: 'The FILE arg is required',
    pass: 'ok',
    fail: 'missing'
  }, {
    nook: true,
    test: cli.input.length <= 1,
    message: 'Can only accept one DIR (make sure to escape spaces!)',
    pass: 'ok',
    fail: 'received ' + cli.input.length
  }, {
    nook: true,
    test: !json || !markdown,
    message: 'The `--json` and `--markdown` flags can not be used at the same time',
    pass: 'ok',
    fail: 'bad'
  });
  if (!wasValidInput) {
    return;
  }
  logger.logger.warn('Warning: This will approximate your Conda dependencies using PyPI. We do not yet officially support Conda. Use at your own risk.');
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$v);
    return;
  }
  await handleManifestConda(target, String(out || ''), json ? 'json' : markdown ? 'markdown' : 'text', String(cwd), Boolean(verbose));
}

const {
  DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$u
} = constants;
const config$x = {
  commandName: 'gradle',
  description: '[beta] Use Gradle to generate a manifest file (`pom.xml`) for a Gradle/Java/Kotlin/etc project',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    bin: {
      type: 'string',
      description: 'Location of gradlew binary to use, default: CWD/gradlew'
    },
    cwd: {
      type: 'string',
      description: 'Set the cwd, defaults to process.cwd()'
    },
    gradleOpts: {
      type: 'string',
      default: '',
      description: 'Additional options to pass on to ./gradlew, see `./gradlew --help`'
    },
    task: {
      type: 'string',
      default: 'all',
      description: 'Task to target. By default targets all'
    },
    verbose: {
      type: 'boolean',
      description: 'Print debug messages'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command} [--bin=path/to/gradle/binary] [--out=path/to/result] DIR

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Uses gradle, preferably through your local project \`gradlew\`, to generate a
    \`pom.xml\` file for each task. If you have no \`gradlew\` you can try the
    global \`gradle\` binary but that may not work (hard to predict).

    The \`pom.xml\` is a manifest file similar to \`package.json\` for npm or
    or requirements.txt for PyPi), but specifically for Maven, which is Java's
    dependency repository. Languages like Kotlin and Scala piggy back on it too.

    There are some caveats with the gradle to \`pom.xml\` conversion:

    - each task will generate its own xml file and by default it generates one xml
      for every task.

    - it's possible certain features don't translate well into the xml. If you
      think something is missing that could be supported please reach out.

    - it works with your \`gradlew\` from your repo and local settings and config

    Support is beta. Please report issues or give us feedback on what's missing.

    Examples

      $ ${command} .
      $ ${command} --bin=../gradlew .
  `
};
const cmdManifestGradle = {
  description: config$x.description,
  hidden: config$x.hidden,
  run: run$x
};
async function run$x(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$x,
    importMeta,
    parentName
  });
  const verbose = Boolean(cli.flags['verbose']);
  const {
    json,
    markdown
  } = cli.flags;
  const outputKind = utils.getOutputKind(json, markdown); // TODO: impl json/md further

  if (verbose) {
    logger.logger.group('- ', parentName, config$x.commandName, ':');
    logger.logger.group('- flags:', cli.flags);
    logger.logger.groupEnd();
    logger.logger.log('- input:', cli.input);
    logger.logger.groupEnd();
  }
  const [target = ''] = cli.input;

  // TODO: I'm not sure it's feasible to parse source file from stdin. We could
  //       try, store contents in a file in some folder, target that folder... what
  //       would the file name be?

  const wasValidInput = utils.checkCommandInput(outputKind, {
    test: !!target && target !== '-',
    message: 'The DIR arg is required',
    pass: 'ok',
    fail: target === '-' ? 'stdin is not supported' : 'missing'
  }, {
    nook: true,
    test: cli.input.length <= 1,
    message: 'Can only accept one DIR (make sure to escape spaces!)',
    pass: 'ok',
    fail: 'received ' + cli.input.length
  });
  if (!wasValidInput) {
    return;
  }
  const {
    bin = path.join(target, 'gradlew'),
    cwd = process.cwd()
  } = cli.flags;
  if (verbose) {
    logger.logger.group();
    logger.logger.log('- target:', target);
    logger.logger.log('- gradle bin:', bin);
    logger.logger.groupEnd();
  }
  let gradleOpts = [];
  if (cli.flags['gradleOpts']) {
    gradleOpts = cli.flags['gradleOpts'].split(' ').map(s => s.trim()).filter(Boolean);
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$u);
    return;
  }
  await convertGradleToMaven(target, String(bin), String(cwd), verbose, gradleOpts);
}

const {
  DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$t
} = constants;

// TODO: we may want to dedupe some pieces for all gradle languages. I think it
//       makes sense to have separate commands for them and I think it makes
//       sense for the help panels to note the requested language, rather than
//       `socket manifest kotlin` to print help screens with `gradle` as the
//       command. Room for improvement.
const config$w = {
  commandName: 'kotlin',
  description: '[beta] Use Gradle to generate a manifest file (`pom.xml`) for a Kotlin project',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    bin: {
      type: 'string',
      description: 'Location of gradlew binary to use, default: CWD/gradlew'
    },
    cwd: {
      type: 'string',
      description: 'Set the cwd, defaults to process.cwd()'
    },
    gradleOpts: {
      type: 'string',
      default: '',
      description: 'Additional options to pass on to ./gradlew, see `./gradlew --help`'
    },
    task: {
      type: 'string',
      default: 'all',
      description: 'Task to target. By default targets all'
    },
    verbose: {
      type: 'boolean',
      description: 'Print debug messages'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command} [--bin=path/to/gradle/binary] [--out=path/to/result] DIR

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Uses gradle, preferably through your local project \`gradlew\`, to generate a
    \`pom.xml\` file for each task. If you have no \`gradlew\` you can try the
    global \`gradle\` binary but that may not work (hard to predict).

    The \`pom.xml\` is a manifest file similar to \`package.json\` for npm or
    or requirements.txt for PyPi), but specifically for Maven, which is Java's
    dependency repository. Languages like Kotlin and Scala piggy back on it too.

    There are some caveats with the gradle to \`pom.xml\` conversion:

    - each task will generate its own xml file and by default it generates one xml
      for every task. (This may be a good thing!)

    - it's possible certain features don't translate well into the xml. If you
      think something is missing that could be supported please reach out.

    - it works with your \`gradlew\` from your repo and local settings and config

    Support is beta. Please report issues or give us feedback on what's missing.

    Examples

      $ ${command} .
      $ ${command} --bin=../gradlew .
  `
};
const cmdManifestKotlin = {
  description: config$w.description,
  hidden: config$w.hidden,
  run: run$w
};
async function run$w(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$w,
    importMeta,
    parentName
  });
  const verbose = Boolean(cli.flags['verbose']);
  const {
    json,
    markdown
  } = cli.flags;
  const outputKind = utils.getOutputKind(json, markdown); // TODO: impl json/md further

  if (verbose) {
    logger.logger.group('- ', parentName, config$w.commandName, ':');
    logger.logger.group('- flags:', cli.flags);
    logger.logger.groupEnd();
    logger.logger.log('- input:', cli.input);
    logger.logger.groupEnd();
  }
  const [target = ''] = cli.input;

  // TODO: I'm not sure it's feasible to parse source file from stdin. We could
  //       try, store contents in a file in some folder, target that folder... what
  //       would the file name be?

  const wasValidInput = utils.checkCommandInput(outputKind, {
    test: !!target && target !== '-',
    message: 'The DIR arg is required',
    pass: 'ok',
    fail: target === '-' ? 'stdin is not supported' : 'missing'
  }, {
    nook: true,
    test: cli.input.length <= 1,
    message: 'Can only accept one DIR (make sure to escape spaces!)',
    pass: 'ok',
    fail: 'received ' + cli.input.length
  });
  if (!wasValidInput) {
    return;
  }
  const {
    bin = path.join(target, 'gradlew'),
    cwd = process.cwd()
  } = cli.flags;
  if (verbose) {
    logger.logger.group();
    logger.logger.log('- target:', target);
    logger.logger.log('- gradle bin:', bin);
    logger.logger.groupEnd();
  }
  let gradleOpts = [];
  if (cli.flags['gradleOpts']) {
    gradleOpts = cli.flags['gradleOpts'].split(' ').map(s => s.trim()).filter(Boolean);
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$t);
    return;
  }
  await convertGradleToMaven(target, String(bin), String(cwd), verbose, gradleOpts);
}

const {
  DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$s
} = constants;
const config$v = {
  commandName: 'scala',
  description: "[beta] Generate a manifest file (`pom.xml`) from Scala's `build.sbt` file",
  hidden: false,
  flags: {
    ...utils.commonFlags,
    bin: {
      type: 'string',
      default: 'sbt',
      description: 'Location of sbt binary to use'
    },
    cwd: {
      type: 'string',
      description: 'Set the cwd, defaults to process.cwd()'
    },
    out: {
      type: 'string',
      default: './socket.pom.xml',
      description: 'Path of output file; where to store the resulting manifest, see also --stdout'
    },
    stdout: {
      type: 'boolean',
      description: 'Print resulting pom.xml to stdout (supersedes --out)'
    },
    sbtOpts: {
      type: 'string',
      default: '',
      description: 'Additional options to pass on to sbt, as per `sbt --help`'
    },
    verbose: {
      type: 'boolean',
      description: 'Print debug messages'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command} [--bin=path/to/sbt/binary] [--out=path/to/result] FILE|DIR

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Uses \`sbt makePom\` to generate a \`pom.xml\` from your \`build.sbt\` file.
    This xml file is the dependency manifest (like a package.json
    for Node.js or requirements.txt for PyPi), but specifically for Scala.

    There are some caveats with \`build.sbt\` to \`pom.xml\` conversion:

    - the xml is exported as socket.pom.xml as to not confuse existing build tools
      but it will first hit your /target/sbt<version> folder (as a different name)

    - the pom.xml format (standard by Scala) does not support certain sbt features
      - \`excludeAll()\`, \`dependencyOverrides\`, \`force()\`, \`relativePath\`
      - For details: https://www.scala-sbt.org/1.x/docs/Library-Management.html

    - it uses your sbt settings and local configuration verbatim

    - it can only export one target per run, so if you have multiple targets like
      development and production, you must run them separately.

    You can optionally configure the path to the \`sbt\` bin to invoke.

    Support is beta. Please report issues or give us feedback on what's missing.

    This is only for SBT. If your Scala setup uses gradle, please see the help
    sections for \`socket manifest gradle\` or \`socket cdxgen\`.

    Examples

      $ ${command} ./build.sbt
      $ ${command} --bin=/usr/bin/sbt ./build.sbt
  `
};
const cmdManifestScala = {
  description: config$v.description,
  hidden: config$v.hidden,
  run: run$v
};
async function run$v(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$v,
    importMeta,
    parentName
  });
  const verbose = Boolean(cli.flags['verbose']);
  const {
    json,
    markdown
  } = cli.flags;
  const outputKind = utils.getOutputKind(json, markdown); // TODO: impl json/md further

  if (verbose) {
    logger.logger.group('- ', parentName, config$v.commandName, ':');
    logger.logger.group('- flags:', cli.flags);
    logger.logger.groupEnd();
    logger.logger.log('- input:', cli.input);
    logger.logger.groupEnd();
  }
  const [target = ''] = cli.input;

  // TODO: I'm not sure it's feasible to parse source file from stdin. We could
  //       try, store contents in a file in some folder, target that folder... what
  //       would the file name be?

  const wasValidInput = utils.checkCommandInput(outputKind, {
    test: !!target && target !== '-',
    message: 'The DIR arg is required',
    pass: 'ok',
    fail: target === '-' ? 'stdin is not supported' : 'missing'
  }, {
    nook: true,
    test: cli.input.length <= 1,
    message: 'Can only accept one DIR (make sure to escape spaces!)',
    pass: 'ok',
    fail: 'received ' + cli.input.length
  });
  if (!wasValidInput) {
    return;
  }
  let bin = 'sbt';
  if (cli.flags['bin']) {
    bin = cli.flags['bin'];
  }
  let out = './socket.pom.xml';
  if (cli.flags['out']) {
    out = cli.flags['out'];
  }
  if (cli.flags['stdout']) {
    out = '-';
  }
  if (verbose) {
    logger.logger.group();
    logger.logger.log('- target:', target);
    logger.logger.log('- gradle bin:', bin);
    logger.logger.log('- out:', out);
    logger.logger.groupEnd();
  }
  let sbtOpts = [];
  if (cli.flags['sbtOpts']) {
    sbtOpts = cli.flags['sbtOpts'].split(' ').map(s => s.trim()).filter(Boolean);
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$s);
    return;
  }
  await convertSbtToMaven(target, bin, out, verbose, sbtOpts);
}

const config$u = {
  commandName: 'manifest',
  description: 'Generate a dependency manifest for given file or dir',
  hidden: false,
  flags: {
    ...utils.commonFlags
  }};
const cmdManifest = {
  description: config$u.description,
  hidden: config$u.hidden,
  run: run$u
};
async function run$u(argv, importMeta, {
  parentName
}) {
  await utils.meowWithSubcommands({
    auto: cmdManifestAuto,
    cdxgen: cmdManifestCdxgen,
    conda: cmdManifestConda,
    scala: cmdManifestScala,
    gradle: cmdManifestGradle,
    kotlin: cmdManifestKotlin
  }, {
    argv,
    aliases: {
      yolo: {
        description: config$u.description,
        hidden: true,
        argv: ['auto']
      }
    },
    description: config$u.description,
    importMeta,
    flags: config$u.flags,
    name: `${parentName} ${config$u.commandName}`
  });
}

const require$3 =Module.createRequire(require$$0.pathToFileURL(__filename).href)
const {
  DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$r
} = constants;
const config$t = {
  commandName: 'npm',
  description: `npm wrapper functionality`,
  hidden: false,
  flags: {
    ...utils.commonFlags
  },
  help: (command, _config) => `
    Usage
      $ ${command}
  `
};
const cmdNpm = {
  description: config$t.description,
  hidden: config$t.hidden,
  run: run$t
};
async function run$t(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    allowUnknownFlags: true,
    argv,
    config: config$t,
    importMeta,
    parentName
  });
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$r);
    return;
  }

  // Lazily access constants.distShadowBinPath.
  const shadowBin = require$3(constants.distShadowBinPath);
  await shadowBin('npm', argv);
}

const require$2 =Module.createRequire(require$$0.pathToFileURL(__filename).href)
const {
  DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$q
} = constants;
const config$s = {
  commandName: 'npx',
  description: `npx wrapper functionality`,
  hidden: false,
  flags: {
    ...utils.commonFlags
  },
  help: (command, _config) => `
    Usage
      $ ${command}
  `
};
const cmdNpx = {
  description: config$s.description,
  hidden: config$s.hidden,
  run: run$s
};
async function run$s(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    allowUnknownFlags: true,
    argv,
    config: config$s,
    importMeta,
    parentName
  });
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$q);
    return;
  }

  // Lazily access constants.distShadowBinPath.
  const shadowBin = require$2(constants.distShadowBinPath);
  await shadowBin('npx', argv);
}

const {
  DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$p
} = constants;
const config$r = {
  commandName: 'oops',
  description: 'Trigger an intentional error (for development)',
  hidden: true,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags
  },
  help: (parentName, config) => `
    Usage
      $ ${parentName} ${config.commandName}

    Don't run me.
  `
};
const cmdOops = {
  description: config$r.description,
  hidden: config$r.hidden,
  run: run$r
};
async function run$r(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$r,
    importMeta,
    parentName
  });
  const {
    json,
    markdown
  } = cli.flags;
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$p);
    return;
  }
  if (json) {
    process.exitCode = 1;
    logger.logger.log(utils.serializeResultJson({
      ok: false,
      message: 'Oops',
      cause: 'This error was intentionally left blank'
    }));
  }
  if (markdown) {
    process.exitCode = 1;
    logger.logger.fail(utils.failMsgWithBadge('Oops', 'This error was intentionally left blank'));
    return;
  }
  throw new Error('This error was intentionally left blank');
}

const {
  BUN: BUN$4,
  NPM: NPM$6,
  PNPM: PNPM$5,
  VLT: VLT$4,
  YARN_BERRY: YARN_BERRY$4,
  YARN_CLASSIC: YARN_CLASSIC$5
} = constants;
function matchLsCmdViewHumanStdout(stdout, name) {
  return stdout.includes(` ${name}@`);
}
function matchQueryCmdStdout(stdout, name) {
  return stdout.includes(`"${name}"`);
}
const depsIncludesByAgent = new Map([[BUN$4, matchLsCmdViewHumanStdout], [NPM$6, matchQueryCmdStdout], [PNPM$5, matchQueryCmdStdout], [VLT$4, matchQueryCmdStdout], [YARN_BERRY$4, matchLsCmdViewHumanStdout], [YARN_CLASSIC$5, matchLsCmdViewHumanStdout]]);

function getDependencyEntries(pkgEnvDetails) {
  const {
    dependencies,
    devDependencies,
    optionalDependencies,
    peerDependencies
  } = pkgEnvDetails.editablePkgJson.content;
  return [['dependencies', dependencies ? {
    __proto__: null,
    ...dependencies
  } : undefined], ['devDependencies', devDependencies ? {
    __proto__: null,
    ...devDependencies
  } : undefined], ['peerDependencies', peerDependencies ? {
    __proto__: null,
    ...peerDependencies
  } : undefined], ['optionalDependencies', optionalDependencies ? {
    __proto__: null,
    ...optionalDependencies
  } : undefined]].filter(({
    1: o
  }) => o);
}

const {
  BUN: BUN$3,
  NPM: NPM$5,
  OVERRIDES: OVERRIDES$1,
  PNPM: PNPM$4,
  RESOLUTIONS: RESOLUTIONS$1,
  VLT: VLT$3,
  YARN_BERRY: YARN_BERRY$3,
  YARN_CLASSIC: YARN_CLASSIC$4
} = constants;
function getOverridesDataBun(pkgEnvDetails) {
  const overrides = pkgEnvDetails.editablePkgJson.content?.[RESOLUTIONS$1] ?? {};
  return {
    type: YARN_BERRY$3,
    overrides
  };
}

// npm overrides documentation:
// https://docs.npmjs.com/cli/v10/configuring-npm/package-json#overrides
function getOverridesDataNpm(pkgEnvDetails) {
  const overrides = pkgEnvDetails.editablePkgJson.content?.[OVERRIDES$1] ?? {};
  return {
    type: NPM$5,
    overrides
  };
}

// pnpm overrides documentation:
// https://pnpm.io/package_json#pnpmoverrides
function getOverridesDataPnpm(pkgEnvDetails) {
  const overrides = pkgEnvDetails.editablePkgJson.content?.[PNPM$4]?.[OVERRIDES$1] ?? {};
  return {
    type: PNPM$4,
    overrides
  };
}
function getOverridesDataVlt(pkgEnvDetails) {
  const overrides = pkgEnvDetails.editablePkgJson.content?.[OVERRIDES$1] ?? {};
  return {
    type: VLT$3,
    overrides
  };
}

// Yarn resolutions documentation:
// https://yarnpkg.com/configuration/manifest#resolutions
function getOverridesDataYarn(pkgEnvDetails) {
  const overrides = pkgEnvDetails.editablePkgJson.content?.[RESOLUTIONS$1] ?? {};
  return {
    type: YARN_BERRY$3,
    overrides
  };
}

// Yarn resolutions documentation:
// https://classic.yarnpkg.com/en/docs/selective-version-resolutions
function getOverridesDataYarnClassic(pkgEnvDetails) {
  const overrides = pkgEnvDetails.editablePkgJson.content?.[RESOLUTIONS$1] ?? {};
  return {
    type: YARN_CLASSIC$4,
    overrides
  };
}
const overridesDataByAgent = new Map([[BUN$3, getOverridesDataBun], [NPM$5, getOverridesDataNpm], [PNPM$4, getOverridesDataPnpm], [VLT$3, getOverridesDataVlt], [YARN_BERRY$3, getOverridesDataYarn], [YARN_CLASSIC$4, getOverridesDataYarnClassic]]);

const {
  BUN: BUN$2,
  LOCK_EXT,
  NPM: NPM$4,
  PNPM: PNPM$3,
  VLT: VLT$2,
  YARN_BERRY: YARN_BERRY$2,
  YARN_CLASSIC: YARN_CLASSIC$3
} = constants;
function includesNpm(lockSrc, name) {
  // Detects the package name in the following cases:
  //   "name":
  return lockSrc.includes(`"${name}":`);
}
function includesBun(lockSrc, name, lockName) {
  // This is a bit counterintuitive. When lockName ends with a .lockb
  // we treat it as a yarn.lock. When lockName ends with a .lock we
  // treat it as a package-lock.json. The bun.lock format is not identical
  // package-lock.json, however it close enough for npmLockIncludes to work.
  const lockfileScanner = lockName?.endsWith(LOCK_EXT) ? includesNpm : includesYarn;
  return lockfileScanner(lockSrc, name);
}
function includesPnpm(lockSrc, name) {
  const escapedName = regexps.escapeRegExp(name);
  return new RegExp(
  // Detects the package name in the following cases:
  //   /name/
  //   'name'
  //   name:
  //   name@
  `(?<=^\\s*)(?:(['/])${escapedName}\\1|${escapedName}(?=[:@]))`, 'm').test(lockSrc);
}
function includesVlt(lockSrc, name) {
  // Detects the package name in the following cases:
  //   "name"
  return lockSrc.includes(`"${name}"`);
}
function includesYarn(lockSrc, name) {
  const escapedName = regexps.escapeRegExp(name);
  return new RegExp(
  // Detects the package name in the following cases:
  //   "name@
  //   , "name@
  //   name@
  //   , name@
  `(?<=(?:^\\s*|,\\s*)"?)${escapedName}(?=@)`, 'm').test(lockSrc);
}
const lockfileIncludesByAgent = new Map([[BUN$2, includesBun], [NPM$4, includesNpm], [PNPM$3, includesPnpm], [VLT$2, includesVlt], [YARN_BERRY$2, includesYarn], [YARN_CLASSIC$3, includesYarn]]);

const {
  BUN: BUN$1,
  NPM: NPM$3,
  PNPM: PNPM$2,
  VLT: VLT$1,
  YARN_BERRY: YARN_BERRY$1,
  YARN_CLASSIC: YARN_CLASSIC$2
} = constants;
function cleanupQueryStdout(stdout) {
  if (stdout === '') {
    return '';
  }
  let pkgs;
  try {
    pkgs = JSON.parse(stdout);
  } catch {}
  if (!Array.isArray(pkgs)) {
    return '';
  }
  const names = new Set();
  for (const {
    _id,
    name,
    pkgid
  } of pkgs) {
    // `npm query` results may not have a "name" property, in which case we
    // fallback to "_id" and then "pkgid".
    // `vlt ls --view json` results always have a "name" property.
    const fallback = _id ?? pkgid ?? '';
    const resolvedName = name ?? fallback.slice(0, fallback.indexOf('@', 1));
    // Add package names, except for those under the `@types` scope as those
    // are known to only be dev dependencies.
    if (resolvedName && !resolvedName.startsWith('@types/')) {
      names.add(resolvedName);
    }
  }
  return JSON.stringify([...names], null, 2);
}
function parsableToQueryStdout(stdout) {
  if (stdout === '') {
    return '';
  }
  // Convert the parsable stdout into a json array of unique names.
  // The matchAll regexp looks for a forward (posix) or backward (win32) slash
  // and matches one or more non-slashes until the newline.
  const names = new Set(stdout.matchAll(/(?<=[/\\])[^/\\]+(?=\n)/g));
  return JSON.stringify([...names], null, 2);
}
async function npmQuery(npmExecPath, cwd) {
  let stdout = '';
  try {
    stdout = (await spawn.spawn(npmExecPath, ['query', ':not(.dev)'], {
      cwd,
      // Lazily access constants.WIN32.
      shell: constants.WIN32
    })).stdout.trim();
  } catch {}
  return cleanupQueryStdout(stdout);
}
async function lsBun(pkgEnvDetails, cwd) {
  try {
    // Bun does not support filtering by production packages yet.
    // https://github.com/oven-sh/bun/issues/8283
    return (await spawn.spawn(pkgEnvDetails.agentExecPath, ['pm', 'ls', '--all'], {
      cwd,
      // Lazily access constants.WIN32.
      shell: constants.WIN32
    })).stdout.trim();
  } catch {}
  return '';
}
async function lsNpm(pkgEnvDetails, cwd) {
  return await npmQuery(pkgEnvDetails.agentExecPath, cwd);
}
async function lsPnpm(pkgEnvDetails, cwd, options) {
  const npmExecPath = options?.npmExecPath;
  if (npmExecPath && npmExecPath !== NPM$3) {
    const result = await npmQuery(npmExecPath, cwd);
    if (result) {
      return result;
    }
  }
  let stdout = '';
  try {
    stdout = (await spawn.spawn(pkgEnvDetails.agentExecPath,
    // Pnpm uses the alternative spelling of parsable.
    // https://en.wiktionary.org/wiki/parsable
    ['ls', '--parseable', '--prod', '--depth', 'Infinity'], {
      cwd,
      // Lazily access constants.WIN32.
      shell: constants.WIN32
    })).stdout.trim();
  } catch {}
  return parsableToQueryStdout(stdout);
}
async function lsVlt(pkgEnvDetails, cwd) {
  let stdout = '';
  try {
    // See https://docs.vlt.sh/cli/commands/list#options.
    stdout = (await spawn.spawn(pkgEnvDetails.agentExecPath, ['ls', '--view', 'human', ':not(.dev)'], {
      cwd,
      // Lazily access constants.WIN32.
      shell: constants.WIN32
    })).stdout.trim();
  } catch {}
  return cleanupQueryStdout(stdout);
}
async function lsYarnBerry(pkgEnvDetails, cwd) {
  try {
    return (
      // Yarn Berry does not support filtering by production packages yet.
      // https://github.com/yarnpkg/berry/issues/5117
      (await spawn.spawn(pkgEnvDetails.agentExecPath, ['info', '--recursive', '--name-only'], {
        cwd,
        // Lazily access constants.WIN32.
        shell: constants.WIN32
      })).stdout.trim()
    );
  } catch {}
  return '';
}
async function lsYarnClassic(pkgEnvDetails, cwd) {
  try {
    // However, Yarn Classic does support it.
    // https://github.com/yarnpkg/yarn/releases/tag/v1.0.0
    // > Fix: Excludes dev dependencies from the yarn list output when the
    //   environment is production
    return (await spawn.spawn(pkgEnvDetails.agentExecPath, ['list', '--prod'], {
      cwd,
      // Lazily access constants.WIN32.
      shell: constants.WIN32
    })).stdout.trim();
  } catch {}
  return '';
}
const lsByAgent = new Map([[BUN$1, lsBun], [NPM$3, lsNpm], [PNPM$2, lsPnpm], [VLT$1, lsVlt], [YARN_BERRY$1, lsYarnBerry], [YARN_CLASSIC$2, lsYarnClassic]]);

const CMD_NAME = 'socket optimize';

const {
  BUN,
  NPM: NPM$2,
  OVERRIDES,
  PNPM: PNPM$1,
  RESOLUTIONS,
  VLT,
  YARN_BERRY,
  YARN_CLASSIC: YARN_CLASSIC$1
} = constants;
const depFields = ['dependencies', 'devDependencies', 'peerDependencies', 'peerDependenciesMeta', 'optionalDependencies', 'bundleDependencies'];
function getEntryIndexes(entries, keys) {
  return keys.map(n => entries.findIndex(p => p[0] === n)).filter(n => n !== -1).sort((a, b) => a - b);
}
function getLowestEntryIndex(entries, keys) {
  return getEntryIndexes(entries, keys)?.[0] ?? -1;
}
function getHighestEntryIndex(entries, keys) {
  return getEntryIndexes(entries, keys).at(-1) ?? -1;
}
function updatePkgJsonField(editablePkgJson, field, value) {
  const oldValue = editablePkgJson.content[field];
  if (oldValue) {
    // The field already exists so we simply update the field value.
    if (field === PNPM$1) {
      const isPnpmObj = objects.isObject(oldValue);
      if (objects.hasKeys(value)) {
        editablePkgJson.update({
          [field]: {
            ...(isPnpmObj ? oldValue : {}),
            overrides: {
              ...(isPnpmObj ? oldValue[OVERRIDES] : {}),
              ...value
            }
          }
        });
      } else {
        // Properties with undefined values are omitted when saved as JSON.
        editablePkgJson.update(objects.hasKeys(oldValue) ? {
          [field]: {
            ...(isPnpmObj ? oldValue : {}),
            overrides: undefined
          }
        } : {
          [field]: undefined
        });
      }
    } else if (field === OVERRIDES || field === RESOLUTIONS) {
      // Properties with undefined values are omitted when saved as JSON.
      editablePkgJson.update({
        [field]: objects.hasKeys(value) ? value : undefined
      });
    } else {
      editablePkgJson.update({
        [field]: value
      });
    }
    return;
  }
  if ((field === OVERRIDES || field === PNPM$1 || field === RESOLUTIONS) && !objects.hasKeys(value)) {
    return;
  }
  // Since the field doesn't exist we want to insert it into the package.json
  // in a place that makes sense, e.g. close to the "dependencies" field. If
  // we can't find a place to insert the field we'll add it to the bottom.
  const entries = Object.entries(editablePkgJson.content);
  let insertIndex = -1;
  let isPlacingHigher = false;
  if (field === OVERRIDES) {
    insertIndex = getLowestEntryIndex(entries, [RESOLUTIONS]);
    if (insertIndex === -1) {
      isPlacingHigher = true;
      insertIndex = getHighestEntryIndex(entries, [...depFields, PNPM$1]);
    }
  } else if (field === RESOLUTIONS) {
    isPlacingHigher = true;
    insertIndex = getHighestEntryIndex(entries, [...depFields, OVERRIDES, PNPM$1]);
  } else if (field === PNPM$1) {
    insertIndex = getLowestEntryIndex(entries, [OVERRIDES, RESOLUTIONS]);
    if (insertIndex === -1) {
      isPlacingHigher = true;
      insertIndex = getHighestEntryIndex(entries, depFields);
    }
  }
  if (insertIndex === -1) {
    insertIndex = getLowestEntryIndex(entries, ['engines', 'files']);
  }
  if (insertIndex === -1) {
    isPlacingHigher = true;
    insertIndex = getHighestEntryIndex(entries, ['exports', 'imports', 'main']);
  }
  if (insertIndex === -1) {
    insertIndex = entries.length;
  } else if (isPlacingHigher) {
    insertIndex += 1;
  }
  entries.splice(insertIndex, 0, [field, field === PNPM$1 ? {
    [OVERRIDES]: value
  } : value]);
  editablePkgJson.fromJSON(`${JSON.stringify(Object.fromEntries(entries), null, 2)}\n`);
}
function updateOverridesField(pkgEnvDetails, overrides) {
  updatePkgJsonField(pkgEnvDetails.editablePkgJson, OVERRIDES, overrides);
}
function updateResolutionsField(pkgEnvDetails, overrides) {
  updatePkgJsonField(pkgEnvDetails.editablePkgJson, RESOLUTIONS, overrides);
}
function updatePnpmField(pkgEnvDetails, overrides) {
  updatePkgJsonField(pkgEnvDetails.editablePkgJson, PNPM$1, overrides);
}
const updateManifestByAgent = new Map([[BUN, updateResolutionsField], [NPM$2, updateOverridesField], [PNPM$1, updatePnpmField], [VLT, updateOverridesField], [YARN_BERRY, updateResolutionsField], [YARN_CLASSIC$1, updateResolutionsField]]);

const {
  NPM: NPM$1,
  PNPM,
  YARN_CLASSIC
} = constants;
const manifestNpmOverrides = registry.getManifestData(NPM$1);
async function addOverrides(pkgEnvDetails, pkgPath, options) {
  const {
    agent,
    lockName,
    lockSrc,
    npmExecPath,
    pkgPath: rootPath
  } = pkgEnvDetails;
  const {
    logger,
    pin,
    prod,
    spinner,
    state = {
      added: new Set(),
      addedInWorkspaces: new Set(),
      updated: new Set(),
      updatedInWorkspaces: new Set(),
      warnedPnpmWorkspaceRequiresNpm: false
    }
  } = {
    __proto__: null,
    ...options
  };
  const workspacePkgJsonPaths = await utils.globWorkspace(agent, pkgPath);
  const isWorkspace = workspacePkgJsonPaths.length > 0;
  const isWorkspaceRoot = pkgPath === rootPath;
  const isLockScanned = isWorkspaceRoot && !prod;
  const workspaceName = isWorkspaceRoot ? 'root' : path.relative(rootPath, pkgPath);
  if (isWorkspace && agent === PNPM &&
  // npmExecPath will === the agent name IF it CANNOT be resolved.
  npmExecPath === NPM$1 && !state.warnedPnpmWorkspaceRequiresNpm) {
    state.warnedPnpmWorkspaceRequiresNpm = true;
    logger?.warn(utils.cmdPrefixMessage(CMD_NAME, `${agent} workspace support requires \`npm ls\`, falling back to \`${agent} list\``));
  }
  const overridesDataObjects = [];
  if (isWorkspace || pkgEnvDetails.editablePkgJson.content['private']) {
    overridesDataObjects.push(overridesDataByAgent.get(agent)(pkgEnvDetails));
  } else {
    overridesDataObjects.push(overridesDataByAgent.get(NPM$1)(pkgEnvDetails), overridesDataByAgent.get(YARN_CLASSIC)(pkgEnvDetails));
  }
  spinner?.setText(`Adding overrides to ${workspaceName}...`);
  const depAliasMap = new Map();
  const depEntries = getDependencyEntries(pkgEnvDetails);
  const manifestEntries = manifestNpmOverrides.filter(({
    1: data
  }) => vendor.semverExports.satisfies(
  // Roughly check Node range as semver.coerce will strip leading
  // v's, carets (^), comparators (<,<=,>,>=,=), and tildes (~).
  vendor.semverExports.coerce(data.engines.node), pkgEnvDetails.pkgRequirements.node));

  // Chunk package names to process them in parallel 3 at a time.
  await require$$7.pEach(manifestEntries, 3, async ({
    1: data
  }) => {
    const {
      name: sockRegPkgName,
      package: origPkgName,
      version
    } = data;
    const major = vendor.semverExports.major(version);
    const sockOverridePrefix = `${NPM$1}:${sockRegPkgName}@`;
    const sockOverrideSpec = `${sockOverridePrefix}${pin ? version : `^${major}`}`;
    for (const {
      1: depObj
    } of depEntries) {
      const sockSpec = objects.hasOwn(depObj, sockRegPkgName) ? depObj[sockRegPkgName] : undefined;
      if (sockSpec) {
        depAliasMap.set(sockRegPkgName, sockSpec);
      }
      const origSpec = objects.hasOwn(depObj, origPkgName) ? depObj[origPkgName] : undefined;
      if (origSpec) {
        let thisSpec = origSpec;
        // Add package aliases for direct dependencies to avoid npm EOVERRIDE
        // errors...
        // https://docs.npmjs.com/cli/v8/using-npm/package-spec#aliases
        if (
        // ...if the spec doesn't start with a valid Socket override.
        !(thisSpec.startsWith(sockOverridePrefix) &&
        // Check the validity of the spec by passing it through npa and
        // seeing if it will coerce to a version.
        vendor.semverExports.coerce(vendor.npaExports(thisSpec).rawSpec)?.version)) {
          thisSpec = sockOverrideSpec;
          depObj[origPkgName] = thisSpec;
          state.added.add(sockRegPkgName);
          if (!isWorkspaceRoot) {
            state.addedInWorkspaces.add(workspaceName);
          }
        }
        depAliasMap.set(origPkgName, thisSpec);
      }
    }
    if (isWorkspaceRoot) {
      // The AgentDepsIncludesFn and AgentLockIncludesFn types overlap in their
      // first two parameters. AgentLockIncludesFn accepts an optional third
      // parameter which AgentDepsIncludesFn will ignore so we cast thingScanner
      // as an AgentLockIncludesFn type.
      const thingScanner = isLockScanned ? lockfileIncludesByAgent.get(agent) : depsIncludesByAgent.get(agent);
      const thingToScan = isLockScanned ? lockSrc : await lsByAgent.get(agent)(pkgEnvDetails, pkgPath, {
        npmExecPath
      });
      // Chunk package names to process them in parallel 3 at a time.
      await require$$7.pEach(overridesDataObjects, 3, async ({
        overrides,
        type
      }) => {
        const overrideExists = objects.hasOwn(overrides, origPkgName);
        if (overrideExists || thingScanner(thingToScan, origPkgName, lockName)) {
          const oldSpec = overrideExists ? overrides[origPkgName] : undefined;
          const origDepAlias = depAliasMap.get(origPkgName);
          const sockRegDepAlias = depAliasMap.get(sockRegPkgName);
          const depAlias = sockRegDepAlias ?? origDepAlias;
          let newSpec = sockOverrideSpec;
          if (type === NPM$1 && depAlias) {
            // With npm one may not set an override for a package that one directly
            // depends on unless both the dependency and the override itself share
            // the exact same spec. To make this limitation easier to deal with,
            // overrides may also be defined as a reference to a spec for a direct
            // dependency by prefixing the name of the package to match the version
            // of with a $.
            // https://docs.npmjs.com/cli/v8/configuring-npm/package-json#overrides
            newSpec = `$${sockRegDepAlias ? sockRegPkgName : origPkgName}`;
          } else if (typeof oldSpec === 'string') {
            const thisSpec = oldSpec.startsWith('$') ? depAlias || newSpec : oldSpec || newSpec;
            if (thisSpec.startsWith(sockOverridePrefix)) {
              if (pin && vendor.semverExports.major(
              // Check the validity of the spec by passing it through npa
              // and seeing if it will coerce to a version. semver.coerce
              // will strip leading v's, carets (^), comparators (<,<=,>,>=,=),
              // and tildes (~). If not coerced to a valid version then
              // default to the manifest entry version.
              vendor.semverExports.coerce(vendor.npaExports(thisSpec).rawSpec)?.version ?? version) !== major) {
                const otherVersion = (await packages.fetchPackageManifest(thisSpec))?.version;
                if (otherVersion && otherVersion !== version) {
                  newSpec = `${sockOverridePrefix}${pin ? otherVersion : `^${vendor.semverExports.major(otherVersion)}`}`;
                }
              }
            } else {
              newSpec = oldSpec;
            }
          }
          if (newSpec !== oldSpec) {
            overrides[origPkgName] = newSpec;
            const addedOrUpdated = overrideExists ? 'updated' : 'added';
            state[addedOrUpdated].add(sockRegPkgName);
          }
        }
      });
    }
  });
  if (isWorkspace) {
    // Chunk package names to process them in parallel 3 at a time.
    await require$$7.pEach(workspacePkgJsonPaths, 3, async workspacePkgJsonPath => {
      const otherState = await addOverrides(pkgEnvDetails, path.dirname(workspacePkgJsonPath), {
        logger,
        pin,
        prod,
        spinner
      });
      for (const key of ['added', 'addedInWorkspaces', 'updated', 'updatedInWorkspaces']) {
        for (const value of otherState[key]) {
          state[key].add(value);
        }
      }
    });
  }
  if (state.added.size > 0 || state.updated.size > 0) {
    pkgEnvDetails.editablePkgJson.update(Object.fromEntries(depEntries));
    for (const {
      overrides,
      type
    } of overridesDataObjects) {
      updateManifestByAgent.get(type)(pkgEnvDetails, objects.toSortedObject(overrides));
    }
    await pkgEnvDetails.editablePkgJson.save();
  }
  return state;
}

const {
  NPM_BUGGY_OVERRIDES_PATCHED_VERSION
} = constants;
async function updateLockfile(pkgEnvDetails, options) {
  const {
    cmdName = '',
    logger,
    spinner
  } = {
    __proto__: null,
    ...options
  };
  const isSpinning = !!spinner?.['isSpinning'];
  if (!isSpinning) {
    spinner?.start();
  }
  spinner?.setText(`Updating ${pkgEnvDetails.lockName}...`);
  try {
    await utils.runAgentInstall(pkgEnvDetails, {
      spinner
    });
    if (pkgEnvDetails.features.npmBuggyOverrides) {
      spinner?.stop();
      logger?.log(`💡 Re-run ${cmdName ? `${cmdName} ` : ''}whenever ${pkgEnvDetails.lockName} changes.\n   This can be skipped for ${pkgEnvDetails.agent} >=${NPM_BUGGY_OVERRIDES_PATCHED_VERSION}.`);
    }
  } catch (e) {
    spinner?.stop();
    logger?.fail(utils.cmdPrefixMessage(cmdName, `${pkgEnvDetails.agent} install failed to update ${pkgEnvDetails.lockName}`));
    logger?.error(e);
  }
  if (isSpinning) {
    spinner?.start();
  } else {
    spinner?.stop();
  }
}

function createActionMessage(verb, overrideCount, workspaceCount) {
  return `${verb} ${overrideCount} Socket.dev optimized ${words.pluralize('override', overrideCount)}${workspaceCount ? ` in ${workspaceCount} ${words.pluralize('workspace', workspaceCount)}` : ''}`;
}
async function applyOptimization(cwd, pin, prod) {
  const pkgEnvDetails = await utils.detectAndValidatePackageEnvironment(cwd, {
    cmdName: CMD_NAME,
    logger: logger.logger,
    prod
  });
  if (!pkgEnvDetails) {
    return;
  }
  // Lazily access constants.spinner.
  const {
    spinner
  } = constants;
  spinner.start('Socket optimizing...');
  const state = await addOverrides(pkgEnvDetails, pkgEnvDetails.pkgPath, {
    logger: logger.logger,
    pin,
    prod,
    spinner
  });
  const addedCount = state.added.size;
  const updatedCount = state.updated.size;
  const pkgJsonChanged = addedCount > 0 || updatedCount > 0;
  if (pkgJsonChanged || pkgEnvDetails.features.npmBuggyOverrides) {
    await updateLockfile(pkgEnvDetails, {
      cmdName: CMD_NAME,
      logger: logger.logger,
      spinner
    });
  }
  spinner.stop();
  if (pkgJsonChanged) {
    if (updatedCount > 0) {
      logger.logger?.log(`${createActionMessage('Updated', updatedCount, state.updatedInWorkspaces.size)}${addedCount ? '.' : '🚀'}`);
    }
    if (addedCount > 0) {
      logger.logger?.log(`${createActionMessage('Added', addedCount, state.addedInWorkspaces.size)} 🚀`);
    }
  } else {
    logger.logger?.log('Congratulations! Already Socket.dev optimized 🎉');
  }
}

const {
  DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$o
} = constants;
const config$q = {
  commandName: 'optimize',
  description: 'Optimize dependencies with @socketregistry overrides',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    pin: {
      type: 'boolean',
      default: false,
      description: 'Pin overrides to their latest version'
    },
    prod: {
      type: 'boolean',
      default: false,
      description: 'Only add overrides for production dependencies'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command}

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command}
      $ ${command} --pin
  `
};
const cmdOptimize = {
  description: config$q.description,
  hidden: config$q.hidden,
  run: run$q
};
async function run$q(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$q,
    importMeta,
    parentName
  });

  // TODO: impl json/md

  const cwd = process.cwd();
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$o);
    return;
  }
  await applyOptimization(cwd, Boolean(cli.flags['pin']), Boolean(cli.flags['prod']));
}

async function fetchOrganization() {
  const sockSdkResult = await utils.setupSdk();
  if (!sockSdkResult.ok) {
    return sockSdkResult;
  }
  const sockSdk = sockSdkResult.data;
  return await utils.handleApiCall(sockSdk.getOrganizations(), 'organization list');
}

async function outputOrganizationList(result, outputKind = 'text') {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result));
    return;
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  const organizations = Object.values(result.data.organizations);
  const visibleTokenPrefix = utils.getVisibleTokenPrefix();
  switch (outputKind) {
    case 'markdown':
      {
        // | Syntax      | Description |
        // | ----------- | ----------- |
        // | Header      | Title       |
        // | Paragraph   | Text        |
        let mw1 = 4;
        let mw2 = 2;
        let mw3 = 4;
        for (const o of organizations) {
          mw1 = Math.max(mw1, o.name?.length ?? 0);
          mw2 = Math.max(mw2, o.id.length);
          mw3 = Math.max(mw3, o.plan.length);
        }
        logger.logger.log('# Organizations\n');
        logger.logger.log(`List of organizations associated with your API key, starting with: ${vendor.yoctocolorsCjsExports.italic(visibleTokenPrefix)}\n`);
        logger.logger.log(`| Name${' '.repeat(mw1 - 4)} | ID${' '.repeat(mw2 - 2)} | Plan${' '.repeat(mw3 - 4)} |`);
        logger.logger.log(`| ${'-'.repeat(mw1)} | ${'-'.repeat(mw2)} | ${'-'.repeat(mw3)} |`);
        for (const o of organizations) {
          logger.logger.log(`| ${(o.name || '').padEnd(mw1, ' ')} | ${(o.id || '').padEnd(mw2, ' ')} | ${(o.plan || '').padEnd(mw3, ' ')} |`);
        }
        logger.logger.log(`| ${'-'.repeat(mw1)} | ${'-'.repeat(mw2)} | ${'-'.repeat(mw3)} |`);
        return;
      }
    default:
      {
        logger.logger.log(`List of organizations associated with your API key, starting with: ${vendor.yoctocolorsCjsExports.italic(visibleTokenPrefix)}\n`);
        // Just dump
        for (const o of organizations) {
          logger.logger.log(`- Name: ${vendor.yoctocolorsCjsExports.bold(o.name ?? 'undefined')}, ID: ${vendor.yoctocolorsCjsExports.bold(o.id)}, Plan: ${vendor.yoctocolorsCjsExports.bold(o.plan)}`);
        }
      }
  }
}

async function handleOrganizationList(outputKind = 'text') {
  const data = await fetchOrganization();
  await outputOrganizationList(data, outputKind);
}

const {
  DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$n
} = constants;
const config$p = {
  commandName: 'list',
  description: 'List organizations associated with the API key used',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags
  },
  help: (command, _config) => `
    Usage
      $ ${command}

    API Token Requirements
      - Quota: 1 unit
      - Permissions: none (does need a token)

    Options
      ${utils.getFlagListOutput(config$p.flags, 6)}
  `
};
const cmdOrganizationList = {
  description: config$p.description,
  hidden: config$p.hidden,
  run: run$p
};
async function run$p(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$p,
    importMeta,
    parentName
  });
  const {
    json,
    markdown
  } = cli.flags;
  const outputKind = utils.getOutputKind(json, markdown);
  const hasApiToken = utils.hasDefaultToken();
  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: true,
    test: !json || !markdown,
    message: 'The `--json` and `--markdown` flags can not be used at the same time',
    pass: 'ok',
    fail: 'bad'
  }, {
    nook: true,
    test: hasApiToken,
    message: 'You need to be logged in to use this command. See `socket login`.',
    pass: 'ok',
    fail: 'missing API token'
  });
  if (!wasValidInput) {
    return;
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$n);
    return;
  }
  await handleOrganizationList(outputKind);
}

async function fetchLicensePolicy(orgSlug) {
  const sockSdkResult = await utils.setupSdk();
  if (!sockSdkResult.ok) {
    return sockSdkResult;
  }
  const sockSdk = sockSdkResult.data;
  return await utils.handleApiCall(sockSdk.getOrgLicensePolicy(orgSlug), 'organization license policy');
}

async function outputLicensePolicy(result, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result));
    return;
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  logger.logger.info('Use --json to get the full result');
  logger.logger.log('# License policy');
  logger.logger.log('');
  logger.logger.log('This is the license policy for your organization:');
  logger.logger.log('');
  const rules = result.data['license_policy'];
  const entries = rules ? Object.entries(rules) : [];
  const mapped = entries.map(([key, value]) => [key, value?.['allowed'] ? ' yes' : ' no']);
  mapped.sort(([a], [b]) => a < b ? -1 : a > b ? 1 : 0);
  logger.logger.log(utils.mdTableOfPairs(mapped, ['License Name', 'Allowed']));
  logger.logger.log('');
}

async function handleLicensePolicy(orgSlug, outputKind) {
  const data = await fetchLicensePolicy(orgSlug);
  await outputLicensePolicy(data, outputKind);
}

const {
  DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$m
} = constants;

// TODO: secret toplevel alias `socket license policy`?
const config$o = {
  commandName: 'license',
  description: 'Retrieve the license policy of an organization',
  hidden: true,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags,
    interactive: {
      type: 'boolean',
      default: true,
      description: 'Allow for interactive elements, asking for input. Use --no-interactive to prevent any input questions, defaulting them to cancel/no.'
    },
    org: {
      type: 'string',
      description: 'Force override the organization slug, overrides the default org from config'
    }
  },
  help: (command, _config) => `
    Usage
      $ ${command}${utils.isTestingV1() ? '' : ' <org slug>'}

    API Token Requirements
      - Quota: 1 unit
      - Permissions: license-policy:read

    Options
      ${utils.getFlagListOutput(config$o.flags, 6)}

    Your API token will need the \`license-policy:read\` permission otherwise
    the request will fail with an authentication error.

    Examples
      $ ${command}${utils.isTestingV1() ? '' : ' mycorp'}
      $ ${command}${utils.isTestingV1() ? '' : ' mycorp'} --json
  `
};
const cmdOrganizationPolicyLicense = {
  description: config$o.description,
  hidden: config$o.hidden,
  run: run$o
};
async function run$o(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$o,
    importMeta,
    parentName
  });
  const {
    dryRun,
    interactive,
    json,
    markdown,
    org: orgFlag
  } = cli.flags;
  const outputKind = utils.getOutputKind(json, markdown);
  const [orgSlug] = await utils.determineOrgSlug(String(orgFlag || ''), cli.input[0] || '', !!interactive, !!dryRun);
  const hasApiToken = utils.hasDefaultToken();
  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: true,
    test: !!orgSlug,
    message: utils.isTestingV1() ? 'Org name by default setting, --org, or auto-discovered' : 'Org name must be the first argument',
    pass: 'ok',
    fail: 'missing'
  }, {
    nook: true,
    test: !json || !markdown,
    message: 'The json and markdown flags cannot be both set, pick one',
    pass: 'ok',
    fail: 'omit one'
  }, {
    nook: true,
    test: hasApiToken,
    message: 'You need to be logged in to use this command. See `socket login`.',
    pass: 'ok',
    fail: 'missing API token'
  });
  if (!wasValidInput) {
    return;
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$m);
    return;
  }
  await handleLicensePolicy(orgSlug, outputKind);
}

async function fetchSecurityPolicy(orgSlug) {
  const sockSdkResult = await utils.setupSdk();
  if (!sockSdkResult.ok) {
    return sockSdkResult;
  }
  const sockSdk = sockSdkResult.data;
  return await utils.handleApiCall(sockSdk.getOrgSecurityPolicy(orgSlug), 'organization security policy');
}

async function outputSecurityPolicy(result, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result));
    return;
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  logger.logger.log('# Security policy');
  logger.logger.log('');
  logger.logger.log(`The default security policy setting is: "${result.data.securityPolicyDefault}"`);
  logger.logger.log('');
  logger.logger.log('These are the security policies per setting for your organization:');
  logger.logger.log('');
  const rules = result.data.securityPolicyRules;
  const entries = rules ? Object.entries(rules) : [];
  const mapped = entries.map(([key, value]) => [key, value.action]);
  mapped.sort(([a], [b]) => a < b ? -1 : a > b ? 1 : 0);
  logger.logger.log(utils.mdTableOfPairs(mapped, ['name', 'action']));
  logger.logger.log('');
}

async function handleSecurityPolicy(orgSlug, outputKind) {
  const data = await fetchSecurityPolicy(orgSlug);
  await outputSecurityPolicy(data, outputKind);
}

const {
  DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$l
} = constants;

// TODO: secret toplevel alias `socket security policy`?
const config$n = {
  commandName: 'security',
  description: 'Retrieve the security policy of an organization',
  hidden: true,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags,
    interactive: {
      type: 'boolean',
      default: true,
      description: 'Allow for interactive elements, asking for input. Use --no-interactive to prevent any input questions, defaulting them to cancel/no.'
    },
    org: {
      type: 'string',
      description: 'Force override the organization slug, overrides the default org from config'
    }
  },
  help: (command, _config) => `
    Usage
      $ ${command}${utils.isTestingV1() ? '' : ' <org slug>'}

    API Token Requirements
      - Quota: 1 unit
      - Permissions: security-policy:read

    Options
      ${utils.getFlagListOutput(config$n.flags, 6)}

    Your API token will need the \`security-policy:read\` permission otherwise
    the request will fail with an authentication error.

    Examples
      $ ${command}${utils.isTestingV1() ? '' : ' mycorp'}
      $ ${command}${utils.isTestingV1() ? '' : ' mycorp'} --json
  `
};
const cmdOrganizationPolicyPolicy = {
  description: config$n.description,
  hidden: config$n.hidden,
  run: run$n
};
async function run$n(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$n,
    importMeta,
    parentName
  });
  const {
    dryRun,
    interactive,
    json,
    markdown,
    org: orgFlag
  } = cli.flags;
  const outputKind = utils.getOutputKind(json, markdown);
  const [orgSlug] = await utils.determineOrgSlug(String(orgFlag || ''), cli.input[0] || '', !!interactive, !!dryRun);
  const hasApiToken = utils.hasDefaultToken();
  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: true,
    test: !!orgSlug,
    message: 'Org name as the first argument',
    pass: 'ok',
    fail: 'missing'
  }, {
    nook: true,
    test: !json || !markdown,
    message: 'The json and markdown flags cannot be both set, pick one',
    pass: 'ok',
    fail: 'omit one'
  }, {
    nook: true,
    test: hasApiToken,
    message: 'You need to be logged in to use this command. See `socket login`.',
    pass: 'ok',
    fail: 'missing API token'
  });
  if (!wasValidInput) {
    return;
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$l);
    return;
  }
  await handleSecurityPolicy(orgSlug, outputKind);
}

const description$6 = 'Organization policy details';
const cmdOrganizationPolicy = {
  description: description$6,
  // Hidden because it was broken all this time (nobody could be using it)
  // and we're not sure if it's useful to anyone in its current state.
  // Until we do, we'll hide this to keep the help tidier.
  // And later, we may simply move this under `scan`, anyways.
  hidden: true,
  async run(argv, importMeta, {
    parentName
  }) {
    await utils.meowWithSubcommands({
      security: cmdOrganizationPolicyPolicy,
      license: cmdOrganizationPolicyLicense
    }, {
      argv,
      description: description$6,
      defaultSub: 'list',
      // Backwards compat
      importMeta,
      name: parentName + ' policy'
    });
  }
};

async function fetchQuota() {
  const sockSdkResult = await utils.setupSdk();
  if (!sockSdkResult.ok) {
    return sockSdkResult;
  }
  const sockSdk = sockSdkResult.data;
  return await utils.handleApiCall(sockSdk.getQuota(), 'token quota');
}

async function outputQuota(result, outputKind = 'text') {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result));
    return;
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  if (outputKind === 'markdown') {
    logger.logger.log('# Quota');
    logger.logger.log('');
    logger.logger.log(`Quota left on the current API token: ${result.data.quota}`);
    logger.logger.log('');
    return;
  }
  logger.logger.log(`Quota left on the current API token: ${result.data.quota}`);
  logger.logger.log('');
}

async function handleQuota(outputKind = 'text') {
  const data = await fetchQuota();
  await outputQuota(data, outputKind);
}

const {
  DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$k
} = constants;
const config$m = {
  commandName: 'quota',
  description: 'List organizations associated with the API key used',
  hidden: true,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags
  },
  help: (command, _config) => `
    Usage
      $ ${command}

    Options
      ${utils.getFlagListOutput(config$m.flags, 6)}
  `
};
const cmdOrganizationQuota = {
  description: config$m.description,
  hidden: config$m.hidden,
  run: run$m
};
async function run$m(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$m,
    importMeta,
    parentName
  });
  const json = Boolean(cli.flags['json']);
  const markdown = Boolean(cli.flags['markdown']);
  const outputKind = utils.getOutputKind(json, markdown);
  const hasApiToken = utils.hasDefaultToken();
  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: true,
    test: !json || !markdown,
    message: 'The json and markdown flags cannot be both set, pick one',
    pass: 'ok',
    fail: 'omit one'
  }, {
    nook: true,
    test: hasApiToken,
    message: 'You need to be logged in to use this command. See `socket login`.',
    pass: 'ok',
    fail: 'missing API token'
  });
  if (!wasValidInput) {
    return;
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$k);
    return;
  }
  await handleQuota(outputKind);
}

const description$5 = 'Account details';
const cmdOrganization = {
  description: description$5,
  // Hidden because it was broken all this time (nobody could be using it)
  // and we're not sure if it's useful to anyone in its current state.
  // Until we do, we'll hide this to keep the help tidier.
  // And later, we may simply move this under `scan`, anyways.
  hidden: true,
  async run(argv, importMeta, {
    parentName
  }) {
    await utils.meowWithSubcommands({
      list: cmdOrganizationList,
      quota: cmdOrganizationQuota,
      policy: cmdOrganizationPolicy
    }, {
      argv,
      description: description$5,
      defaultSub: 'list',
      // Backwards compat
      importMeta,
      name: parentName + ' organization'
    });
  }
};

async function fetchPurlDeepScore(purl) {
  logger.logger.info(`Requesting deep score data for this purl: ${purl}`);
  return await utils.queryApiSafeJson(`purl/score/${encodeURIComponent(purl)}`, 'the deep package scores');
}

async function outputPurlScore(purl, result, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result));
    return;
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  if (outputKind === 'markdown') {
    const {
      purl: requestedPurl,
      self: {
        alerts: selfAlerts,
        capabilities: selfCaps,
        purl,
        score: selfScore
      },
      transitively: {
        alerts,
        capabilities,
        dependencyCount,
        func,
        lowest,
        score
      }
    } = result.data;
    logger.logger.success(`Score report for "${requestedPurl}" ("${purl}"):\n`);
    logger.logger.log('# Complete Package Score');
    logger.logger.log('');
    if (dependencyCount) {
      logger.logger.log(`This is a Socket report for the package *"${purl}"* and its *${dependencyCount}* direct/transitive dependencies.`);
    } else {
      logger.logger.log(`This is a Socket report for the package *"${purl}"*. It has *no dependencies*.`);
    }
    logger.logger.log('');
    if (dependencyCount) {
      logger.logger.log(`It will show you the shallow score for just the package itself and a deep score for all the transitives combined. Additionally you can see which capabilities were found and the top alerts as well as a package that was responsible for it.`);
    } else {
      logger.logger.log(`It will show you the shallow score for the package itself, which capabilities were found, and its top alerts.`);
      logger.logger.log('');
      logger.logger.log('Since it has no dependencies, the shallow score is also the deep score.');
    }
    logger.logger.log('');
    if (dependencyCount) {
      // This doesn't make much sense if there are no dependencies. Better to omit it.
      logger.logger.log('The report should give you a good insight into the status of this package.');
      logger.logger.log('');
      logger.logger.log('## Package itself');
      logger.logger.log('');
      logger.logger.log('Here are results for the package itself (excluding data from dependencies).');
    } else {
      logger.logger.log('## Report');
      logger.logger.log('');
      logger.logger.log('The report should give you a good insight into the status of this package.');
    }
    logger.logger.log('');
    logger.logger.log('### Shallow Score');
    logger.logger.log('');
    logger.logger.log('This score is just for the package itself:');
    logger.logger.log('');
    logger.logger.log('- Overall: ' + selfScore.overall);
    logger.logger.log('- Maintenance: ' + selfScore.maintenance);
    logger.logger.log('- Quality: ' + selfScore.quality);
    logger.logger.log('- Supply Chain: ' + selfScore.supplyChain);
    logger.logger.log('- Vulnerability: ' + selfScore.vulnerability);
    logger.logger.log('- License: ' + selfScore.license);
    logger.logger.log('');
    logger.logger.log('### Capabilities');
    logger.logger.log('');
    if (selfCaps.length) {
      logger.logger.log('These are the capabilities detected in the package itself:');
      logger.logger.log('');
      selfCaps.forEach(cap => {
        logger.logger.log(`- ${cap}`);
      });
    } else {
      logger.logger.log('No capabilities were found in the package.');
    }
    logger.logger.log('');
    logger.logger.log('### Alerts for this package');
    logger.logger.log('');
    if (selfAlerts.length) {
      if (dependencyCount) {
        logger.logger.log('These are the alerts found for the package itself:');
      } else {
        logger.logger.log('These are the alerts found for this package:');
      }
      logger.logger.log('');
      logger.logger.log(utils.mdTable(selfAlerts, ['severity', 'name'], ['Severity', 'Alert Name']));
    } else {
      logger.logger.log('There are currently no alerts for this package.');
    }
    logger.logger.log('');
    if (dependencyCount) {
      logger.logger.log('## Transitive Package Results');
      logger.logger.log('');
      logger.logger.log('Here are results for the package and its direct/transitive dependencies.');
      logger.logger.log('');
      logger.logger.log('### Deep Score');
      logger.logger.log('');
      logger.logger.log('This score represents the package and and its direct/transitive dependencies:');
      logger.logger.log(`The function used to calculate the values in aggregate is: *"${func}"*`);
      logger.logger.log('');
      logger.logger.log('- Overall: ' + score.overall);
      logger.logger.log('- Maintenance: ' + score.maintenance);
      logger.logger.log('- Quality: ' + score.quality);
      logger.logger.log('- Supply Chain: ' + score.supplyChain);
      logger.logger.log('- Vulnerability: ' + score.vulnerability);
      logger.logger.log('- License: ' + score.license);
      logger.logger.log('');
      logger.logger.log('### Capabilities');
      logger.logger.log('');
      logger.logger.log('These are the packages with the lowest recorded score. If there is more than one with the lowest score, just one is shown here. This may help you figure out the source of low scores.');
      logger.logger.log('');
      logger.logger.log('- Overall: ' + lowest.overall);
      logger.logger.log('- Maintenance: ' + lowest.maintenance);
      logger.logger.log('- Quality: ' + lowest.quality);
      logger.logger.log('- Supply Chain: ' + lowest.supplyChain);
      logger.logger.log('- Vulnerability: ' + lowest.vulnerability);
      logger.logger.log('- License: ' + lowest.license);
      logger.logger.log('');
      logger.logger.log('### Capabilities');
      logger.logger.log('');
      if (capabilities.length) {
        logger.logger.log('These are the capabilities detected in at least one package:');
        logger.logger.log('');
        capabilities.forEach(cap => {
          logger.logger.log(`- ${cap}`);
        });
      } else {
        logger.logger.log('This package had no capabilities and neither did any of its direct/transitive dependencies.');
      }
      logger.logger.log('');
      logger.logger.log('### Alerts');
      logger.logger.log('');
      if (alerts.length) {
        logger.logger.log('These are the alerts found:');
        logger.logger.log('');
        logger.logger.log(utils.mdTable(alerts, ['severity', 'name', 'example'], ['Severity', 'Alert Name', 'Example package reporting it']));
      } else {
        logger.logger.log('This package had no alerts and neither did any of its direct/transitive dependencies');
      }
      logger.logger.log('');
    }
    return;
  }
  logger.logger.log(`Score report for "${purl}" (use --json for raw and --markdown for formatted reports):`);
  logger.logger.log(result.data);
  logger.logger.log('');
}

async function handlePurlDeepScore(purl, outputKind) {
  const result = await fetchPurlDeepScore(purl);
  await outputPurlScore(purl, result, outputKind);
}

// Either an ecosystem was given or all args must be (namespaced) purls
// The `pkg:` part is optional here. We'll scan for `eco/name@version`.
// Not hardcoding the namespace since we don't know what the server accepts.
// The ecosystem is considered as the first package if it is not an a-z string.
function parsePackageSpecifiers(ecosystem, pkgs) {
  let valid = true;
  const purls = [];
  if (!ecosystem) {
    valid = false;
  } else if (/^[a-zA-Z]+$/.test(ecosystem)) {
    for (let i = 0; i < pkgs.length; ++i) {
      const pkg = pkgs[i] ?? '';
      if (!pkg) {
        valid = false;
        break;
      } else if (pkg.startsWith('pkg:')) {
        // keep
        purls.push(pkg);
      } else {
        purls.push('pkg:' + ecosystem + '/' + pkg);
      }
    }
    if (!purls.length) {
      valid = false;
    }
  } else {
    // Assume ecosystem is a purl, too
    pkgs.unshift(ecosystem);
    for (let i = 0; i < pkgs.length; ++i) {
      const pkg = pkgs[i] ?? '';
      if (!/^(?:pkg:)?[a-zA-Z]+\/./.test(pkg)) {
        // At least one purl did not start with `pkg:eco/x` or `eco/x`
        valid = false;
        break;
      } else if (pkg.startsWith('pkg:')) {
        purls.push(pkg);
      } else {
        purls.push('pkg:' + pkg);
      }
    }
    if (!purls.length) {
      valid = false;
    }
  }
  return {
    purls,
    valid
  };
}

const {
  DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$j
} = constants;
const config$l = {
  commandName: 'score',
  description: '[beta] Look up score for one package which reflects all of its transitive dependencies as well',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags
  },
  help: (command, config) => `
    Usage
      $ ${command} <<ecosystem> <name> | <purl>>

    API Token Requirements
      - Quota: 100 units
      - Permissions: packages:list

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Show deep scoring details for one package. The score will reflect the package
    itself, any of its dependencies, and any of its transitive dependencies.

    When you want to know whether to trust a package, this is the command to run.

    See also the \`socket package shallow\` command, which returns the shallow
    score for any number of packages. That will not reflect the dependency scores.

    Only a few ecosystems are supported like npm, golang, and maven.

    A "purl" is a standard package name formatting: \`pkg:eco/name@version\`
    This command will automatically prepend "pkg:" when not present.

    The version is optional but when given should be a direct match.

    Examples
      $ ${command} npm babel-cli
      $ ${command} npm babel-cli@1.9.1
      $ ${command} npm/babel-cli@1.9.1
      $ ${command} pkg:npm/babel-cli@1.9.1
  `
};
const cmdPackageScore = {
  description: config$l.description,
  hidden: config$l.hidden,
  run: run$l
};
async function run$l(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$l,
    importMeta,
    parentName
  });
  const {
    json,
    markdown
  } = cli.flags;
  const outputKind = utils.getOutputKind(json, markdown);
  const [ecosystem = '', purl] = cli.input;
  const hasApiToken = utils.hasDefaultToken();
  const {
    purls,
    valid
  } = parsePackageSpecifiers(ecosystem, purl ? [purl] : []);
  const wasValidInput = utils.checkCommandInput(outputKind, {
    test: valid,
    message: 'First parameter must be an ecosystem or the whole purl',
    pass: 'ok',
    fail: 'bad'
  }, {
    test: purls.length === 1,
    message: 'Expecting at least one package',
    pass: 'ok',
    fail: purls.length === 0 ? 'missing' : 'too many'
  }, {
    nook: true,
    test: !json || !markdown,
    message: 'The json and markdown flags cannot be both set, pick one',
    pass: 'ok',
    fail: 'omit one'
  }, {
    nook: true,
    test: hasApiToken,
    message: 'You need to be logged in to use this command. See `socket login`.',
    pass: 'ok',
    fail: 'missing API token'
  });
  if (!wasValidInput) {
    return;
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$j);
    return;
  }
  await handlePurlDeepScore(purls[0] || '', outputKind);
}

async function fetchPurlsShallowScore(purls) {
  logger.logger.info(`Requesting shallow score data for ${purls.length} package urls (purl): ${purls.join(', ')}`);
  const sockSdkResult = await utils.setupSdk();
  if (!sockSdkResult.ok) {
    return sockSdkResult;
  }
  const sockSdk = sockSdkResult.data;
  const result = await utils.handleApiCall(sockSdk.batchPackageFetch({
    alerts: 'true'
  }, {
    components: purls.map(purl => ({
      purl
    }))
  }), 'looking up package');
  if (!result.ok) {
    return result;
  }

  // TODO: seems like there's a bug in the typing since we absolutely have to return the .data here
  return {
    ok: true,
    data: result.data
  };
}

function outputPurlsShallowScore(purls, result, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result));
    return;
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }

  // Make some effort to match the requested data with the response

  const set = new Set();
  result.data.forEach(data => {
    set.add('pkg:' + data.type + '/' + data.name + '@' + data.version);
    set.add('pkg:' + data.type + '/' + data.name);
  });
  const missing = purls.filter(purl => {
    if (set.has(purl)) {
      return false;
    }
    if (purl.endsWith('@latest') && set.has(purl.slice(0, -'@latest'.length))) {
      return false;
    }
    return true; // not found
  });
  if (outputKind === 'markdown') {
    logger.logger.log(`
# Shallow Package Report

This report contains the response for requesting data on some package url(s).

Please note: The listed scores are ONLY for the package itself. It does NOT
             reflect the scores of any dependencies, transitive or otherwise.

${missing.length ? `\n## Missing response\n\nAt least one package had no response or the purl was not canonical:\n\n${missing.map(purl => '- ' + purl + '\n').join('')}` : ''}

${result.data.map(data => '## ' + formatReportCard(data, false)).join('\n\n\n')}
    `.trim());
    return;
  }
  logger.logger.log('\n' + vendor.yoctocolorsCjsExports.bold('Shallow Package Score') + '\n');
  logger.logger.log('Please note: The listed scores are ONLY for the package itself. It does NOT\n' + '             reflect the scores of any dependencies, transitive or otherwise.');
  if (missing.length) {
    logger.logger.log(`\nAt least one package had no response or the purl was not canonical:\n${missing.map(purl => '\n- ' + vendor.yoctocolorsCjsExports.bold(purl)).join('')}`);
  }
  result.data.forEach(data => {
    logger.logger.log('\n');
    logger.logger.log(formatReportCard(data, true));
  });
  logger.logger.log('');
}
function formatReportCard(data, color) {
  const scoreResult = {
    'Supply Chain Risk': Math.floor((data.score?.supplyChain ?? 0) * 100),
    Maintenance: Math.floor((data.score?.maintenance ?? 0) * 100),
    Quality: Math.floor((data.score?.quality ?? 0) * 100),
    Vulnerabilities: Math.floor((data.score?.vulnerability ?? 0) * 100),
    License: Math.floor((data.score?.license ?? 0) * 100)
  };
  const alertString = getAlertString(data.alerts, !color);
  const purl = 'pkg:' + data.type + '/' + data.name + '@' + data.version;
  return ['Package: ' + (color ? vendor.yoctocolorsCjsExports.bold(purl) : purl), '', ...Object.entries(scoreResult).map(score => `- ${score[0]}:`.padEnd(20, ' ') + `  ${formatScore(score[1], !color, true)}`), alertString].join('\n');
}
function formatScore(score, noColor = false, pad = false) {
  const padded = String(score).padStart(pad ? 3 : 0, ' ');
  if (noColor) {
    return padded;
  }
  if (score >= 80) {
    return vendor.yoctocolorsCjsExports.green(padded);
  }
  if (score >= 60) {
    return vendor.yoctocolorsCjsExports.yellow(padded);
  }
  return vendor.yoctocolorsCjsExports.red(padded);
}
function getAlertString(alerts, noColor = false) {
  if (!alerts?.length) {
    return noColor ? `- Alerts: none!` : `- Alerts: ${vendor.yoctocolorsCjsExports.green('none')}!`;
  }
  const bad = alerts.filter(alert => alert.severity !== 'low' && alert.severity !== 'middle').sort((a, b) => a.type < b.type ? -1 : a.type > b.type ? 1 : 0);
  const mid = alerts.filter(alert => alert.severity === 'middle').sort((a, b) => a.type < b.type ? -1 : a.type > b.type ? 1 : 0);
  const low = alerts.filter(alert => alert.severity === 'low').sort((a, b) => a.type < b.type ? -1 : a.type > b.type ? 1 : 0);

  // We need to create the no-color string regardless because the actual string
  // contains a bunch of invisible ANSI chars which would screw up length checks.
  const colorless = `- Alerts (${bad.length}/${mid.length.toString()}/${low.length}):`;
  if (noColor) {
    return colorless + ' '.repeat(Math.max(0, 20 - colorless.length)) + '  ' + [bad.map(alert => `[${alert.severity}] ` + alert.type).join(', '), mid.map(alert => `[${alert.severity}] ` + alert.type).join(', '), low.map(alert => `[${alert.severity}] ` + alert.type).join(', ')].filter(Boolean).join(', ');
  }
  return `- Alerts (${vendor.yoctocolorsCjsExports.red(bad.length.toString())}/${vendor.yoctocolorsCjsExports.yellow(mid.length.toString())}/${low.length}):` + ' '.repeat(Math.max(0, 20 - colorless.length)) + '  ' + [bad.map(alert => vendor.yoctocolorsCjsExports.red(vendor.yoctocolorsCjsExports.dim(`[${alert.severity}] `) + alert.type)).join(', '), mid.map(alert => vendor.yoctocolorsCjsExports.yellow(vendor.yoctocolorsCjsExports.dim(`[${alert.severity}] `) + alert.type)).join(', '), low.map(alert => vendor.yoctocolorsCjsExports.dim(`[${alert.severity}] `) + alert.type).join(', ')].filter(Boolean).join(', ');
}

async function handlePurlsShallowScore({
  outputKind,
  purls
}) {
  const packageData = await fetchPurlsShallowScore(purls);
  outputPurlsShallowScore(purls, packageData, outputKind);
}

const {
  DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$i
} = constants;
const config$k = {
  commandName: 'shallow',
  description: '[beta] Look up info regarding one or more packages but not their transitives',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags
  },
  help: (command, config) => `
    Usage
      $ ${command} <<ecosystem> <name> [<name> ...] | <purl> [<purl> ...]>

    API Token Requirements
      - Quota: 100 units
      - Permissions: packages:list

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Show scoring details for one or more packages purely based on their own package.
    This means that any dependency scores are not reflected by the score. You can
    use the \`socket package score <pkg>\` command to get its full transitive score.

    Only a few ecosystems are supported like npm, golang, and maven.

    A "purl" is a standard package name formatting: \`pkg:eco/name@version\`
    This command will automatically prepend "pkg:" when not present.

    If the first arg is an ecosystem, remaining args that are not a purl are
    assumed to be scoped to that ecosystem.

    Examples
      $ ${command} npm webtorrent
      $ ${command} npm webtorrent@1.9.1
      $ ${command} npm/webtorrent@1.9.1
      $ ${command} pkg:npm/webtorrent@1.9.1
      $ ${command} maven webtorrent babel
      $ ${command} npm/webtorrent golang/babel
      $ ${command} npm npm/webtorrent@1.0.1 babel
  `
};
const cmdPackageShallow = {
  description: config$k.description,
  hidden: config$k.hidden,
  alias: {
    shallowScore: {
      description: config$k.description,
      hidden: true,
      argv: []
    }
  },
  run: run$k
};
async function run$k(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$k,
    importMeta,
    parentName
  });
  const {
    json,
    markdown
  } = cli.flags;
  const outputKind = utils.getOutputKind(json, markdown);
  const [ecosystem = '', ...pkgs] = cli.input;
  const {
    purls,
    valid
  } = parsePackageSpecifiers(ecosystem, pkgs);
  const wasValidInput = utils.checkCommandInput(outputKind, {
    test: valid,
    message: 'First parameter should be an ecosystem or all args must be purls',
    pass: 'ok',
    fail: 'bad'
  }, {
    test: purls.length > 0,
    message: 'Expecting at least one package',
    pass: 'ok',
    fail: 'missing'
  }, {
    nook: true,
    test: !json || !markdown,
    message: 'The json and markdown flags cannot be both set, pick one',
    pass: 'ok',
    fail: 'omit one'
  });
  if (!wasValidInput) {
    return;
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$i);
    return;
  }
  await handlePurlsShallowScore({
    outputKind,
    purls
  });
}

const description$4 = 'Commands relating to looking up published packages';
const cmdPackage = {
  description: description$4,
  hidden: false,
  async run(argv, importMeta, {
    parentName
  }) {
    await utils.meowWithSubcommands({
      score: cmdPackageScore,
      shallow: cmdPackageShallow
    }, {
      aliases: {
        deep: {
          description: description$4,
          hidden: true,
          argv: ['score']
        }
      },
      argv,
      description: description$4,
      importMeta,
      name: parentName + ' package'
    });
  }
};

async function runRawNpm(argv) {
  const spawnPromise = spawn.spawn(utils.getNpmBinPath(), argv, {
    // Lazily access constants.WIN32.
    shell: constants.WIN32,
    stdio: 'inherit'
  });
  // See https://nodejs.org/api/child_process.html#event-exit.
  spawnPromise.process.on('exit', (code, signalName) => {
    if (signalName) {
      process.kill(process.pid, signalName);
    } else if (code !== null) {
      // eslint-disable-next-line n/no-process-exit
      process.exit(code);
    }
  });
  await spawnPromise;
}

const {
  DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$h,
  NPM
} = constants;
const config$j = {
  commandName: 'raw-npm',
  description: `Temporarily disable the Socket ${NPM} wrapper`,
  hidden: false,
  flags: {},
  help: command => `
    Usage
      $ ${command} <command>

    Examples
      $ ${command} install
  `
};
const cmdRawNpm = {
  description: config$j.description,
  hidden: config$j.hidden,
  run: run$j
};
async function run$j(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    allowUnknownFlags: true,
    argv,
    config: config$j,
    importMeta,
    parentName
  });
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$h);
    return;
  }
  await runRawNpm(argv);
}

async function runRawNpx(argv) {
  const spawnPromise = spawn.spawn(utils.getNpxBinPath(), argv, {
    // Lazily access constants.WIN32.
    shell: constants.WIN32,
    stdio: 'inherit'
  });
  // See https://nodejs.org/api/child_process.html#event-exit.
  spawnPromise.process.on('exit', (code, signalName) => {
    if (signalName) {
      process.kill(process.pid, signalName);
    } else if (code !== null) {
      // eslint-disable-next-line n/no-process-exit
      process.exit(code);
    }
  });
  await spawnPromise;
}

const {
  DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$g,
  NPX
} = constants;
const config$i = {
  commandName: 'raw-npx',
  description: `Temporarily disable the Socket ${NPX} wrapper`,
  hidden: false,
  flags: {},
  help: command => `
    Usage
      $ ${command} <command>

    Examples
      $ ${command} install
  `
};
const cmdRawNpx = {
  description: config$i.description,
  hidden: config$i.hidden,
  run: run$i
};
async function run$i(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    allowUnknownFlags: true,
    argv,
    config: config$i,
    importMeta,
    parentName
  });
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$g);
    return;
  }
  await runRawNpx(argv);
}

const config$h = {
  commandName: 'create',
  description: '[Deprecated] Create a project report',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags
  },
  help: () => `
    This command is deprecated in favor of \`socket scan view\`.
    It will be removed in the next major release of the CLI.
  `
};
const cmdReportCreate = {
  description: config$h.description,
  hidden: config$h.hidden,
  run: run$h
};
async function run$h(argv, importMeta, {
  parentName
}) {
  utils.meowOrExit({
    argv,
    config: config$h,
    importMeta,
    parentName
  });
  logger.logger.fail('This command has been sunset. Instead, please look at `socket scan create` to create scans and `socket scan report` to view a report of your scans.');
  process.exitCode = 1;
}

const config$g = {
  commandName: 'view',
  description: '[Deprecated] View a project report',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags
  },
  help: () => `
    This command is deprecated in favor of \`socket scan view\`.
    It will be removed in the next major release of the CLI.
  `
};
const cmdReportView = {
  description: config$g.description,
  hidden: config$g.hidden,
  run: run$g
};
async function run$g(argv, importMeta, {
  parentName
}) {
  utils.meowOrExit({
    argv,
    config: config$g,
    importMeta,
    parentName
  });
  logger.logger.fail('This command has been sunset. Instead, please look at `socket scan create` to create scans and `socket scan report` to view a report of your scans.');
  process.exitCode = 1;
}

const description$3 = '[Deprecated] Project report related commands';
const cmdReport = {
  description: description$3,
  hidden: true,
  // Deprecated in favor of `scan`
  async run(argv, importMeta, {
    parentName
  }) {
    await utils.meowWithSubcommands({
      create: cmdReportCreate,
      view: cmdReportView
    }, {
      argv,
      description: description$3,
      importMeta,
      name: parentName + ' report'
    });
  }
};

async function fetchCreateRepo({
  default_branch,
  description,
  homepage,
  orgSlug,
  repoName,
  visibility
}) {
  const sockSdkResult = await utils.setupSdk();
  if (!sockSdkResult.ok) {
    return sockSdkResult;
  }
  const sockSdk = sockSdkResult.data;
  return await utils.handleApiCall(sockSdk.createOrgRepo(orgSlug, {
    name: repoName,
    description,
    homepage,
    default_branch,
    visibility
  }), 'to create a repository');
}

function outputCreateRepo(result, requestedName, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result));
    return;
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  const {
    slug
  } = result.data;
  logger.logger.success(`OK. Repository created successfully, slug: \`${slug}\`${slug !== requestedName ? ' (Warning: slug is not the same as name that was requested!)' : ''}`);
}

async function handleCreateRepo({
  default_branch,
  description,
  homepage,
  orgSlug,
  repoName,
  visibility
}, outputKind) {
  const data = await fetchCreateRepo({
    default_branch,
    description,
    homepage,
    orgSlug,
    repoName,
    visibility
  });
  outputCreateRepo(data, repoName, outputKind);
}

const {
  DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$f
} = constants;
const config$f = {
  commandName: 'create',
  description: 'Create a repository in an organization',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags,
    defaultBranch: {
      type: 'string',
      shortFlag: 'b',
      default: 'main',
      description: 'Repository default branch'
    },
    homepage: {
      type: 'string',
      shortFlag: 'h',
      default: '',
      description: 'Repository url'
    },
    interactive: {
      type: 'boolean',
      default: true,
      description: 'Allow for interactive elements, asking for input. Use --no-interactive to prevent any input questions, defaulting them to cancel/no.'
    },
    org: {
      type: 'string',
      description: 'Force override the organization slug, overrides the default org from config'
    },
    repoDescription: {
      type: 'string',
      shortFlag: 'd',
      default: '',
      description: 'Repository description'
    },
    repoName: {
      type: 'string',
      shortFlag: 'n',
      default: '',
      description: 'Repository name'
    },
    visibility: {
      type: 'string',
      shortFlag: 'v',
      default: 'private',
      description: 'Repository visibility (Default Private)'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command} ${utils.isTestingV1() ? '<repo>' : '<org slug> --repo-name=<name>'}

    API Token Requirements
      - Quota: 1 unit
      - Permissions: repo:create

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command} ${utils.isTestingV1() ? 'test-repo' : 'FakeOrg --repoName=test-repo'}
  `
};
const cmdReposCreate = {
  description: config$f.description,
  hidden: config$f.hidden,
  run: run$f
};
async function run$f(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$f,
    importMeta,
    parentName
  });
  const {
    dryRun,
    interactive,
    json,
    markdown,
    org: orgFlag,
    repoName: repoNameFlag
  } = cli.flags;
  const outputKind = utils.getOutputKind(json, markdown); // TODO: impl json/md further

  const [orgSlug] = await utils.determineOrgSlug(String(orgFlag || ''), cli.input[0] || '', !!interactive, !!dryRun);
  const repoName = (utils.isTestingV1() ? cli.input[0] : repoNameFlag) || '';
  const hasApiToken = utils.hasDefaultToken();
  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: true,
    test: !!orgSlug,
    message: utils.isTestingV1() ? 'Org name by default setting, --org, or auto-discovered' : 'Org name must be the first argument',
    pass: 'ok',
    fail: 'missing'
  }, {
    test: !!repoName,
    message: utils.isTestingV1() ? 'Repository name as first argument' : 'Repository name using --repoName',
    pass: 'ok',
    fail: 'missing'
  }, {
    nook: true,
    test: hasApiToken,
    message: 'You need to be logged in to use this command. See `socket login`.',
    pass: 'ok',
    fail: 'missing API token'
  }, {
    nook: true,
    test: !utils.isTestingV1() || !repoNameFlag,
    message: 'In v1 the first arg should be the repo, not the flag',
    pass: 'ok',
    fail: 'received --repo-name flag'
  });
  if (!wasValidInput) {
    return;
  }
  if (dryRun) {
    logger.logger.log(DRY_RUN_BAILING_NOW$f);
    return;
  }
  await handleCreateRepo({
    orgSlug,
    repoName: String(repoName),
    description: String(cli.flags['repoDescription'] || ''),
    homepage: String(cli.flags['homepage'] || ''),
    default_branch: String(cli.flags['defaultBranch'] || ''),
    visibility: String(cli.flags['visibility'] || 'private')
  }, outputKind);
}

async function fetchDeleteRepo(orgSlug, repoName) {
  const sockSdkResult = await utils.setupSdk();
  if (!sockSdkResult.ok) {
    return sockSdkResult;
  }
  const sockSdk = sockSdkResult.data;
  return await utils.handleApiCall(sockSdk.deleteOrgRepo(orgSlug, repoName), 'to delete a repository');
}

async function outputDeleteRepo(result, repoName, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result));
    return;
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  logger.logger.success(`OK. Repository \`${repoName}\` deleted successfully`);
}

async function handleDeleteRepo(orgSlug, repoName, outputKind) {
  const data = await fetchDeleteRepo(orgSlug, repoName);
  await outputDeleteRepo(data, repoName, outputKind);
}

const {
  DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$e
} = constants;
const config$e = {
  commandName: 'del',
  description: 'Delete a repository in an organization',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags,
    interactive: {
      type: 'boolean',
      default: true,
      description: 'Allow for interactive elements, asking for input. Use --no-interactive to prevent any input questions, defaulting them to cancel/no.'
    },
    org: {
      type: 'string',
      description: 'Force override the organization slug, overrides the default org from config'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command} ${utils.isTestingV1() ? '<repo>' : '<org slug> --repo-name=<name>'}

    API Token Requirements
      - Quota: 1 unit
      - Permissions: repo:delete

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command} ${utils.isTestingV1() ? 'test-repo' : 'FakeOrg test-repo'}
  `
};
const cmdReposDel = {
  description: config$e.description,
  hidden: config$e.hidden,
  run: run$e
};
async function run$e(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$e,
    importMeta,
    parentName
  });
  const {
    dryRun,
    interactive,
    json,
    markdown,
    org: orgFlag
  } = cli.flags;
  const outputKind = utils.getOutputKind(json, markdown);
  const [orgSlug, defaultOrgSlug] = await utils.determineOrgSlug(String(orgFlag || ''), cli.input[0] || '', !!interactive, !!dryRun);
  const repoName = (defaultOrgSlug || utils.isTestingV1() ? cli.input[0] : cli.input[1]) || '';
  const hasApiToken = utils.hasDefaultToken();
  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: true,
    test: !!orgSlug,
    message: utils.isTestingV1() ? 'Org name by default setting, --org, or auto-discovered' : 'Org name must be the first argument',
    pass: 'ok',
    fail: 'missing'
  }, {
    test: !!repoName,
    message: utils.isTestingV1() ? 'Repository name as first argument' : 'Repository name using --repoName',
    pass: 'ok',
    fail: 'missing'
  }, {
    nook: true,
    test: hasApiToken,
    message: 'You need to be logged in to use this command. See `socket login`.',
    pass: 'ok',
    fail: 'missing API token'
  });
  if (!wasValidInput) {
    return;
  }
  if (dryRun) {
    logger.logger.log(DRY_RUN_BAILING_NOW$e);
    return;
  }
  await handleDeleteRepo(orgSlug, repoName, outputKind);
}

async function fetchListAllRepos({
  direction,
  orgSlug,
  sort
}) {
  const sockSdkResult = await utils.setupSdk();
  if (!sockSdkResult.ok) {
    return sockSdkResult;
  }
  const sockSdk = sockSdkResult.data;
  const rows = [];
  let protection = 0;
  let nextPage = 0;
  while (nextPage >= 0) {
    if (++protection > 100) {
      return {
        ok: false,
        message: 'Infinite loop detected',
        cause: `Either there are over 100 pages of results or the fetch has run into an infinite loop. Breaking it off now. nextPage=${nextPage}`
      };
    }
    // eslint-disable-next-line no-await-in-loop
    const result = await utils.handleApiCall(sockSdk.getOrgRepoList(orgSlug, {
      sort,
      direction,
      per_page: String(100),
      // max
      page: String(nextPage)
    }), 'list of repositories');
    if (!result.ok) {
      debug.debugLog('[DEBUG] fetchListAllRepos: At least one fetch failed, bailing...');
      debug.debugLog(result);
      return result;
    }
    result.data.results.forEach(row => rows.push(row));
    nextPage = result.data.nextPage ?? -1;
  }
  return {
    ok: true,
    data: {
      results: rows,
      nextPage: null
    }
  };
}

async function fetchListRepos({
  direction,
  orgSlug,
  page,
  per_page,
  sort
}) {
  const sockSdkResult = await utils.setupSdk();
  if (!sockSdkResult.ok) {
    return sockSdkResult;
  }
  const sockSdk = sockSdkResult.data;
  return await utils.handleApiCall(sockSdk.getOrgRepoList(orgSlug, {
    sort,
    direction,
    per_page: String(per_page),
    page: String(page)
  }), 'list of repositories');
}

// @ts-ignore
async function outputListRepos(result, outputKind, page, nextPage, sort, perPage, direction) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (outputKind === 'json') {
    if (result.ok) {
      logger.logger.log(utils.serializeResultJson({
        ok: true,
        data: {
          data: result.data,
          direction,
          nextPage: nextPage ?? 0,
          page,
          perPage,
          sort
        }
      }));
    } else {
      logger.logger.log(utils.serializeResultJson(result));
    }
    return;
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  logger.logger.log(`Result page: ${page}, results per page: ${perPage === Infinity ? 'all' : perPage}, sorted by: ${sort}, direction: ${direction}`);
  const options = {
    columns: [{
      field: 'id',
      name: vendor.yoctocolorsCjsExports.magenta('ID')
    }, {
      field: 'name',
      name: vendor.yoctocolorsCjsExports.magenta('Name')
    }, {
      field: 'visibility',
      name: vendor.yoctocolorsCjsExports.magenta('Visibility')
    }, {
      field: 'default_branch',
      name: vendor.yoctocolorsCjsExports.magenta('Default branch')
    }, {
      field: 'archived',
      name: vendor.yoctocolorsCjsExports.magenta('Archived')
    }]
  };
  logger.logger.log(vendor.srcExports(options, result.data.results));
  if (nextPage) {
    logger.logger.info(`This is page ${page}. Server indicated there are more results available on page ${nextPage}...`);
    logger.logger.info(`(Hint: you can use \`socket repos list --page ${nextPage}\`)`);
  } else if (perPage === Infinity) {
    logger.logger.info(`This should be the entire list available on the server.`);
  } else {
    logger.logger.info(`This is page ${page}. Server indicated this is the last page with results.`);
  }
}

async function handleListRepos({
  all,
  direction,
  orgSlug,
  outputKind,
  page,
  per_page,
  sort
}) {
  if (all) {
    const data = await fetchListAllRepos({
      direction,
      orgSlug,
      sort
    });
    await outputListRepos(data, outputKind, 0, 0, sort, Infinity, direction);
  } else {
    const data = await fetchListRepos({
      direction,
      orgSlug,
      page,
      per_page,
      sort
    });
    if (!data.ok) {
      await outputListRepos(data, outputKind, 0, 0, '', 0, direction);
    } else {
      // Note: nextPage defaults to 0, is null when there's no next page
      await outputListRepos(data, outputKind, page, data.data.nextPage, sort, per_page, direction);
    }
  }
}

const {
  DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$d
} = constants;
const config$d = {
  commandName: 'list',
  description: 'List repositories in an organization',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags,
    all: {
      type: 'boolean',
      default: false,
      description: 'By default view shows the last n repos. This flag allows you to fetch the entire list. Will ignore --page and --perPage.'
    },
    direction: {
      type: 'string',
      default: 'desc',
      description: 'Direction option'
    },
    interactive: {
      type: 'boolean',
      default: true,
      description: 'Allow for interactive elements, asking for input. Use --no-interactive to prevent any input questions, defaulting them to cancel/no.'
    },
    org: {
      type: 'string',
      description: 'Force override the organization slug, overrides the default org from config'
    },
    perPage: {
      type: 'number',
      shortFlag: 'pp',
      default: 30,
      description: 'Number of results per page'
    },
    page: {
      type: 'number',
      shortFlag: 'p',
      default: 1,
      description: 'Page number'
    },
    sort: {
      type: 'string',
      shortFlag: 's',
      default: 'created_at',
      description: 'Sorting option'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command} ${utils.isTestingV1() ? '' : '<org slug>'}

    API Token Requirements
      - Quota: 1 unit
      - Permissions: repo:list

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command} ${utils.isTestingV1() ? '' : '<org slug>'}
  `
};
const cmdReposList = {
  description: config$d.description,
  hidden: config$d.hidden,
  run: run$d
};
async function run$d(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$d,
    importMeta,
    parentName
  });
  const {
    all,
    direction = 'desc',
    dryRun,
    interactive,
    json,
    markdown,
    org: orgFlag
  } = cli.flags;
  const outputKind = utils.getOutputKind(json, markdown);
  const [orgSlug] = await utils.determineOrgSlug(String(orgFlag || ''), cli.input[0] || '', !!interactive, !!dryRun);
  const hasApiToken = utils.hasDefaultToken();
  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: true,
    test: !!orgSlug,
    message: utils.isTestingV1() ? 'Org name by default setting, --org, or auto-discovered' : 'Org name must be the first argument',
    pass: 'ok',
    fail: 'missing'
  }, {
    nook: true,
    test: !json || !markdown,
    message: 'The `--json` and `--markdown` flags can not be used at the same time',
    pass: 'ok',
    fail: 'bad'
  }, {
    nook: true,
    test: hasApiToken,
    message: 'You need to be logged in to use this command. See `socket login`.',
    pass: 'ok',
    fail: 'missing API token'
  }, {
    nook: true,
    test: direction === 'asc' || direction === 'desc',
    message: 'The --direction value must be "asc" or "desc"',
    pass: 'ok',
    fail: 'unexpected value'
  });
  if (!wasValidInput) {
    return;
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$d);
    return;
  }
  await handleListRepos({
    all: Boolean(all),
    direction: direction === 'asc' ? 'asc' : 'desc',
    orgSlug,
    outputKind,
    page: Number(cli.flags['page']) || 1,
    per_page: Number(cli.flags['perPage']) || 30,
    sort: String(cli.flags['sort'] || 'created_at')
  });
}

async function fetchUpdateRepo({
  default_branch,
  description,
  homepage,
  orgSlug,
  repoName,
  visibility
}) {
  const sockSdkResult = await utils.setupSdk();
  if (!sockSdkResult.ok) {
    return sockSdkResult;
  }
  const sockSdk = sockSdkResult.data;
  return await utils.handleApiCall(sockSdk.updateOrgRepo(orgSlug, repoName, {
    orgSlug,
    name: repoName,
    description,
    homepage,
    default_branch,
    visibility
  }), 'to update a repository');
}

async function outputUpdateRepo(result, repoName, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result));
    return;
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  logger.logger.success(`Repository \`${repoName}\` updated successfully`);
}

async function handleUpdateRepo({
  default_branch,
  description,
  homepage,
  orgSlug,
  repoName,
  visibility
}, outputKind) {
  const data = await fetchUpdateRepo({
    default_branch,
    description,
    homepage,
    orgSlug,
    repoName,
    visibility
  });
  await outputUpdateRepo(data, repoName, outputKind);
}

const {
  DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$c
} = constants;
const config$c = {
  commandName: 'update',
  description: 'Update a repository in an organization',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags,
    defaultBranch: {
      type: 'string',
      shortFlag: 'b',
      default: 'main',
      description: 'Repository default branch'
    },
    homepage: {
      type: 'string',
      shortFlag: 'h',
      default: '',
      description: 'Repository url'
    },
    interactive: {
      type: 'boolean',
      default: true,
      description: 'Allow for interactive elements, asking for input. Use --no-interactive to prevent any input questions, defaulting them to cancel/no.'
    },
    org: {
      type: 'string',
      description: 'Force override the organization slug, overrides the default org from config'
    },
    repoName: {
      type: 'string',
      shortFlag: 'n',
      default: '',
      description: 'Repository name'
    },
    repoDescription: {
      type: 'string',
      shortFlag: 'd',
      default: '',
      description: 'Repository description'
    },
    visibility: {
      type: 'string',
      shortFlag: 'v',
      default: 'private',
      description: 'Repository visibility (Default Private)'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command} ${utils.isTestingV1() ? '<repo>' : '<org slug> --repo-name=<name>'}

    API Token Requirements
      - Quota: 1 unit
      - Permissions: repo:update

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command} ${utils.isTestingV1() ? 'test-repo' : 'FakeOrg test-repo'}
  `
};
const cmdReposUpdate = {
  description: config$c.description,
  hidden: config$c.hidden,
  run: run$c
};
async function run$c(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$c,
    importMeta,
    parentName
  });
  const {
    dryRun,
    interactive,
    json,
    markdown,
    org: orgFlag
  } = cli.flags;
  const outputKind = utils.getOutputKind(json, markdown); // TODO: impl json/md further

  const [orgSlug] = await utils.determineOrgSlug(String(orgFlag || ''), cli.input[0] || '', !!interactive, !!dryRun);
  const repoNameFlag = cli.flags['repoName'];
  const repoName = (utils.isTestingV1() ? cli.input[0] : repoNameFlag) || '';
  const hasApiToken = utils.hasDefaultToken();
  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: true,
    test: !!orgSlug,
    message: utils.isTestingV1() ? 'Org name by default setting, --org, or auto-discovered' : 'Org name must be the first argument',
    pass: 'ok',
    fail: 'missing'
  }, {
    test: !!repoName,
    message: utils.isTestingV1() ? 'Repository name as first argument' : 'Repository name using --repoName',
    pass: 'ok',
    fail: 'missing'
  }, {
    nook: true,
    test: hasApiToken,
    message: 'You need to be logged in to use this command. See `socket login`.',
    pass: 'ok',
    fail: 'missing API token'
  }, {
    nook: true,
    test: !utils.isTestingV1() || !repoNameFlag,
    message: 'In v1 the first arg should be the repo, not the flag',
    pass: 'ok',
    fail: 'received --repo-name flag'
  });
  if (!wasValidInput) {
    return;
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$c);
    return;
  }
  await handleUpdateRepo({
    orgSlug,
    repoName: String(repoName),
    description: String(cli.flags['repoDescription'] || ''),
    homepage: String(cli.flags['homepage'] || ''),
    default_branch: String(cli.flags['defaultBranch'] || ''),
    visibility: String(cli.flags['visibility'] || 'private')
  }, outputKind);
}

async function fetchViewRepo(orgSlug, repoName) {
  const sockSdkResult = await utils.setupSdk();
  if (!sockSdkResult.ok) {
    return sockSdkResult;
  }
  const sockSdk = sockSdkResult.data;
  return await utils.handleApiCall(sockSdk.getOrgRepo(orgSlug, repoName), 'repository data');
}

// @ts-ignore
async function outputViewRepo(result, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result));
    return;
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  const options = {
    columns: [{
      field: 'id',
      name: vendor.yoctocolorsCjsExports.magenta('ID')
    }, {
      field: 'name',
      name: vendor.yoctocolorsCjsExports.magenta('Name')
    }, {
      field: 'visibility',
      name: vendor.yoctocolorsCjsExports.magenta('Visibility')
    }, {
      field: 'default_branch',
      name: vendor.yoctocolorsCjsExports.magenta('Default branch')
    }, {
      field: 'homepage',
      name: vendor.yoctocolorsCjsExports.magenta('Homepage')
    }, {
      field: 'archived',
      name: vendor.yoctocolorsCjsExports.magenta('Archived')
    }, {
      field: 'created_at',
      name: vendor.yoctocolorsCjsExports.magenta('Created at')
    }]
  };
  logger.logger.log(vendor.srcExports(options, [result.data]));
}

async function handleViewRepo(orgSlug, repoName, outputKind) {
  const data = await fetchViewRepo(orgSlug, repoName);
  await outputViewRepo(data, outputKind);
}

const {
  DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$b
} = constants;
const config$b = {
  commandName: 'view',
  description: 'View repositories in an organization',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags,
    interactive: {
      type: 'boolean',
      default: true,
      description: 'Allow for interactive elements, asking for input. Use --no-interactive to prevent any input questions, defaulting them to cancel/no.'
    },
    org: {
      type: 'string',
      description: 'Force override the organization slug, overrides the default org from config'
    },
    repoName: {
      description: 'The repository to check',
      default: '',
      type: 'string'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command} ${utils.isTestingV1() ? '<repo>' : '<org slug> --repo-name=<name>'}

    API Token Requirements
      - Quota: 1 unit
      - Permissions: repo:list

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command} ${utils.isTestingV1() ? 'test-repo' : 'FakeOrg test-repo'}
  `
};
const cmdReposView = {
  description: config$b.description,
  hidden: config$b.hidden,
  run: run$b
};
async function run$b(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$b,
    importMeta,
    parentName
  });
  const {
    dryRun,
    interactive,
    json,
    markdown,
    org: orgFlag,
    repoName: repoNameFlag
  } = cli.flags;
  const outputKind = utils.getOutputKind(json, markdown);
  const [orgSlug] = await utils.determineOrgSlug(String(orgFlag || ''), cli.input[0] || '', !!interactive, !!dryRun);
  const repoName = (utils.isTestingV1() ? cli.input[0] : repoNameFlag) || '';
  const hasApiToken = utils.hasDefaultToken();
  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: true,
    test: !!orgSlug,
    message: utils.isTestingV1() ? 'Org name by default setting, --org, or auto-discovered' : 'Org name must be the first argument',
    pass: 'ok',
    fail: 'missing'
  }, {
    test: !!repoName,
    message: utils.isTestingV1() ? 'Repository name as first argument' : 'Repository name using --repoName',
    pass: 'ok',
    fail: 'missing'
  }, {
    nook: true,
    test: !json || !markdown,
    message: 'The `--json` and `--markdown` flags can not be used at the same time',
    pass: 'ok',
    fail: 'bad'
  }, {
    nook: true,
    test: hasApiToken,
    message: 'You need to be logged in to use this command. See `socket login`.',
    pass: 'ok',
    fail: 'missing API token'
  }, {
    nook: true,
    test: !utils.isTestingV1() || !repoNameFlag,
    message: 'In v1 the first arg should be the repo, not the flag',
    pass: 'ok',
    fail: 'received --repo-name flag'
  });
  if (!wasValidInput) {
    return;
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$b);
    return;
  }
  await handleViewRepo(orgSlug, String(repoName), outputKind);
}

const description$2 = 'Repositories related commands';
const cmdRepos = {
  description: description$2,
  async run(argv, importMeta, {
    parentName
  }) {
    await utils.meowWithSubcommands({
      create: cmdReposCreate,
      view: cmdReposView,
      list: cmdReposList,
      del: cmdReposDel,
      update: cmdReposUpdate
    }, {
      argv,
      description: description$2,
      importMeta,
      name: `${parentName} repos`
    });
  }
};

async function suggestTarget() {
  // We could prefill this with sub-dirs of the current
  // dir ... but is that going to be useful?
  const proceed = await prompts.select({
    message: 'No TARGET given. Do you want to use the current directory?',
    choices: [{
      name: 'Yes',
      value: true,
      description: 'Target the current directory'
    }, {
      name: 'No',
      value: false,
      description: 'Do not use the current directory (this will end in a no-op)'
    }]
  });
  if (proceed) {
    return ['.'];
  }
}

const {
  DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$a
} = constants;
const config$a = {
  commandName: 'create',
  description: 'Create a scan',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags,
    autoManifest: {
      type: 'boolean',
      default: false,
      description: 'Run `socket manifest auto` before collecting manifest files? This would be necessary for languages like Scala, Gradle, and Kotlin, See `socket manifest auto --help`.'
    },
    branch: {
      type: 'string',
      shortFlag: 'b',
      default: 'socket-default-branch',
      description: 'Branch name'
    },
    commitMessage: {
      type: 'string',
      shortFlag: 'm',
      default: '',
      description: 'Commit message'
    },
    commitHash: {
      type: 'string',
      shortFlag: 'ch',
      default: '',
      description: 'Commit hash'
    },
    committers: {
      type: 'string',
      shortFlag: 'c',
      default: '',
      description: 'Committers'
    },
    cwd: {
      type: 'string',
      description: 'working directory, defaults to process.cwd()'
    },
    defaultBranch: {
      type: 'boolean',
      default: false,
      description: 'Set the default branch of the repository to the branch of this full-scan. Should only need to be done once, for example for the "main" or "master" branch.'
    },
    interactive: {
      type: 'boolean',
      default: true,
      description: 'Allow for interactive elements, asking for input. Use --no-interactive to prevent any input questions, defaulting them to cancel/no.'
    },
    pullRequest: {
      type: 'number',
      shortFlag: 'pr',
      description: 'Commit hash'
    },
    org: {
      type: 'string',
      description: 'Force override the organization slug, overrides the default org from config'
    },
    readOnly: {
      type: 'boolean',
      default: false,
      description: 'Similar to --dry-run except it can read from remote, stops before it would create an actual report'
    },
    repo: {
      type: 'string',
      shortFlag: 'r',
      default: 'socket-default-repository',
      description: 'Repository name'
    },
    report: {
      type: 'boolean',
      default: false,
      description: 'Wait for the scan creation to complete, then basically run `socket scan report` on it'
    },
    setAsAlertsPage: {
      type: 'boolean',
      default: true,
      aliases: ['pendingHead'],
      description: 'When true and if this is the "default branch" then this Scan will be the one reflected on your alerts page. See help for details. Defaults to true.'
    },
    tmp: {
      type: 'boolean',
      shortFlag: 't',
      default: false,
      description: 'Set the visibility (true/false) of the scan in your dashboard.'
    }
  },
  // TODO: your project's "socket.yml" file's "projectIgnorePaths"
  help: (command, config) => `
    Usage
      $ ${command} [...options]${utils.isTestingV1() ? '' : ' <org>'} <TARGET> [TARGET...]

    API Token Requirements
      - Quota: 1 unit
      - Permissions: full-scans:create

    Uploads the specified "package.json" and lock files for JavaScript, Python,
    Go, Scala, Gradle, and Kotlin dependency manifests.
    If any folder is specified, the ones found in there recursively are uploaded.

    Supports globbing such as "**/package.json", "**/requirements.txt", etc.

    Ignores any file specified in your project's ".gitignore" and also has a
    sensible set of default ignores from the "ignore-by-default" module.

    TARGET should be a FILE or DIR that _must_ be inside the CWD.

    When a FILE is given only that FILE is targeted. Otherwise any eligible
    files in the given DIR will be considered.

    The --repo and --branch flags tell Socket to associate this Scan with that
    repo/branch. The names will show up on your dashboard on the Socket website.

    Note: for a first run you probably want to set --defaultBranch to indicate
          the default branch name, like "main" or "master".

    The "alerts page" (https://socket.dev/dashboard/org/YOURORG/alerts) will show
    the results from the last scan designated as the "pending head" on the branch
    configured on Socket to be the "default branch". When creating a scan the
    --setAsAlertsPage flag will default to true to update this. You can prevent
    this by using --no-setAsAlertsPage. This flag is ignored for any branch that
    is not designated as the "default branch". It is disabled when using --tmp.

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command}${utils.isTestingV1() ? '' : ' FakeOrg'} .
      $ ${command} --repo=test-repo --branch=main${utils.isTestingV1() ? '' : ' FakeOrg'} ./package.json
  `
};
const cmdScanCreate = {
  description: config$a.description,
  hidden: config$a.hidden,
  run: run$a
};
async function run$a(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$a,
    importMeta,
    parentName
  });
  const {
    autoManifest = false,
    branch: branchName = 'socket-default-branch',
    commitHash,
    commitMessage,
    committers,
    cwd: cwdOverride,
    defaultBranch,
    dryRun = false,
    interactive = true,
    json,
    markdown,
    org: orgFlag,
    pullRequest,
    readOnly,
    repo: repoName = 'socket-default-repository',
    report,
    setAsAlertsPage: pendingHeadFlag,
    tmp
  } = cli.flags;
  const outputKind = utils.getOutputKind(json, markdown);
  const pendingHead = tmp ? false : pendingHeadFlag;
  let [orgSlug, defaultOrgSlug] = await utils.determineOrgSlug(String(orgFlag || ''), cli.input[0] || '', interactive, dryRun);
  if (!defaultOrgSlug) {
    // Tmp. just for TS. will drop this later.
    defaultOrgSlug = '';
  }
  let targets = cli.input.slice(utils.isTestingV1() || defaultOrgSlug ? 0 : 1);
  const cwd = cwdOverride && cwdOverride !== 'process.cwd()' ? String(cwdOverride) : process.cwd();

  // We're going to need an api token to suggest data because those suggestions
  // must come from data we already know. Don't error on missing api token yet.
  // If the api-token is not set, ignore it for the sake of suggestions.
  const hasApiToken = utils.hasDefaultToken();

  // If we updated any inputs then we should print the command line to repeat
  // the command without requiring user input, as a suggestion.
  let updatedInput = false;
  if (!targets.length && !dryRun && interactive) {
    const received = await suggestTarget();
    targets = received ?? [];
    updatedInput = true;
  }

  // If the current cwd is unknown and is used as a repo slug anyways, we will
  // first need to register the slug before we can use it.
  // Only do suggestions with an apiToken and when not in dryRun mode
  if (hasApiToken && !dryRun && interactive) {
    if (!orgSlug) {
      const suggestion = await utils.suggestOrgSlug();
      if (suggestion) {
        orgSlug = suggestion;
      }
      updatedInput = true;
    }
  }
  const detected = await detectManifestActions(cwd);
  if (detected.count > 0 && !autoManifest) {
    logger.logger.info(`Detected ${detected.count} manifest targets we could try to generate. Please set the --autoManifest flag if you want to include languages covered by \`socket manifest auto\` in the Scan.`);
  }
  if (updatedInput && orgSlug && targets?.length) {
    logger.logger.info('Note: You can invoke this command next time to skip the interactive questions:');
    logger.logger.info('```');
    logger.logger.info(`    socket scan create [other flags...] ${defaultOrgSlug ? '' : orgSlug} ${targets.join(' ')}`);
    logger.logger.info('```\n');
  }
  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: !utils.isTestingV1() && !!defaultOrgSlug,
    test: !!orgSlug && orgSlug !== '.',
    message: utils.isTestingV1() ? 'Org name by default setting, --org, or auto-discovered' : 'Org name must be the first argument',
    pass: 'ok',
    fail: orgSlug === '.' ? 'dot is an invalid org, most likely you forgot the org name here?' : 'missing'
  }, {
    test: !!targets.length,
    message: 'At least one TARGET (e.g. `.` or `./package.json`)',
    pass: 'ok',
    fail: 'missing (or perhaps you forgot the org slug?)'
  }, {
    nook: true,
    test: !json || !markdown,
    message: 'The json and markdown flags cannot be both set, pick one',
    pass: 'ok',
    fail: 'omit one'
  }, {
    nook: true,
    test: hasApiToken,
    message: 'This command requires an API token for access',
    pass: 'ok',
    fail: 'missing (try `socket login`)'
  }, {
    nook: true,
    test: !pendingHead || !!branchName,
    message: 'When --pendingHead is set, --branch is mandatory',
    pass: 'ok',
    fail: 'missing branch name'
  }, {
    nook: true,
    test: !defaultBranch || !!branchName,
    message: 'When --defaultBranch is set, --branch is mandatory',
    pass: 'ok',
    fail: 'missing branch name'
  });
  if (!wasValidInput) {
    return;
  }

  // Note exiting earlier to skirt a hidden auth requirement
  if (dryRun) {
    logger.logger.log(DRY_RUN_BAILING_NOW$a);
    return;
  }
  await handleCreateNewScan({
    autoManifest: Boolean(autoManifest),
    branchName: branchName,
    commitHash: commitHash && String(commitHash) || '',
    commitMessage: commitMessage && String(commitMessage) || '',
    committers: committers && String(committers) || '',
    cwd,
    defaultBranch: Boolean(defaultBranch),
    interactive: Boolean(interactive),
    orgSlug,
    outputKind,
    pendingHead: Boolean(pendingHead),
    pullRequest: Number(pullRequest),
    readOnly: Boolean(readOnly),
    repoName: repoName,
    report,
    targets,
    tmp: Boolean(tmp)
  });
}

async function fetchDeleteOrgFullScan(orgSlug, scanId) {
  const sockSdkResult = await utils.setupSdk();
  if (!sockSdkResult.ok) {
    return sockSdkResult;
  }
  const sockSdk = sockSdkResult.data;
  return await utils.handleApiCall(sockSdk.deleteOrgFullScan(orgSlug, scanId), 'to delete a scan');
}

async function outputDeleteScan(result, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result));
    return;
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  logger.logger.success('Scan deleted successfully');
}

async function handleDeleteScan(orgSlug, scanId, outputKind) {
  const data = await fetchDeleteOrgFullScan(orgSlug, scanId);
  await outputDeleteScan(data, outputKind);
}

const {
  DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$9
} = constants;
const config$9 = {
  commandName: 'del',
  description: 'Delete a scan',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags,
    interactive: {
      type: 'boolean',
      default: true,
      description: 'Allow for interactive elements, asking for input. Use --no-interactive to prevent any input questions, defaulting them to cancel/no.'
    },
    org: {
      type: 'string',
      description: 'Force override the organization slug, overrides the default org from config'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command}${utils.isTestingV1() ? '' : ' <org slug>'} <scan ID>

    API Token Requirements
      - Quota: 1 unit
      - Permissions: full-scans:delete

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command}${utils.isTestingV1() ? '' : ' FakeOrg'} 000aaaa1-0000-0a0a-00a0-00a0000000a0
  `
};
const cmdScanDel = {
  description: config$9.description,
  hidden: config$9.hidden,
  run: run$9
};
async function run$9(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$9,
    importMeta,
    parentName
  });
  const {
    dryRun,
    interactive,
    json,
    markdown,
    org: orgFlag
  } = cli.flags;
  const outputKind = utils.getOutputKind(json, markdown);
  const [orgSlug, defaultOrgSlug] = await utils.determineOrgSlug(String(orgFlag || ''), cli.input[0] || '', !!interactive, !!dryRun);
  const scanId = (utils.isTestingV1() || defaultOrgSlug ? cli.input[0] : cli.input[1]) || '';
  const hasApiToken = utils.hasDefaultToken();
  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: !!defaultOrgSlug,
    test: !!orgSlug && orgSlug !== '.',
    message: utils.isTestingV1() ? 'Org name by default setting, --org, or auto-discovered' : 'Org name must be the first argument',
    pass: 'ok',
    fail: orgSlug === '.' ? 'dot is an invalid org, most likely you forgot the org name here?' : 'missing'
  }, {
    test: !!scanId,
    message: 'Scan ID to delete',
    pass: 'ok',
    fail: 'missing'
  }, {
    nook: true,
    test: hasApiToken,
    message: 'You need to be logged in to use this command. See `socket login`.',
    pass: 'ok',
    fail: 'missing API token'
  });
  if (!wasValidInput) {
    return;
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$9);
    return;
  }
  await handleDeleteScan(orgSlug, scanId, outputKind);
}

async function fetchDiffScan({
  id1,
  id2,
  orgSlug
}) {
  logger.logger.info('Scan ID 1:', id1);
  logger.logger.info('Scan ID 2:', id2);
  logger.logger.info('Note: this request may take some time if the scans are big');
  return await utils.queryApiSafeJson(`orgs/${orgSlug}/full-scans/diff?before=${encodeURIComponent(id1)}&after=${encodeURIComponent(id2)}`, 'a scan diff');
}

const {
  SOCKET_WEBSITE_URL: SOCKET_WEBSITE_URL$2
} = constants;
const SOCKET_SBOM_URL_PREFIX$1 = `${SOCKET_WEBSITE_URL$2}/dashboard/org/SocketDev/sbom/`;
async function outputDiffScan(result, {
  depth,
  file,
  outputKind
}) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (!result.ok) {
    if (outputKind === 'json') {
      logger.logger.log(utils.serializeResultJson(result));
      return;
    }
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  const dashboardUrl = result.data.diff_report_url;
  const dashboardMessage = dashboardUrl ? `\n View this diff scan in the Socket dashboard: ${vendor.yoctocolorsCjsExports.cyan(dashboardUrl)}` : '';

  // When forcing json, or dumping to file, serialize to string such that it
  // won't get truncated. The only way to dump the full raw JSON to stdout is
  // to use `--json --file -` (the dash is a standard notation for stdout)
  if (outputKind === 'json' || file) {
    await handleJson(result, file, dashboardMessage);
    return;
  }
  if (outputKind === 'markdown') {
    await handleMarkdown(result.data);
    return;
  }

  // In this case neither the --json nor the --file flag was passed
  // Dump the JSON to CLI and let NodeJS deal with truncation

  logger.logger.log('Diff scan result:');
  logger.logger.log(util.inspect(result.data, {
    showHidden: false,
    depth: depth > 0 ? depth : null,
    colors: true,
    maxArrayLength: null
  }));
  logger.logger.info(`\n 📝 To display the detailed report in the terminal, use the --json flag. For a friendlier report, use the --markdown flag.\n`);
  logger.logger.info(dashboardMessage);
}
async function handleJson(data, file, dashboardMessage) {
  const json = utils.serializeResultJson(data);
  if (file && file !== '-') {
    logger.logger.log(`Writing json to \`${file}\``);
    fs$1.writeFile(file, json, err => {
      if (err) {
        logger.logger.fail(`Writing to \`${file}\` failed...`);
        logger.logger.error(err);
      } else {
        logger.logger.success(`Data successfully written to \`${file}\``);
      }
      logger.logger.error(dashboardMessage);
    });
  } else {
    // only .log goes to stdout
    logger.logger.info(`\n Diff scan result: \n`);
    logger.logger.log(json);
    logger.logger.info(dashboardMessage);
  }
}
async function handleMarkdown(data) {
  logger.logger.log('# Scan diff result');
  logger.logger.log('');
  logger.logger.log('This Socket.dev report shows the changes between two scans:');
  logger.logger.log(`- [${data.before.id}](${SOCKET_SBOM_URL_PREFIX$1}${data.before.id})`);
  logger.logger.log(`- [${data.after.id}](${SOCKET_SBOM_URL_PREFIX$1}${data.after.id})`);
  logger.logger.log('');
  logger.logger.log(`You can [view this report in your dashboard](${data.diff_report_url})`);
  logger.logger.log('');
  logger.logger.log('## Changes');
  logger.logger.log('');
  logger.logger.log(`- directDependenciesChanged: ${data.directDependenciesChanged}`);
  logger.logger.log(`- Added packages: ${data.artifacts.added.length}`);
  if (data.artifacts.added.length > 0) {
    data.artifacts.added.slice(0, 10).forEach(artifact => {
      logger.logger.log(`  - ${artifact.type} ${artifact.name}@${artifact.version}`);
    });
    if (data.artifacts.added.length > 10) {
      logger.logger.log(`  ... and ${data.artifacts.added.length - 10} more`);
    }
  }
  logger.logger.log(`- Removed packages: ${data.artifacts.removed.length}`);
  if (data.artifacts.removed.length > 0) {
    data.artifacts.removed.slice(0, 10).forEach(artifact => {
      logger.logger.log(`  - ${artifact.type} ${artifact.name}@${artifact.version}`);
    });
    if (data.artifacts.removed.length > 10) {
      logger.logger.log(`  ... and ${data.artifacts.removed.length - 10} more`);
    }
  }
  logger.logger.log(`- Replaced packages: ${data.artifacts.replaced.length}`);
  if (data.artifacts.replaced.length > 0) {
    data.artifacts.replaced.slice(0, 10).forEach(artifact => {
      logger.logger.log(`  - ${artifact.type} ${artifact.name}@${artifact.version}`);
    });
    if (data.artifacts.replaced.length > 10) {
      logger.logger.log(`  ... and ${data.artifacts.replaced.length - 10} more`);
    }
  }
  logger.logger.log(`- Updated packages: ${data.artifacts.updated.length}`);
  if (data.artifacts.updated.length > 0) {
    data.artifacts.updated.slice(0, 10).forEach(artifact => {
      logger.logger.log(`  - ${artifact.type} ${artifact.name}@${artifact.version}`);
    });
    if (data.artifacts.updated.length > 10) {
      logger.logger.log(`  ... and ${data.artifacts.updated.length - 10} more`);
    }
  }
  logger.logger.log(`- Unchanged packages: ${data.artifacts.unchanged.length}`);
  if (data.artifacts.unchanged.length > 0) {
    data.artifacts.unchanged.slice(0, 10).forEach(artifact => {
      logger.logger.log(`  - ${artifact.type} ${artifact.name}@${artifact.version}`);
    });
    if (data.artifacts.unchanged.length > 10) {
      logger.logger.log(`  ... and ${data.artifacts.unchanged.length - 10} more`);
    }
  }
  logger.logger.log('');
  logger.logger.log(`## Scan ${data.before.id}`);
  logger.logger.log('');
  logger.logger.log('This Scan was considered to be the "base" / "from" / "before" Scan.');
  logger.logger.log('');
  for (const [key, value] of Object.entries(data.before)) {
    if (key === 'pull_request' && !value) {
      continue;
    }
    if (!['id', 'organization_id', 'repository_id'].includes(key)) {
      logger.logger.group(`- ${key === 'repository_slug' ? 'repo' : key === 'organization_slug' ? 'org' : key}: ${value}`);
      logger.logger.groupEnd();
    }
  }
  logger.logger.log('');
  logger.logger.log(`## Scan ${data.after.id}`);
  logger.logger.log('');
  logger.logger.log('This Scan was considered to be the "head" / "to" / "after" Scan.');
  logger.logger.log('');
  for (const [key, value] of Object.entries(data.after)) {
    if (key === 'pull_request' && !value) {
      continue;
    }
    if (!['id', 'organization_id', 'repository_id'].includes(key)) {
      logger.logger.group(`- ${key === 'repository_slug' ? 'repo' : key === 'organization_slug' ? 'org' : key}: ${value}`);
      logger.logger.groupEnd();
    }
  }
  logger.logger.log('');
}

async function handleDiffScan({
  depth,
  file,
  id1,
  id2,
  orgSlug,
  outputKind
}) {
  const data = await fetchDiffScan({
    id1,
    id2,
    orgSlug
  });
  await outputDiffScan(data, {
    depth,
    file,
    outputKind
  });
}

const {
  DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$8,
  SOCKET_WEBSITE_URL: SOCKET_WEBSITE_URL$1
} = constants;
const SOCKET_SBOM_URL_PREFIX = `${SOCKET_WEBSITE_URL$1}/dashboard/org/SocketDev/sbom/`;
const {
  length: SOCKET_SBOM_URL_PREFIX_LENGTH
} = SOCKET_SBOM_URL_PREFIX;
const config$8 = {
  commandName: 'diff',
  description: 'See what changed between two Scans',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags,
    depth: {
      type: 'number',
      default: 2,
      description: 'Max depth of JSON to display before truncating, use zero for no limit (without --json/--file)'
    },
    file: {
      type: 'string',
      shortFlag: 'f',
      default: '',
      description: 'Path to a local file where the output should be saved. Use `-` to force stdout.'
    },
    interactive: {
      type: 'boolean',
      default: true,
      description: 'Allow for interactive elements, asking for input. Use --no-interactive to prevent any input questions, defaulting them to cancel/no.'
    },
    org: {
      type: 'string',
      description: 'Force override the organization slug, overrides the default org from config'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command}${utils.isTestingV1() ? '' : ' <org slug>'} <ID1> <ID2>

    API Token Requirements
      - Quota: 1 unit
      - Permissions: full-scans:list

    This command displays the package changes between two scans. The full output
    can be pretty large depending on the size of your repo and time range. It is
    best stored to disk (with --json) to be further analyzed by other tools.

    Note: First Scan ID is assumed to be the older ID. This is only relevant for
          the added/removed list (similar to diffing two files with git).

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command}${utils.isTestingV1() ? '' : ' FakeOrg'} aaa0aa0a-aaaa-0000-0a0a-0000000a00a0 aaa1aa1a-aaaa-1111-1a1a-1111111a11a1
      $ ${command}${utils.isTestingV1() ? '' : ' FakeOrg'} aaa0aa0a-aaaa-0000-0a0a-0000000a00a0 aaa1aa1a-aaaa-1111-1a1a-1111111a11a1 --json
  `
};
const cmdScanDiff = {
  description: config$8.description,
  hidden: config$8.hidden,
  run: run$8
};
async function run$8(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$8,
    importMeta,
    parentName
  });
  const {
    depth,
    dryRun,
    file,
    interactive,
    json,
    markdown,
    org: orgFlag
  } = cli.flags;
  const outputKind = utils.getOutputKind(json, markdown);
  const [orgSlug] = await utils.determineOrgSlug(String(orgFlag || ''), cli.input[0] || '', !!interactive, !!dryRun);
  let id1 = cli.input[utils.isTestingV1() || orgSlug ? 0 : 1] || '';
  let id2 = cli.input[utils.isTestingV1() || orgSlug ? 1 : 2] || '';
  if (id1.startsWith(SOCKET_SBOM_URL_PREFIX)) {
    id1 = id1.slice(SOCKET_SBOM_URL_PREFIX_LENGTH);
  }
  if (id2.startsWith(SOCKET_SBOM_URL_PREFIX)) {
    id2 = id2.slice(SOCKET_SBOM_URL_PREFIX_LENGTH);
  }
  const hasApiToken = utils.hasDefaultToken();
  const wasValidInput = utils.checkCommandInput(outputKind, {
    test: !!(id1 && id2),
    message: 'Specify two Scan IDs.\nA Scan ID looks like `aaa0aa0a-aaaa-0000-0a0a-0000000a00a0`.',
    pass: 'ok',
    fail: !id1 && !id2 ? 'missing both Scan IDs' : !id2 ? 'missing second Scan ID' : 'missing first Scan ID' // Not sure how this can happen but ok.
  }, {
    test: !!orgSlug,
    nook: true,
    message: utils.isTestingV1() ? 'Org name by default setting, --org, or auto-discovered' : 'Org name must be the first argument',
    pass: 'ok',
    fail: 'missing'
  }, {
    nook: true,
    test: !json || !markdown,
    message: 'The `--json` and `--markdown` flags can not be used at the same time',
    pass: 'ok',
    fail: 'bad'
  }, {
    nook: true,
    test: hasApiToken,
    message: 'You need to be logged in to use this command. See `socket login`.',
    pass: 'ok',
    fail: 'missing API token'
  });
  if (!wasValidInput) {
    return;
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$8);
    return;
  }
  await handleDiffScan({
    id1: String(id1 || ''),
    id2: String(id2 || ''),
    depth: Number(depth),
    orgSlug,
    outputKind,
    file: String(file || '')
  });
}

// Supported manifest file name patterns
// Keep in mind that we have to request these files through the GitHub API; that cost is much heavier than local disk searches
// TODO: get this list from API instead? Is that too much? Has to fetch through gh api...
const SUPPORTED_FILE_PATTERNS = [/.*[-.]spdx\.json/, /bom\.json/, /.*[-.]cyclonedx\.json/, /.*[-.]cyclonedx\.xml/, /package\.json/, /package-lock\.json/, /npm-shrinkwrap\.json/, /yarn\.lock/, /pnpm-lock\.yaml/, /pnpm-lock\.yml/, /pnpm-workspace\.yaml/, /pnpm-workspace\.yml/, /pipfile/, /pyproject\.toml/, /poetry\.lock/, /requirements[\\/].*\.txt/, /requirements-.*\.txt/, /requirements_.*\.txt/, /requirements\.frozen/, /setup\.py/, /pipfile\.lock/, /go\.mod/, /go\.sum/, /pom\.xml/, /.*\..*proj/, /.*\.props/, /.*\.targets/, /.*\.nuspec/, /nuget\.config/, /packages\.config/, /packages\.lock\.json/];
async function createScanFromGithub({
  all,
  githubApiUrl,
  githubToken,
  interactive,
  orgGithub,
  orgSlug,
  outputKind,
  repos
}) {
  let targetRepos = repos.trim().split(',').map(repo => repo.trim()).filter(Boolean);
  if (all || targetRepos.length === 0) {
    // Fetch from Socket API
    const result = await fetchListAllRepos({
      direction: 'asc',
      orgSlug,
      sort: 'name'
    });
    if (!result.ok) {
      return result;
    }
    targetRepos = result.data.results.map(obj => obj.slug || '');
  }
  targetRepos = targetRepos.map(slug => slug.trim()).filter(Boolean);
  logger.logger.info(`Have ${targetRepos.length} repo names to Scan!`);
  logger.logger.log('');
  if (!targetRepos.filter(Boolean).length) {
    return {
      ok: false,
      message: 'No repo found',
      cause: 'You did not set the --repos value and/or the server responded with zero repos when asked for some. Unable to proceed.'
    };
  }

  // Non-interactive or explicitly requested; just do it.
  if (interactive && targetRepos.length > 1 && !all && !repos) {
    const which = await selectFocus(targetRepos);
    if (!which.ok) {
      return which;
    }
    targetRepos = which.data;
  }

  // 10 is an arbitrary number. Maybe confirm whenever count>1 ?
  // Do not ask to confirm when the list was given explicit.
  if (interactive && (all || !repos) && targetRepos.length > 10) {
    const sure = await makeSure(targetRepos.length);
    if (!sure.ok) {
      return sure;
    }
  }
  for (const repoSlug of targetRepos) {
    // eslint-disable-next-line no-await-in-loop
    await scanRepo(repoSlug, {
      githubApiUrl,
      githubToken,
      orgSlug,
      orgGithub,
      outputKind,
      repos
    });
  }
  logger.logger.success('Scanned', targetRepos.length, 'repos, or tried to, anyways!');
  return {
    ok: true,
    data: undefined
  };
}
async function scanRepo(repoSlug, {
  githubApiUrl,
  githubToken,
  orgGithub,
  orgSlug,
  outputKind,
  repos
}) {
  logger.logger.info(`Requesting repo details from GitHub API for: \`${orgGithub}/${repoSlug}\`...`);
  logger.logger.group();
  const result = await scanOneRepo(repoSlug, {
    githubApiUrl,
    githubToken,
    orgSlug,
    orgGithub,
    outputKind});
  logger.logger.groupEnd();
  logger.logger.log('');
  return result;
}
async function scanOneRepo(repoSlug, {
  githubApiUrl,
  githubToken,
  orgGithub,
  orgSlug,
  outputKind
}) {
  const repoResult = await getRepoDetails({
    orgGithub,
    repoSlug,
    githubApiUrl,
    githubToken
  });
  if (!repoResult.ok) {
    return repoResult;
  }
  const {
    defaultBranch,
    repoApiUrl
  } = repoResult.data;
  logger.logger.info(`Default branch: \`${defaultBranch}\``);
  const treeResult = await getRepoBranchTree({
    orgGithub,
    repoSlug,
    repoApiUrl,
    defaultBranch,
    githubToken
  });
  if (!treeResult.ok) {
    return treeResult;
  }
  const files = treeResult.data;
  if (!files.length) {
    logger.logger.warn('No files were reported for the default branch. Moving on to next repo.');
    return {
      ok: true,
      data: undefined
    };
  }
  const tmpDir = fs$1.mkdtempSync(path.join(os.tmpdir(), repoSlug));
  debug.debugLog(`[DEBUG] Temp dir for downloaded manifest (serves as scan root): ${tmpDir}`);
  const downloadResult = await testAndDownloadManifestFiles({
    files,
    tmpDir,
    repoSlug,
    defaultBranch,
    orgGithub,
    repoApiUrl,
    githubToken
  });
  if (!downloadResult.ok) {
    return downloadResult;
  }
  const commitResult = await getLastCommitDetails({
    orgGithub,
    repoSlug,
    defaultBranch,
    repoApiUrl,
    githubToken
  });
  if (!commitResult.ok) {
    return commitResult;
  }
  const {
    lastCommitMessage,
    lastCommitSha,
    lastCommitter
  } = commitResult.data;

  // Make request for full scan
  // I think we can just kick off the socket scan create command now...

  await handleCreateNewScan({
    autoManifest: false,
    branchName: defaultBranch,
    commitHash: lastCommitSha,
    commitMessage: lastCommitMessage || '',
    committers: lastCommitter || '',
    cwd: tmpDir,
    defaultBranch: true,
    interactive: false,
    orgSlug,
    outputKind,
    pendingHead: true,
    pullRequest: 0,
    readOnly: false,
    repoName: repoSlug,
    report: false,
    targets: ['.'],
    tmp: false
  });
  return {
    ok: true,
    data: undefined
  };
}
async function testAndDownloadManifestFiles({
  defaultBranch,
  files,
  githubToken,
  orgGithub,
  repoApiUrl,
  repoSlug,
  tmpDir
}) {
  logger.logger.info(`File tree for ${defaultBranch} contains ${files.length} entries. Searching for supported manifest files...`);
  logger.logger.group();
  let fileCount = 0;
  let firstFailureResult;
  for (const file of files) {
    // eslint-disable-next-line no-await-in-loop
    const result = await testAndDownloadManifestFile({
      file,
      tmpDir,
      defaultBranch,
      repoApiUrl,
      githubToken
    });
    if (result.ok) {
      if (result.data.isManifest) {
        fileCount += 1;
      }
    } else if (!firstFailureResult) {
      firstFailureResult = result;
    }
  }
  logger.logger.info('Found and downloaded', fileCount, 'manifest files');
  logger.logger.groupEnd();
  if (!fileCount) {
    if (firstFailureResult) {
      logger.logger.fail('While no supported manifest files were downloaded, at least one error encountered trying to do so. Showing the first error.');
      return firstFailureResult;
    }
    return {
      ok: false,
      message: 'No manifest files found',
      cause: `No supported manifest files were found in the latest commit on the branch ${defaultBranch} for repo ${orgGithub}/${repoSlug}. Skipping full scan.`
    };
  }
  return {
    ok: true,
    data: undefined
  };
}
async function testAndDownloadManifestFile({
  defaultBranch,
  file,
  githubToken,
  repoApiUrl,
  tmpDir
}) {
  debug.debugLog(`[DEBUG] Testing file:`, file);
  if (!SUPPORTED_FILE_PATTERNS.some(regex => regex.test(file))) {
    // Not an error.
    return {
      ok: true,
      data: {
        isManifest: false
      }
    };
  }
  logger.logger.success(`Found a manifest file: \`${file}\`, will download it to temp dir...`);
  logger.logger.group();
  const result = await downloadManifestFile({
    file,
    tmpDir,
    defaultBranch,
    repoApiUrl,
    githubToken
  });
  logger.logger.groupEnd();
  if (!result.ok) {
    return result;
  }
  return {
    ok: true,
    data: {
      isManifest: true
    }
  };
}
async function downloadManifestFile({
  defaultBranch,
  file,
  githubToken,
  repoApiUrl,
  tmpDir
}) {
  logger.logger.info('Requesting download url from GitHub...');
  const fileUrl = `${repoApiUrl}/contents/${file}?ref=${defaultBranch}`;
  debug.debugLog('[DEBUG] File url:', fileUrl);
  const downloadUrlResponse = await fetch(fileUrl, {
    method: 'GET',
    headers: {
      Authorization: `Bearer ${githubToken}`
    }
  });
  logger.logger.success(`Request completed.`);
  const downloadUrlText = await downloadUrlResponse.text();
  debug.debugLog('[DEBUG] raw download url response:');
  debug.debugLog(downloadUrlText);
  let downloadUrl;
  try {
    downloadUrl = JSON.parse(downloadUrlText).download_url;
  } catch {
    logger.logger.fail(`GitHub response contained invalid JSON for download url for file`);
    logger.logger.error(downloadUrlText);
    return {
      ok: false,
      message: 'Invalid JSON response',
      cause: `Server responded with invalid JSON for download url ${downloadUrl}`
    };
  }
  logger.logger.info(`Downloading manifest file...`);
  const localPath = path.join(tmpDir, file);
  debug.debugLog('[DEBUG] Downloading from', downloadUrl, 'to', localPath);
  // Now stream the file to that file...

  const result = await streamDownloadWithFetch(localPath, downloadUrl);
  if (!result.ok) {
    // Do we proceed? Bail? Hrm...
    logger.logger.fail(`Failed to download manifest file, skipping to next file. File: ${file}`);
    return result;
  }
  logger.logger.success(`Downloaded manifest file.`);
  return {
    ok: true,
    data: undefined
  };
}

// Courtesy of gemini:
async function streamDownloadWithFetch(localPath, downloadUrl) {
  let response; // Declare response here to access it in catch if needed

  try {
    response = await fetch(downloadUrl);
    if (!response.ok) {
      const errorMsg = `Download failed: ${response.status} ${response.statusText} for ${downloadUrl}`;
      return {
        ok: false,
        message: 'Download Failed',
        cause: errorMsg
      };
    }
    if (!response.body) {
      return {
        ok: false,
        message: 'Download Failed',
        cause: 'Response body is null or undefined.'
      };
    }
    const fileStream = fs$1.createWriteStream(localPath);

    // Using stream.pipeline for better error handling and cleanup

    await promises.pipeline(response.body, fileStream);
    // 'pipeline' will automatically handle closing streams and propagating errors.
    // It resolves when the piping is fully complete and fileStream is closed.
    return {
      ok: true,
      data: localPath
    };
  } catch (error) {
    logger.logger.fail('An error occurred trying to download the file...');
    // If an error occurs and fileStream was created, attempt to clean up.
    if (fs$1.existsSync(localPath)) {
      // Check if fileStream was even opened before trying to delete
      // This check might be too simplistic depending on when error occurs
      fs$1.unlink(localPath, unlinkErr => {
        if (unlinkErr) {
          logger.logger.fail(`Error deleting partial file ${localPath}: ${unlinkErr.message}`);
        }
      });
    }
    // Construct a more informative error message
    let detailedError = `Error during download of ${downloadUrl}: ${error.message}`;
    if (error.cause) {
      // Include cause if available (e.g., from network errors)
      detailedError += `\nCause: ${error.cause}`;
    }
    if (response && !response.ok) {
      // If error was due to bad HTTP status
      detailedError += ` (HTTP Status: ${response.status} ${response.statusText})`;
    }
    return {
      ok: false,
      message: 'Download Failed',
      cause: detailedError
    };
  }
}
async function getLastCommitDetails({
  defaultBranch,
  githubToken,
  orgGithub,
  repoApiUrl,
  repoSlug
}) {
  logger.logger.info(`Requesting last commit for default branch ${defaultBranch} for ${orgGithub}/${repoSlug}...`);
  const commitApiUrl = `${repoApiUrl}/commits?sha=${defaultBranch}&per_page=1`;
  debug.debugLog('Commit url:', commitApiUrl);
  const commitResponse = await fetch(commitApiUrl, {
    headers: {
      Authorization: `Bearer ${githubToken}`
    }
  });
  const commitText = await commitResponse.text();
  debug.debugLog('[DEBUG] Raw Commit Response:', commitText);
  let lastCommit;
  try {
    lastCommit = JSON.parse(commitText)?.[0];
  } catch {
    logger.logger.fail(`GitHub response contained invalid JSON for last commit`);
    logger.logger.error(commitText);
    return {
      ok: false,
      message: 'Invalid JSON response',
      cause: `Server responded with invalid JSON for last commit of repo ${repoSlug}`
    };
  }
  const lastCommitSha = lastCommit.sha;
  const lastCommitter = Array.from(new Set([lastCommit.commit.author.name, lastCommit.commit.committer.name]))[0];
  const lastCommitMessage = lastCommit.message;
  if (!lastCommitSha) {
    return {
      ok: false,
      message: 'Missing commit SHA',
      cause: 'Unable to get last commit for repo'
    };
  }
  if (!lastCommitter) {
    return {
      ok: false,
      message: 'Missing committer',
      cause: 'Last commit does not have information about who made the commit'
    };
  }
  return {
    ok: true,
    data: {
      lastCommitSha,
      lastCommitter,
      lastCommitMessage
    }
  };
}
async function selectFocus(repos) {
  const proceed = await prompts.select({
    message: 'Please select the repo to process:',
    choices: repos.map(slug => ({
      name: slug,
      value: slug,
      description: `Create scan for the ${slug} repo through GitHub`
    })).concat({
      name: '(Exit)',
      value: '',
      description: 'Cancel this action and exit'
    })
  });
  if (!proceed) {
    return {
      ok: false,
      message: 'Canceled by user',
      cause: 'User chose to cancel the action'
    };
  }
  return {
    ok: true,
    data: [proceed]
  };
}
async function makeSure(count) {
  if (!(await prompts.confirm({
    message: `Are you sure you want to run this for ${count} repos?`,
    default: false
  }))) {
    return {
      ok: false,
      message: 'User canceled',
      cause: 'Action canceled by user'
    };
  }
  return {
    ok: true,
    data: undefined
  };
}
async function getRepoDetails({
  githubApiUrl,
  githubToken,
  orgGithub,
  repoSlug
}) {
  const repoApiUrl = `${githubApiUrl}/repos/${orgGithub}/${repoSlug}`;
  debug.debugLog('Repo url:', repoApiUrl);
  const repoDetailsResponse = await fetch(repoApiUrl, {
    method: 'GET',
    headers: {
      Authorization: `Bearer ${githubToken}`
    }
  });
  logger.logger.success(`Request completed.`);
  const repoDetailsText = await repoDetailsResponse.text();
  debug.debugLog('[DEBUG] Raw Repo Response:', repoDetailsText);
  let repoDetails;
  try {
    repoDetails = JSON.parse(repoDetailsText);
  } catch {
    logger.logger.fail(`GitHub response contained invalid JSON for repo ${repoSlug}`);
    logger.logger.error(repoDetailsText);
    return {
      ok: false,
      message: 'Invalid JSON response',
      cause: `Server responded with invalid JSON for repo ${repoSlug}`
    };
  }
  const defaultBranch = repoDetails.default_branch;
  if (!defaultBranch) {
    return {
      ok: false,
      message: 'Default Branch Not Found',
      cause: `Repo ${repoSlug} does not have a default branch set or it was not reported`
    };
  }
  return {
    ok: true,
    data: {
      defaultBranch,
      repoDetails,
      repoApiUrl
    }
  };
}
async function getRepoBranchTree({
  defaultBranch,
  githubToken,
  orgGithub,
  repoApiUrl,
  repoSlug
}) {
  logger.logger.info(`Requesting default branch file tree; branch \`${defaultBranch}\`, repo \`${orgGithub}/${repoSlug}\`...`);
  const treeApiUrl = `${repoApiUrl}/git/trees/${defaultBranch}?recursive=1`;
  debug.debugLog('Tree url:', treeApiUrl);
  const treeResponse = await fetch(treeApiUrl, {
    method: 'GET',
    headers: {
      Authorization: `Bearer ${githubToken}`
    }
  });
  const treeText = await treeResponse.text();
  debug.debugLog('[DEBUG] Raw Tree Response:', treeText);
  let treeDetails;
  try {
    treeDetails = JSON.parse(treeText);
  } catch {
    logger.logger.fail(`GitHub response contained invalid JSON for default branch of repo ${repoSlug}`);
    logger.logger.error(treeText);
    return {
      ok: false,
      message: 'Invalid JSON response',
      cause: `Server responded with invalid JSON for repo ${repoSlug}`
    };
  }
  if (treeDetails.message) {
    if (treeDetails.message === 'Git Repository is empty.') {
      logger.logger.warn(`GitHub reports the default branch of repo ${repoSlug} to be empty. Moving on to next repo.`);
      return {
        ok: true,
        data: []
      };
    }
    logger.logger.fail('Negative response from GitHub:', treeDetails.message);
    return {
      ok: false,
      message: 'Unexpected error response',
      cause: `GitHub responded with an unexpected error while asking for details on the default branch: ${treeDetails.message}`
    };
  }
  if (!treeDetails.tree || !Array.isArray(treeDetails.tree)) {
    debug.debugLog('treeDetails.tree:', treeDetails.tree);
    return {
      ok: false,
      message: `Tree response for default branch ${defaultBranch} for ${orgGithub}/${repoSlug} was not a list`
    };
  }
  const files = treeDetails.tree.filter(obj => obj.type === 'blob').map(obj => obj.path);
  return {
    ok: true,
    data: files
  };
}

async function handleCreateGithubScan({
  all,
  githubApiUrl,
  githubToken,
  interactive,
  orgGithub,
  orgSlug,
  outputKind,
  repos
}) {
  const result = await createScanFromGithub({
    all: Boolean(all),
    githubApiUrl,
    githubToken,
    interactive: Boolean(interactive),
    orgSlug,
    orgGithub,
    outputKind,
    repos: String(repos || '')
  });
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result));
    return;
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  logger.logger.success('Ok! Finished!');
}

const {
  DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$7
} = constants;
const config$7 = {
  commandName: 'github',
  description: 'Create a scan for given GitHub repo',
  hidden: true,
  // wip
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags,
    all: {
      type: 'boolean',
      description: 'Apply for all known repos reported by the Socket API. Supersedes `repos`.'
    },
    githubToken: {
      type: 'string',
      description: '(required) GitHub token for authentication (or set GITHUB_TOKEN as an environment variable)'
    },
    githubApiUrl: {
      type: 'string',
      default: 'https://api.github.com',
      description: 'Base URL of the GitHub API (default: https://api.github.com)'
    },
    interactive: {
      type: 'boolean',
      default: true,
      description: 'Allow for interactive elements, asking for input. Use --no-interactive to prevent any input questions, defaulting them to cancel/no.'
    },
    org: {
      type: 'string',
      description: 'Force override the organization slug, overrides the default org from config'
    },
    orgGithub: {
      type: 'string',
      description: 'Alternate GitHub Org if the name is different than the Socket Org'
    },
    repos: {
      type: 'string',
      description: 'List of repos to target in a comma-separated format (e.g., repo1,repo2). If not specified, the script will pull the list from Socket and ask you to pick one. Use --all to use them all.'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command}

    API Token Requirements
      - Quota: 1 unit
      - Permissions: full-scans:create

    This is similar to the \`socket scan create\` command except it pulls the files
    from GitHub. See the help for that command for more details.

    A GitHub Personal Access Token (PAT) will at least need read access to the repo
    ("contents", read-only) for this command to work.

    Note: This command cannot run the \`socket manifest auto\` things because that
    requires local access to the repo while this command runs entirely through the
    GitHub for file access.

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command}
  `
};
const cmdScanGithub = {
  description: config$7.description,
  hidden: config$7.hidden,
  run: run$7
};
async function run$7(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$7,
    importMeta,
    parentName
  });
  const {
    all = false,
    dryRun = false,
    githubApiUrl = 'https://api.github.com',
    // Lazily access constants.ENV.SOCKET_CLI_GITHUB_TOKEN.
    githubToken = constants.ENV.SOCKET_CLI_GITHUB_TOKEN,
    interactive = true,
    json,
    markdown,
    org: orgFlag,
    orgGithub: orgGithubFlag,
    repos
  } = cli.flags;
  const outputKind = utils.getOutputKind(json, markdown);
  let [orgSlug, defaultOrgSlug] = await utils.determineOrgSlug(String(orgFlag || ''), cli.input[0] || '', interactive, dryRun);
  if (!defaultOrgSlug) {
    // Tmp. just for TS. will drop this later.
    defaultOrgSlug = '';
  }

  // Default to Socket org slug. Often that's fine. Vanity and all that.
  const orgGithub = orgGithubFlag || orgSlug;

  // We're going to need an api token to suggest data because those suggestions
  // must come from data we already know. Don't error on missing api token yet.
  // If the api-token is not set, ignore it for the sake of suggestions.
  const hasSocketApiToken = utils.hasDefaultToken();
  // We will also be needing that GitHub token.
  const hasGithubApiToken = !!githubToken;

  // If the current cwd is unknown and is used as a repo slug anyways, we will
  // first need to register the slug before we can use it.
  // Only do suggestions with an apiToken and when not in dryRun mode
  if (hasSocketApiToken && !dryRun && interactive) {
    if (!orgSlug) {
      const suggestion = await utils.suggestOrgSlug();
      if (suggestion) {
        orgSlug = suggestion;
      }
    }
  }
  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: !utils.isTestingV1() && !!defaultOrgSlug,
    test: !!orgSlug && orgSlug !== '.',
    message: utils.isTestingV1() ? 'Org name by default setting, --org, or auto-discovered' : 'Org name must be the first argument',
    pass: 'ok',
    fail: orgSlug === '.' ? 'dot is an invalid org, most likely you forgot the org name here?' : 'missing'
  }, {
    nook: true,
    test: !json || !markdown,
    message: 'The json and markdown flags cannot be both set, pick one',
    pass: 'ok',
    fail: 'omit one'
  }, {
    nook: true,
    test: hasSocketApiToken,
    message: 'This command requires an API token for access',
    pass: 'ok',
    fail: 'missing (try `socket login`)'
  }, {
    test: hasGithubApiToken,
    message: 'This command requires a GitHub API token for access',
    pass: 'ok',
    fail: 'missing'
  });
  if (!wasValidInput) {
    return;
  }

  // Note exiting earlier to skirt a hidden auth requirement
  if (dryRun) {
    logger.logger.log(DRY_RUN_BAILING_NOW$7);
    return;
  }
  await handleCreateGithubScan({
    all: Boolean(all),
    githubApiUrl,
    githubToken,
    interactive: Boolean(interactive),
    orgSlug,
    orgGithub,
    outputKind,
    repos: String(repos || '')
  });
}

async function fetchListScans({
  branch,
  direction,
  from_time,
  orgSlug,
  page,
  per_page,
  repo,
  sort
}) {
  const sockSdkResult = await utils.setupSdk();
  if (!sockSdkResult.ok) {
    return sockSdkResult;
  }
  const sockSdk = sockSdkResult.data;
  return await utils.handleApiCall(sockSdk.getOrgFullScanList(orgSlug, {
    ...(branch ? {
      branch
    } : {}),
    ...(repo ? {
      repo
    } : {}),
    sort,
    direction,
    per_page: String(per_page),
    page: String(page),
    from: from_time
  }), 'list of scans');
}

// @ts-ignore
async function outputListScans(result, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result));
    return;
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  const options = {
    columns: [{
      field: 'id',
      name: vendor.yoctocolorsCjsExports.magenta('ID')
    }, {
      field: 'report_url',
      name: vendor.yoctocolorsCjsExports.magenta('Scan URL')
    }, {
      field: 'repo',
      name: vendor.yoctocolorsCjsExports.magenta('Repo')
    }, {
      field: 'branch',
      name: vendor.yoctocolorsCjsExports.magenta('Branch')
    }, {
      field: 'created_at',
      name: vendor.yoctocolorsCjsExports.magenta('Created at')
    }]
  };
  const formattedResults = result.data.results.map(d => {
    return {
      id: d.id,
      report_url: vendor.yoctocolorsCjsExports.underline(`${d.html_report_url}`),
      created_at: d.created_at ? new Date(d.created_at).toLocaleDateString('en-us', {
        year: 'numeric',
        month: 'numeric',
        day: 'numeric'
      }) : '',
      repo: d.repo,
      branch: d.branch
    };
  });
  logger.logger.log(vendor.srcExports(options, formattedResults));
}

async function handleListScans({
  branch,
  direction,
  from_time,
  orgSlug,
  outputKind,
  page,
  per_page,
  repo,
  sort
}) {
  const data = await fetchListScans({
    branch,
    direction,
    from_time,
    orgSlug,
    page,
    per_page,
    repo,
    sort
  });
  await outputListScans(data, outputKind);
}

const {
  DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$6
} = constants;
const config$6 = {
  commandName: 'list',
  description: 'List the scans for an organization',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags,
    branch: {
      type: 'string',
      description: 'Filter to show only scans with this branch name'
    },
    direction: {
      type: 'string',
      shortFlag: 'd',
      default: 'desc',
      description: 'Direction option (`desc` or `asc`) - Default is `desc`'
    },
    fromTime: {
      type: 'string',
      shortFlag: 'f',
      default: '',
      description: 'From time - as a unix timestamp'
    },
    interactive: {
      type: 'boolean',
      default: true,
      description: 'Allow for interactive elements, asking for input. Use --no-interactive to prevent any input questions, defaulting them to cancel/no.'
    },
    page: {
      type: 'number',
      shortFlag: 'p',
      default: 1,
      description: 'Page number - Default is 1'
    },
    perPage: {
      type: 'number',
      shortFlag: 'pp',
      default: 30,
      description: 'Results per page - Default is 30'
    },
    org: {
      type: 'string',
      description: 'Force override the organization slug, overrides the default org from config'
    },
    repo: {
      type: 'string',
      description: 'Filter to show only scans with this repository name'
    },
    sort: {
      type: 'string',
      shortFlag: 's',
      default: 'created_at',
      description: 'Sorting option (`name` or `created_at`) - default is `created_at`'
    },
    untilTime: {
      type: 'string',
      shortFlag: 'u',
      default: '',
      description: 'Until time - as a unix timestamp'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command}${utils.isTestingV1() ? '' : ' <org slug>'}

    API Token Requirements
      - Quota: 1 unit
      - Permissions: full-scans:list

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command}${utils.isTestingV1() ? '' : ' FakeOrg'}
  `
};
const cmdScanList = {
  description: config$6.description,
  hidden: config$6.hidden,
  run: run$6
};
async function run$6(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$6,
    importMeta,
    parentName
  });
  const {
    branch,
    dryRun,
    interactive,
    json,
    markdown,
    org: orgFlag,
    repo
  } = cli.flags;
  const outputKind = utils.getOutputKind(json, markdown);
  const [orgSlug, defaultOrgSlug] = await utils.determineOrgSlug(String(orgFlag || ''), cli.input[0] || '', !!interactive, !!dryRun);
  const hasApiToken = utils.hasDefaultToken();
  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: !!defaultOrgSlug,
    test: !!orgSlug && orgSlug !== '.',
    message: utils.isTestingV1() ? 'Org name by default setting, --org, or auto-discovered' : 'Org name must be the first argument',
    pass: 'ok',
    fail: orgSlug === '.' ? 'dot is an invalid org, most likely you forgot the org name here?' : 'missing'
  }, {
    nook: true,
    test: !json || !markdown,
    message: 'The json and markdown flags cannot be both set, pick one',
    pass: 'ok',
    fail: 'omit one'
  }, {
    nook: true,
    test: hasApiToken,
    message: 'You need to be logged in to use this command. See `socket login`.',
    pass: 'ok',
    fail: 'missing API token'
  });
  if (!wasValidInput) {
    return;
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$6);
    return;
  }
  await handleListScans({
    branch: branch ? String(branch) : '',
    direction: String(cli.flags['direction'] || ''),
    from_time: String(cli.flags['fromTime'] || ''),
    orgSlug,
    outputKind,
    page: Number(cli.flags['page'] || 1),
    per_page: Number(cli.flags['perPage'] || 30),
    repo: repo ? String(repo) : '',
    sort: String(cli.flags['sort'] || '')
  });
}

async function fetchScanMetadata(orgSlug, scanId) {
  const sockSdkResult = await utils.setupSdk();
  if (!sockSdkResult.ok) {
    return sockSdkResult;
  }
  const sockSdk = sockSdkResult.data;
  return await utils.handleApiCall(sockSdk.getOrgFullScanMetadata(orgSlug, scanId), 'meta data for a full scan');
}

async function outputScanMetadata(result, scanId, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result));
    return;
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  if (outputKind === 'markdown') {
    logger.logger.log('# Scan meta data\n');
  }
  logger.logger.log(`Scan ID: ${scanId}\n`);
  for (const [key, value] of Object.entries(result.data)) {
    if (['id', 'updated_at', 'organization_id', 'repository_id', 'commit_hash', 'html_report_url'].includes(key)) {
      continue;
    }
    logger.logger.log(`- ${key}:`, value);
  }
  if (outputKind === 'markdown') {
    logger.logger.log(`\nYou can view this report at: [${result.data.html_report_url}](${result.data.html_report_url})\n`);
  } else {
    logger.logger.log(`\nYou can view this report at: ${result.data.html_report_url}]\n`);
  }
}

async function handleOrgScanMetadata(orgSlug, scanId, outputKind) {
  const data = await fetchScanMetadata(orgSlug, scanId);
  await outputScanMetadata(data, scanId, outputKind);
}

const {
  DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$5
} = constants;
const config$5 = {
  commandName: 'metadata',
  description: "Get a scan's metadata",
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags,
    interactive: {
      type: 'boolean',
      default: true,
      description: 'Allow for interactive elements, asking for input. Use --no-interactive to prevent any input questions, defaulting them to cancel/no.'
    },
    org: {
      type: 'string',
      description: 'Force override the organization slug, overrides the default org from config'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command}${utils.isTestingV1() ? '' : ' <org slug>'} <scan ID>

    API Token Requirements
      - Quota: 1 unit
      - Permissions: full-scans:list

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command}${utils.isTestingV1() ? '' : ' FakeOrg'} 000aaaa1-0000-0a0a-00a0-00a0000000a0
  `
};
const cmdScanMetadata = {
  description: config$5.description,
  hidden: config$5.hidden,
  run: run$5
};
async function run$5(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$5,
    importMeta,
    parentName
  });
  const {
    dryRun,
    interactive,
    json,
    markdown,
    org: orgFlag
  } = cli.flags;
  const outputKind = utils.getOutputKind(json, markdown);
  const [orgSlug, defaultOrgSlug] = await utils.determineOrgSlug(String(orgFlag || ''), cli.input[0] || '', !!interactive, !!dryRun);
  const scanId = (utils.isTestingV1() || defaultOrgSlug ? cli.input[0] : cli.input[1]) || '';
  const hasApiToken = utils.hasDefaultToken();
  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: !!defaultOrgSlug,
    test: !!orgSlug && orgSlug !== '.',
    message: utils.isTestingV1() ? 'Org name by default setting, --org, or auto-discovered' : 'Org name must be the first argument',
    pass: 'ok',
    fail: orgSlug === '.' ? 'dot is an invalid org, most likely you forgot the org name here?' : 'missing'
  }, {
    test: !!scanId,
    message: 'Scan ID to inspect as argument',
    pass: 'ok',
    fail: 'missing'
  }, {
    nook: true,
    test: !json || !markdown,
    message: 'The json and markdown flags cannot be both set, pick one',
    pass: 'ok',
    fail: 'omit one'
  }, {
    nook: true,
    test: hasApiToken,
    message: 'You need to be logged in to use this command. See `socket login`.',
    pass: 'ok',
    fail: 'missing API token'
  });
  if (!wasValidInput) {
    return;
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$5);
    return;
  }
  await handleOrgScanMetadata(orgSlug, scanId, outputKind);
}

const {
  DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$4
} = constants;
const config$4 = {
  commandName: 'report',
  description: 'Check whether a scan result passes the organizational policies (security, license)',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags,
    fold: {
      type: 'string',
      default: 'none',
      description: 'Fold reported alerts to some degree'
    },
    interactive: {
      type: 'boolean',
      default: true,
      description: 'Allow for interactive elements, asking for input. Use --no-interactive to prevent any input questions, defaulting them to cancel/no.'
    },
    org: {
      type: 'string',
      description: 'Force override the organization slug, overrides the default org from config'
    },
    reportLevel: {
      type: 'string',
      default: 'warn',
      description: 'Which policy level alerts should be reported'
    },
    short: {
      type: 'boolean',
      default: false,
      description: 'Report only the healthy status'
    },
    license: {
      type: 'boolean',
      default: false,
      description: 'Also report the license policy status. Default: false'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command}${utils.isTestingV1() ? '' : ' <org slug>'} <scan ID> [path to output file]

    API Token Requirements
      - Quota: 2 units
      - Permissions: full-scans:list security-policy:read

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    By default the result is a nested object that looks like this:
      \`{[ecosystem]: {[pkgName]: {[version]: {[file]: {[type:loc]: policy}}}}\`
    You can fold this up to given level: 'pkg', 'version', 'file', and 'none'.

    By default only the warn and error policy level alerts are reported. You can
    override this and request more ('defer' < 'ignore' < 'monitor' < 'warn' < 'error')

    Short responses: JSON: \`{healthy:bool}\`, markdown: \`healthy = bool\`, text: \`OK/ERR\`

    Examples
      $ ${command}${utils.isTestingV1() ? '' : ' FakeOrg'} 000aaaa1-0000-0a0a-00a0-00a0000000a0 --json --fold=version
      $ ${command}${utils.isTestingV1() ? '' : ' FakeOrg'} 000aaaa1-0000-0a0a-00a0-00a0000000a0 --license --markdown --short
  `
};
const cmdScanReport = {
  description: config$4.description,
  hidden: config$4.hidden,
  run: run$4
};
async function run$4(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$4,
    importMeta,
    parentName
  });
  const {
    fold = 'none',
    json,
    license,
    markdown,
    reportLevel = 'warn'
  } = cli.flags;
  const outputKind = utils.getOutputKind(json, markdown);
  const {
    dryRun,
    interactive,
    org: orgFlag
  } = cli.flags;
  const [orgSlug, defaultOrgSlug] = await utils.determineOrgSlug(String(orgFlag || ''), cli.input[0] || '', !!interactive, !!dryRun);
  const scanId = (utils.isTestingV1() || defaultOrgSlug ? cli.input[0] : cli.input[1]) || '';
  const file = (utils.isTestingV1() || defaultOrgSlug ? cli.input[1] : cli.input[2]) || '-';
  const hasApiToken = utils.hasDefaultToken();
  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: !!defaultOrgSlug,
    test: !!orgSlug && orgSlug !== '.',
    message: utils.isTestingV1() ? 'Org name by default setting, --org, or auto-discovered' : 'Org name must be the first argument',
    pass: 'ok',
    fail: orgSlug === '.' ? 'dot is an invalid org, most likely you forgot the org name here?' : 'missing'
  }, {
    test: !!scanId,
    message: 'Scan ID to report on',
    pass: 'ok',
    fail: 'missing'
  }, {
    nook: true,
    test: !json || !markdown,
    message: 'The json and markdown flags cannot be both set, pick one',
    pass: 'ok',
    fail: 'omit one'
  }, {
    nook: true,
    test: hasApiToken,
    message: 'You need to be logged in to use this command. See `socket login`.',
    pass: 'ok',
    fail: 'missing API token'
  });
  if (!wasValidInput) {
    return;
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$4);
    return;
  }
  await handleScanReport({
    orgSlug,
    scanId: scanId,
    includeLicensePolicy: !!license,
    outputKind,
    filePath: file,
    fold: fold,
    short: !!cli.flags['short'],
    reportLevel: reportLevel
  });
}

async function fetchScan(orgSlug, scanId) {
  const result = await utils.queryApiSafeText(`orgs/${orgSlug}/full-scans/${encodeURIComponent(scanId)}`, 'a scan');
  if (!result.ok) {
    return result;
  }
  const jsonsString = result.data;

  // This is nd-json; each line is a json object
  const lines = jsonsString.split('\n').filter(Boolean);
  let ok = true;
  const data = lines.map(line => {
    try {
      return JSON.parse(line);
    } catch {
      ok = false;
      debug.debugLog('ndjson failed to parse the following line:');
      debug.debugLog(line);
      return null;
    }
  });
  if (ok) {
    return {
      ok: true,
      data
    };
  }
  return {
    ok: false,
    message: 'Invalid API response',
    cause: 'The API responded with at least one line that was not valid JSON. Please report if this persists.'
  };
}

const {
  SOCKET_WEBSITE_URL
} = constants;
async function outputScanView(result, orgSlug, scanId, filePath, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (!result.ok) {
    if (outputKind === 'json') {
      logger.logger.log(utils.serializeResultJson(result));
      return;
    }
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  if (outputKind === 'json' || outputKind === 'text' && filePath && filePath.endsWith('.json')) {
    const json = utils.serializeResultJson(result);
    if (filePath !== '-') {
      logger.logger.info('Writing json results to', filePath);
      try {
        await fs.writeFile(filePath, json, 'utf8');
        logger.logger.info(`Data successfully written to ${filePath}`);
      } catch (e) {
        process.exitCode = 1;
        logger.logger.fail('There was an error trying to write the markdown to disk');
        logger.logger.error(e);
        logger.logger.log(utils.serializeResultJson({
          ok: false,
          message: 'File Write Failure',
          cause: 'Failed to write json to disk'
        }));
      }
      return;
    }
    logger.logger.log(json);
    return;
  }
  const display = result.data.map(art => {
    const author = Array.isArray(art.author) ? `${art.author[0]}${art.author.length > 1 ? ' et.al.' : ''}` : art.author;
    return {
      type: art.type,
      name: art.name,
      version: art.version,
      author,
      score: JSON.stringify(art.score)
    };
  });
  const md = utils.mdTable(display, ['type', 'version', 'name', 'author', 'score']);
  const report = `
# Scan Details

These are the artifacts and their scores found.

Scan ID: ${scanId}

${md}

View this report at: ${SOCKET_WEBSITE_URL}/dashboard/org/${orgSlug}/sbom/${scanId}
  `.trim() + '\n';
  if (filePath !== '-') {
    try {
      await fs.writeFile(filePath, report, 'utf8');
      logger.logger.log(`Data successfully written to ${filePath}`);
    } catch (e) {
      process.exitCode = 1;
      logger.logger.fail('There was an error trying to write the markdown to disk');
      logger.logger.error(e);
    }
  } else {
    logger.logger.log(report);
  }
}

async function handleScanView(orgSlug, scanId, filePath, outputKind) {
  const data = await fetchScan(orgSlug, scanId);
  await outputScanView(data, orgSlug, scanId, filePath, outputKind);
}

async function streamScan(orgSlug, scanId, file) {
  const sockSdkResult = await utils.setupSdk();
  if (!sockSdkResult.ok) {
    return sockSdkResult;
  }
  const sockSdk = sockSdkResult.data;
  logger.logger.info('Requesting data from API...');

  // Note: this will write to stdout or target file. It's not a noop
  return await utils.handleApiCall(sockSdk.getOrgFullScan(orgSlug, scanId, file === '-' ? undefined : file), 'a scan');
}

const {
  DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$3
} = constants;
const config$3 = {
  commandName: 'view',
  description: 'View the raw results of a scan',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags,
    stream: {
      type: 'boolean',
      default: false,
      description: 'Only valid with --json. Streams the response as "ndjson" (chunks of valid json blobs).'
    },
    interactive: {
      type: 'boolean',
      default: true,
      description: 'Allow for interactive elements, asking for input. Use --no-interactive to prevent any input questions, defaulting them to cancel/no.'
    },
    org: {
      type: 'string',
      description: 'Force override the organization slug, overrides the default org from config'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command}${utils.isTestingV1() ? '' : ' <org slug>'} <scan ID> [path to output file]

    API Token Requirements
      - Quota: 1 unit
      - Permissions: full-scans:list

    When no output path is given the contents is sent to stdout.

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command}${utils.isTestingV1() ? '' : ' FakeOrg'} 000aaaa1-0000-0a0a-00a0-00a0000000a0 ./stream.txt
  `
};
const cmdScanView = {
  description: config$3.description,
  hidden: config$3.hidden,
  run: run$3
};
async function run$3(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$3,
    importMeta,
    parentName
  });
  const {
    dryRun,
    interactive,
    json,
    markdown,
    org: orgFlag,
    stream
  } = cli.flags;
  const outputKind = utils.getOutputKind(json, markdown);
  const [orgSlug, defaultOrgSlug] = await utils.determineOrgSlug(String(orgFlag || ''), cli.input[0] || '', !!interactive, !!dryRun);
  const scanId = (utils.isTestingV1() || defaultOrgSlug ? cli.input[0] : cli.input[1]) || '';
  const file = (utils.isTestingV1() || defaultOrgSlug ? cli.input[1] : cli.input[2]) || '-';
  const hasApiToken = utils.hasDefaultToken();
  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: !!defaultOrgSlug,
    test: !!orgSlug && orgSlug !== '.',
    message: utils.isTestingV1() ? 'Org name by default setting, --org, or auto-discovered' : 'Org name must be the first argument',
    pass: 'ok',
    fail: orgSlug === '.' ? 'dot is an invalid org, most likely you forgot the org name here?' : 'missing'
  }, {
    test: !!scanId,
    message: 'Scan ID to view',
    pass: 'ok',
    fail: 'missing'
  }, {
    nook: true,
    test: !json || !markdown,
    message: 'The `--json` and `--markdown` flags can not be used at the same time',
    pass: 'ok',
    fail: 'bad'
  }, {
    nook: true,
    test: hasApiToken,
    message: 'You need to be logged in to use this command. See `socket login`.',
    pass: 'ok',
    fail: 'missing API token'
  }, {
    nook: true,
    test: !stream || !!json,
    message: 'You can only use --stream when using --json',
    pass: 'ok',
    fail: 'Either remove --stream or add --json'
  });
  if (!wasValidInput) {
    return;
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$3);
    return;
  }
  if (json && stream) {
    await streamScan(orgSlug, scanId, file);
  } else {
    await handleScanView(orgSlug, scanId, file, outputKind);
  }
}

const description$1 = 'Scan related commands';
const cmdScan = {
  description: description$1,
  async run(argv, importMeta, {
    parentName
  }) {
    await utils.meowWithSubcommands({
      create: cmdScanCreate,
      del: cmdScanDel,
      diff: cmdScanDiff,
      github: cmdScanGithub,
      list: cmdScanList,
      metadata: cmdScanMetadata,
      report: cmdScanReport,
      view: cmdScanView
    }, {
      aliases: {
        // Backwards compat. TODO: Drop next major bump
        stream: {
          description: cmdScanView.description,
          hidden: true,
          argv: ['view'] // Original args will be appended (!)
        }
      },
      argv,
      description: description$1,
      importMeta,
      name: parentName + ' scan'
    });
  }
};

async function fetchThreatFeed({
  direction,
  ecosystem,
  filter,
  page,
  perPage
}) {
  const queryParams = new URLSearchParams([['direction', direction], ['ecosystem', ecosystem], ['filter', filter], ['page', page], ['per_page', String(perPage)]]);
  return await utils.queryApiSafeJson(`threat-feed?${queryParams}`, 'the Threat Feed data');
}

const require$1 =Module.createRequire(require$$0.pathToFileURL(__filename).href)
async function outputThreatFeed(result, outputKind) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
  }
  if (outputKind === 'json') {
    logger.logger.log(utils.serializeResultJson(result));
    return;
  }
  if (!result.ok) {
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  if (!result.data?.results?.length) {
    logger.logger.warn('Did not receive any data to display...');
    return;
  }
  const formattedOutput = formatResults(result.data.results);
  const descriptions = result.data.results.map(d => d.description);

  // Note: this temporarily takes over the terminal (just like `man` does).
  const ScreenWidget = require$1('../external/blessed/lib/widgets/screen.js');
  // Lazily access constants.blessedOptions.
  const screen = new ScreenWidget({
    ...constants.blessedOptions
  });
  // Register these keys first so you can always exit, even when it gets stuck
  // If we don't do this and the code crashes, the user must hard-kill the
  // node process just to exit it. That's very bad UX.
  // eslint-disable-next-line n/no-process-exit
  screen.key(['escape', 'q', 'C-c'], () => process.exit(0));
  const TableWidget = require$1('../external/blessed-contrib/lib/widget/table.js');
  const table = new TableWidget({
    keys: 'true',
    fg: 'white',
    selectedFg: 'white',
    selectedBg: 'magenta',
    interactive: 'true',
    label: 'Threat feed',
    width: '100%',
    height: '70%',
    // Changed from 100% to 70%
    border: {
      type: 'line',
      fg: 'cyan'
    },
    columnWidth: [10, 30, 20, 18, 15, 200],
    // TODO: the truncation doesn't seem to work too well yet but when we add
    //       `pad` alignment fails, when we extend columnSpacing alignment fails
    columnSpacing: 1,
    truncate: '_'
  });

  // Create details box at the bottom
  const BoxWidget = require$1('../external/blessed/lib/widgets/box.js');
  const detailsBox = new BoxWidget({
    bottom: 0,
    height: '30%',
    width: '100%',
    border: {
      type: 'line',
      fg: 'cyan'
    },
    label: 'Details',
    content: 'Use arrow keys to navigate. Press Enter to select a threat. Press q to exit.',
    style: {
      fg: 'white'
    }
  });
  table.setData({
    headers: [' Ecosystem', ' Name', '  Version', '  Threat type', '  Detected at', ' Details'],
    data: formattedOutput
  });

  // allow control the table with the keyboard
  table.focus();
  screen.append(table);
  screen.append(detailsBox);

  // Update details box when selection changes
  table.rows.on('select item', () => {
    const selectedIndex = table.rows.selected;
    if (selectedIndex !== undefined && selectedIndex >= 0) {
      const selectedRow = formattedOutput[selectedIndex];
      if (selectedRow) {
        // Note: the spacing works around issues with the table; it refuses to pad!
        detailsBox.setContent(`Ecosystem: ${selectedRow[0]}\n` + `Name: ${selectedRow[1]}\n` + `Version:${selectedRow[2]}\n` + `Threat type:${selectedRow[3]}\n` + `Detected at:${selectedRow[4]}\n` + `Details: ${selectedRow[5]}\n` + `Description: ${descriptions[selectedIndex]}`);
        screen.render();
      }
    }
  });
  screen.render();
  screen.key(['return'], () => {
    const selectedIndex = table.rows.selected;
    screen.destroy();
    const selectedRow = formattedOutput[selectedIndex];
    logger.logger.log('Last selection:\n', selectedRow);
  });
}
function formatResults(data) {
  return data.map(d => {
    const ecosystem = d.purl.split('pkg:')[1].split('/')[0];
    const name = d.purl.split('/')[1].split('@')[0];
    const version = d.purl.split('@')[1];
    const timeDiff = msAtHome(d.createdAt);

    // Note: the spacing works around issues with the table; it refuses to pad!
    return [ecosystem, decodeURIComponent(name), ` ${version}`, ` ${d.threatType}`, ` ${timeDiff}`, d.locationHtmlUrl];
  });
}
function msAtHome(isoTimeStamp) {
  const timeStart = Date.parse(isoTimeStamp);
  const timeEnd = Date.now();
  const rtf = new Intl.RelativeTimeFormat('en', {
    numeric: 'always',
    style: 'short'
  });
  const delta = timeEnd - timeStart;
  if (delta < 60 * 60 * 1000) {
    return rtf.format(-Math.round(delta / (60 * 1000)), 'minute');
    // return Math.round(delta / (60 * 1000)) + ' min ago'
  } else if (delta < 24 * 60 * 60 * 1000) {
    return rtf.format(-(delta / (60 * 60 * 1000)).toFixed(1), 'hour');
    // return (delta / (60 * 60 * 1000)).toFixed(1) + ' hr ago'
  } else if (delta < 7 * 24 * 60 * 60 * 1000) {
    return rtf.format(-(delta / (24 * 60 * 60 * 1000)).toFixed(1), 'day');
    // return (delta / (24 * 60 * 60 * 1000)).toFixed(1) + ' day ago'
  } else {
    return isoTimeStamp.slice(0, 10);
  }
}

async function handleThreatFeed({
  direction,
  ecosystem,
  filter,
  outputKind,
  page,
  perPage
}) {
  const data = await fetchThreatFeed({
    direction,
    ecosystem,
    filter,
    page,
    perPage
  });
  await outputThreatFeed(data, outputKind);
}

const {
  DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$2
} = constants;
const config$2 = {
  commandName: 'threat-feed',
  description: '[beta] View the threat feed',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    ...utils.outputFlags,
    interactive: {
      type: 'boolean',
      default: true,
      description: 'Allow for interactive elements, asking for input. Use --no-interactive to prevent any input questions, defaulting them to cancel/no.'
    },
    org: {
      type: 'string',
      description: 'Force override the organization slug, overrides the default org from config'
    },
    perPage: {
      type: 'number',
      shortFlag: 'pp',
      default: 30,
      description: 'Number of items per page'
    },
    page: {
      type: 'string',
      shortFlag: 'p',
      default: '1',
      description: 'Page token'
    },
    direction: {
      type: 'string',
      shortFlag: 'd',
      default: 'desc',
      description: 'Order asc or desc by the createdAt attribute'
    },
    eco: {
      type: 'string',
      shortFlag: 'e',
      default: '',
      description: 'Only show threats for a particular ecosystem'
    },
    filter: {
      type: 'string',
      shortFlag: 'f',
      default: 'mal',
      description: 'Filter what type of threats to return'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command}${utils.isTestingV1() ? '' : ' <org slug>'}

    API Token Requirements
      - Quota: 1 unit
      - Permissions: threat-feed:list
      - Special access

    This feature requires a Threat Feed license. Please contact
    sales@socket.dev if you are interested in purchasing this access.

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Valid filters:

      - anom    Anomaly
      - c       Do not filter
      - fp      False Positives
      - joke    Joke / Fake
      - mal     Malware and Possible Malware [default]
      - secret  Secrets
      - spy     Telemetry
      - tp      False Positives and Unreviewed
      - typo    Typo-squat
      - u       Unreviewed
      - vuln    Vulnerability

    Valid ecosystems:

      - gem
      - golang
      - maven
      - npm
      - nuget
      - pypi

    Examples
      $ ${command}${utils.isTestingV1() ? '' : ' FakeOrg'}
      $ ${command}${utils.isTestingV1() ? '' : ' FakeOrg'} --perPage=5 --page=2 --direction=asc --filter=joke
  `
};
const cmdThreatFeed = {
  description: config$2.description,
  hidden: config$2.hidden,
  run: run$2
};
async function run$2(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$2,
    importMeta,
    parentName
  });
  const {
    dryRun,
    interactive,
    json,
    markdown,
    org: orgFlag
  } = cli.flags;
  const outputKind = utils.getOutputKind(json, markdown);
  const [orgSlug] = await utils.determineOrgSlug(String(orgFlag || ''), cli.input[0] || '', !!interactive, !!dryRun);
  const hasApiToken = utils.hasDefaultToken();
  const wasValidInput = utils.checkCommandInput(outputKind, {
    nook: true,
    test: !!orgSlug,
    message: 'Org name as the first argument',
    pass: 'ok',
    fail: 'missing'
  }, {
    nook: true,
    test: !json || !markdown,
    message: 'The json and markdown flags cannot be both set, pick one',
    pass: 'ok',
    fail: 'omit one'
  }, {
    nook: true,
    test: hasApiToken,
    message: 'You need to be logged in to use this command. See `socket login`.',
    pass: 'ok',
    fail: 'missing API token'
  });
  if (!wasValidInput) {
    return;
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$2);
    return;
  }
  await handleThreatFeed({
    direction: String(cli.flags['direction'] || 'desc'),
    ecosystem: String(cli.flags['eco'] || ''),
    filter: String(cli.flags['filter'] || 'mal'),
    outputKind,
    page: String(cli.flags['page'] || '1'),
    perPage: Number(cli.flags['perPage']) || 30
  });
}

async function outputUninstallCompletion(result, targetName) {
  if (!result.ok) {
    process.exitCode = result.code ?? 1;
    logger.logger.fail(utils.failMsgWithBadge(result.message, result.cause));
    return;
  }
  logger.logger.log(result.message);
  logger.logger.log('');
  logger.logger.log('To remove the tab completion from the current shell (instance of bash) you');
  logger.logger.log('can run this command (due to a bash limitation NodeJS cannot do this):');
  logger.logger.log('');
  logger.logger.log(`    complete -r ${targetName}`);
  logger.logger.log('');
  logger.logger.log('Next time you open a terminal it should no longer be there, regardless.');
  logger.logger.log('');
  if (result.data.left.length) {
    logger.logger.log('Detected more Socket Alias completions left in bashrc. Run `socket uninstall <cmd>` to remove them too.');
    logger.logger.log('');
    result.data.left.forEach(str => {
      logger.logger.log(`  - \`${str}\``);
    });
    logger.logger.log('');
  }
}

async function teardownTabCompletion(targetName) {
  const result = utils.getBashrcDetails(targetName);
  if (!result.ok) {
    return result;
  }
  const {
    completionCommand,
    sourcingCommand,
    toAddToBashrc
  } = result.data;

  // Remove from ~/.bashrc if found
  // Lazily access constants.homePath
  const bashrc = constants.homePath ? path.join(constants.homePath, '.bashrc') : '';
  if (bashrc && fs$1.existsSync(bashrc)) {
    const content = fs$1.readFileSync(bashrc, 'utf8');
    if (content.includes(toAddToBashrc)) {
      const newContent = content
      // Try to remove the whole thing with comment first
      .replaceAll(toAddToBashrc, '')
      // Comment may have been edited away, try to remove the command at least
      .replaceAll(sourcingCommand, '').replaceAll(completionCommand, '');
      fs$1.writeFileSync(bashrc, newContent, 'utf8');
      return {
        ok: true,
        data: {
          action: 'removed',
          left: findRemainingCompletionSetups(newContent)
        },
        message: 'Removed completion from ~/.bashrc'
      };
    } else {
      const left = findRemainingCompletionSetups(content);
      return {
        ok: true,
        data: {
          action: 'missing',
          left
        },
        message: `Completion was not found in ~/.bashrc${left.length ? ' (you may need to manually edit your .bashrc to clean this up...)' : ''}`
      };
    }
  } else {
    return {
      ok: true,
      // Eh. I think this makes most sense.
      data: {
        action: 'not found',
        left: []
      },
      message: '~/.bashrc not found, skipping'
    };
  }
}
function findRemainingCompletionSetups(bashrc) {
  return bashrc.split('\n').map(s => s.trim()).filter(s => s.startsWith(utils.COMPLETION_CMD_PREFIX)).map(s => s.slice(utils.COMPLETION_CMD_PREFIX.length).trim());
}

async function handleUninstallCompletion(targetName) {
  const result = await teardownTabCompletion(targetName);
  await outputUninstallCompletion(result, targetName);
}

const {
  DRY_RUN_BAILING_NOW: DRY_RUN_BAILING_NOW$1
} = constants;
const config$1 = {
  commandName: 'completion',
  description: 'Uninstall bash completion for Socket CLI',
  hidden: true,
  // beta
  flags: {
    ...utils.commonFlags
  },
  help: (command, config) => `
    Usage
      $ ${command} [name=socket]

    Uninstalls bash tab completion for the Socket CLI. This will:
    1. Remove tab completion from your current shell for given command
    2. Remove the setup for given command from your ~/.bashrc

    The optional name is required if you installed tab completion for an alias
    other than the default "socket". This will NOT remove the command, only the
    tab completion that is registered for it in bash.

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Examples

      $ ${command}
      $ ${command} sd
  `
};
const cmdUninstallCompletion = {
  description: config$1.description,
  hidden: config$1.hidden,
  run: run$1
};
async function run$1(argv, importMeta, {
  parentName
}) {
  const cli = utils.meowOrExit({
    argv,
    config: config$1,
    importMeta,
    parentName
  });
  const targetName = cli.input[0] || 'socket';
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW$1);
    return;
  }
  await handleUninstallCompletion(String(targetName));
}

const description = 'Teardown the Socket command from your environment';
const cmdUninstall = {
  description,
  hidden: true,
  // beta
  async run(argv, importMeta, {
    parentName
  }) {
    await utils.meowWithSubcommands({
      completion: cmdUninstallCompletion
    }, {
      argv,
      description,
      importMeta,
      name: `${parentName} uninstall`
    });
  }
};

function addSocketWrapper(file) {
  return fs$1.appendFile(file, 'alias npm="socket npm"\nalias npx="socket npx"\n', err => {
    if (err) {
      return new Error(`There was an error setting up the alias: ${err}`);
    }
    // TODO: pretty sure you need to source the file or restart
    //       any terminal session before changes are reflected.
    logger.logger.log(`
The alias was added to ${file}. Running 'npm install' will now be wrapped in Socket's "safe npm" 🎉
If you want to disable it at any time, run \`socket wrapper --disable\`
      `.trim());
  });
}

function checkSocketWrapperSetup(file) {
  const fileContent = fs$1.readFileSync(file, 'utf8');
  const linesWithSocketAlias = fileContent.split('\n').filter(l => l === 'alias npm="socket npm"' || l === 'alias npx="socket npx"');
  if (linesWithSocketAlias.length) {
    logger.logger.log(`The Socket npm/npx wrapper is set up in your bash profile (${file})`);
    return true;
  }
  return false;
}

async function postinstallWrapper() {
  // Lazily access constants.bashRcPath and constants.zshRcPath.
  const {
    bashRcPath,
    zshRcPath
  } = constants;
  const socketWrapperEnabled = fs$1.existsSync(bashRcPath) && checkSocketWrapperSetup(bashRcPath) || fs$1.existsSync(zshRcPath) && checkSocketWrapperSetup(zshRcPath);
  if (!socketWrapperEnabled) {
    await installSafeNpm(`
The Socket CLI is now successfully installed! 🎉

To better protect yourself against supply-chain attacks, our "safe npm" wrapper can warn you about malicious packages whenever you run 'npm install'.

Do you want to install "safe npm" (this will create an alias to the socket-npm command)?
    `.trim());
  }

  // Attempt to update the existing tab completion
  let updatedTabCompletion = false;
  try {
    const details = utils.getBashrcDetails(''); // Note: command is not relevant, we just want the config path
    if (details.ok) {
      if (fs$1.existsSync(details.data.targetPath)) {
        // Replace the file with the one from this installation
        const result = updateInstalledTabCompletionScript(details.data.targetPath);
        if (result.ok) {
          // This will work no matter what alias(es) were registered since that
          // is controlled by bashrc and they all share the same tab script.
          logger.logger.success('Updated the installed Socket tab completion script');
          updatedTabCompletion = true;
        }
      }
    }
  } catch (e) {
    debug.debugLog('Failed to setup tab completion:');
    debug.debugLog(e);
    // Ignore. Skip tab completion setup.
  }
  if (!updatedTabCompletion) {
    // Setting up tab completion requires bashrc modification. I'm not sure if
    // it's cool to just do that from an npm install...
    logger.logger.log('Run `socket install completion` to setup bash tab completion');
  }
}
async function installSafeNpm(query) {
  logger.logger.log(`
 _____         _       _
|   __|___ ___| |_ ___| |_
|__   | . |  _| '_| -_|  _|
|_____|___|___|_,_|___|_|

`);
  if (await prompts.confirm({
    message: query,
    default: true
  })) {
    // Lazily access constants.bashRcPath and constants.zshRcPath.
    const {
      bashRcPath,
      zshRcPath
    } = constants;
    try {
      if (fs$1.existsSync(bashRcPath)) {
        addSocketWrapper(bashRcPath);
      }
      if (fs$1.existsSync(zshRcPath)) {
        addSocketWrapper(zshRcPath);
      }
    } catch (e) {
      throw new Error(`There was an issue setting up the alias: ${e?.['message']}`);
    }
  }
}

function removeSocketWrapper(file) {
  return fs$1.readFile(file, 'utf8', function (err, data) {
    if (err) {
      logger.logger.fail('There was an error removing the alias:');
      logger.logger.error(err);
      return;
    }
    const linesWithoutSocketAlias = data.split('\n').filter(l => l !== 'alias npm="socket npm"' && l !== 'alias npx="socket npx"');
    const updatedFileContent = linesWithoutSocketAlias.join('\n');
    fs$1.writeFile(file, updatedFileContent, function (err) {
      if (err) {
        logger.logger.error(err);
        return;
      }
      // TODO: pretty sure you need to source the file or restart
      //       any terminal session before changes are reflected.
      logger.logger.log(`The alias was removed from ${file}. Running 'npm install' will now run the standard npm command.`);
    });
  });
}

const {
  DRY_RUN_BAILING_NOW
} = constants;
const config = {
  commandName: 'wrapper',
  description: 'Enable or disable the Socket npm/npx wrapper',
  hidden: false,
  flags: {
    ...utils.commonFlags,
    enable: {
      type: 'boolean',
      default: false,
      description: 'Enables the Socket npm/npx wrapper'
    },
    disable: {
      type: 'boolean',
      default: false,
      description: 'Disables the Socket npm/npx wrapper'
    }
  },
  help: (command, config) => `
    Usage
      $ ${command} <flag>

    Options
      ${utils.getFlagListOutput(config.flags, 6)}

    Examples
      $ ${command} --enable
      $ ${command} --disable
  `
};
const cmdWrapper = {
  description: config.description,
  hidden: config.hidden,
  run
};
async function run(argv, importMeta, {
  parentName
}) {
  // I don't think meow would mess with this but ...
  if (argv[0] === '--postinstall') {
    await postinstallWrapper();
    return;
  }
  const cli = utils.meowOrExit({
    argv,
    config,
    importMeta,
    parentName
  });
  const {
    disable,
    enable,
    json,
    markdown
  } = cli.flags;
  const outputKind = utils.getOutputKind(json, markdown); // TODO: impl json/md further

  const wasValidInput = utils.checkCommandInput(outputKind, {
    test: !!(enable || disable),
    message: 'Must use --enabled or --disable',
    pass: 'ok',
    fail: 'missing'
  }, {
    nook: true,
    test: !enable || !disable,
    message: 'Do not use both --enable and --disable',
    pass: 'ok',
    fail: 'missing'
  });
  if (!wasValidInput) {
    return;
  }
  if (cli.flags['dryRun']) {
    logger.logger.log(DRY_RUN_BAILING_NOW);
    return;
  }

  // Lazily access constants.bashRcPath and constants.zshRcPath.
  const {
    bashRcPath,
    zshRcPath
  } = constants;
  if (enable) {
    if (fs$1.existsSync(bashRcPath) && !checkSocketWrapperSetup(bashRcPath)) {
      addSocketWrapper(bashRcPath);
    }
    if (fs$1.existsSync(zshRcPath) && !checkSocketWrapperSetup(zshRcPath)) {
      addSocketWrapper(zshRcPath);
    }
  } else {
    if (fs$1.existsSync(bashRcPath)) {
      removeSocketWrapper(bashRcPath);
    }
    if (fs$1.existsSync(zshRcPath)) {
      removeSocketWrapper(zshRcPath);
    }
  }
  if (!fs$1.existsSync(bashRcPath) && !fs$1.existsSync(zshRcPath)) {
    logger.logger.fail('There was an issue setting up the alias in your bash profile');
  }
}

const __filename$1 = require$$0.fileURLToPath((typeof document === 'undefined' ? require$$0.pathToFileURL(__filename).href : (_documentCurrentScript && _documentCurrentScript.tagName.toUpperCase() === 'SCRIPT' && _documentCurrentScript.src || new URL('cli.js', document.baseURI).href)));
const {
  SOCKET_CLI_BIN_NAME
} = constants;

// TODO: Add autocompletion using https://socket.dev/npm/package/omelette
void (async () => {
  await vendor.updater({
    name: SOCKET_CLI_BIN_NAME,
    // Lazily access constants.ENV.INLINED_SOCKET_CLI_VERSION.
    version: constants.ENV.INLINED_SOCKET_CLI_VERSION,
    ttl: 86_400_000 /* 24 hours in milliseconds */
  });
  try {
    await utils.meowWithSubcommands({
      ci: cmdCI,
      cdxgen: cmdCdxgen,
      config: cmdConfig,
      fix: cmdFix,
      info: cmdInfo,
      install: cmdInstall,
      login: cmdLogin,
      logout: cmdLogout,
      npm: cmdNpm,
      npx: cmdNpx,
      oops: cmdOops,
      optimize: cmdOptimize,
      organization: cmdOrganization,
      package: cmdPackage,
      'raw-npm': cmdRawNpm,
      'raw-npx': cmdRawNpx,
      report: cmdReport,
      wrapper: cmdWrapper,
      scan: cmdScan,
      'audit-log': cmdAuditLog,
      repos: cmdRepos,
      dependencies: cmdScanCreate$1,
      analytics: cmdAnalytics,
      'diff-scan': cmdDiffScan,
      'threat-feed': cmdThreatFeed,
      manifest: cmdManifest,
      uninstall: cmdUninstall
    }, {
      aliases: {},
      argv: process.argv.slice(2),
      name: SOCKET_CLI_BIN_NAME,
      importMeta: {
        url: `${require$$0.pathToFileURL(__filename$1)}`
      }
    });
  } catch (e) {
    process.exitCode = 1;
    let errorBody;
    let errorTitle;
    let errorMessage = '';
    if (e instanceof utils.AuthError) {
      errorTitle = 'Authentication error';
      errorMessage = e.message;
    } else if (e instanceof utils.InputError) {
      errorTitle = 'Invalid input';
      errorMessage = e.message;
      errorBody = e.body;
    } else if (e instanceof Error) {
      errorTitle = 'Unexpected error';
      errorMessage = vendor.messageWithCauses(e);
      errorBody = vendor.stackWithCauses(e);
    } else {
      errorTitle = 'Unexpected error with no details';
    }
    logger.logger.error('\n'); // Any-spinner-newline
    logger.logger.fail(utils.failMsgWithBadge(errorTitle, errorMessage));
    if (errorBody) {
      debug.debugLog(`${errorBody}`);
    }
    await utils.captureException(e);
  }
})();
//# debugId=c94f3f7e-3083-4d96-937a-6613d7ce5dce
//# sourceMappingURL=cli.js.map
